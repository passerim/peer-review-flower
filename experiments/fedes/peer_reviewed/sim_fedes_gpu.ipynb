{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../../\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eTrCL2FmC5U5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MetBook\\Documents\\UNIVERSITA\\MAGISTRALE\\SD21\\PROGETTO\\FLWR\\peer_reviewed_fl\\envs\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Iterable\n",
    "\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from flwr.common import (EvaluateIns, FitIns, FitRes, MetricsAggregationFn,\n",
    "                         Parameters, Scalar, Weights, parameters_to_weights,\n",
    "                         weights_to_parameters)\n",
    "from flwr.server.client_manager import ClientManager, SimpleClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.criterion import Criterion\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
    "from prflwr.peer_reviewed.prclient import PeerReviewClient\n",
    "from prflwr.peer_reviewed.prconfig import PrConfig\n",
    "from prflwr.peer_reviewed.prserver import PeerReviewServer\n",
    "from prflwr.peer_reviewed.prstrategy import PeerReviewStrategy\n",
    "from prflwr.peer_reviewed.strategies.prfedavg import PeerReviewedFedAvg\n",
    "from prflwr.simulation.app import start_simulation\n",
    "from prflwr.utils.flwr import import_dataset_utils\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torchvision import datasets\n",
    "\n",
    "import_dataset_utils()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4bKI8oK2Ubx",
    "outputId": "4a55807d-855c-4333-f1c4-4c5f9cb2f67a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"CIFAR10\"  # possible values: \"CIFAR10\" or \"CIFAR100\"\n",
    "NUM_CLIENTS = 10\n",
    "NUM_ROUNDS = 3\n",
    "LOCAL_EPOCHS = 1\n",
    "BATCH_SIZE = 128\n",
    "LR = 0.1\n",
    "MILESTONES = [60, 120, 160]\n",
    "LR_DECAY = 0.2\n",
    "W_DECAY = 5e-04\n",
    "FRACTION_FIT = 1/3\n",
    "FRACTION_EVAL = 0\n",
    "FRACTION_REV = 1/2\n",
    "SEED = 0\n",
    "# Set the start method for multiprocessing in case Python version is under 3.8.1\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE = \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BpLBow6s-CNy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "J4Em7BPNTXeX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_datasets(\n",
    "    num_clients: int, dataset: str = \"CIFAR10\", concentration: float = 1, src: str = \".\"\n",
    "):\n",
    "    if dataset not in [\"CIFAR10\", \"CIFAR100\"]:\n",
    "        raise ValueError(\n",
    "            \"Unknown dataset! Admissible values are: 'CIFAR10' or 'CIFAR100'.\"\n",
    "        )\n",
    "    # Download and transform CIFAR dataset (train and test)\n",
    "    augmentation = [\n",
    "        transforms.Pad(4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32),\n",
    "    ]\n",
    "    transform = [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    "    trainset = getattr(datasets, dataset)(\n",
    "        os.path.join(src, \"./data\"),\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([*augmentation, *transform]),\n",
    "    )\n",
    "    testset = getattr(datasets, dataset)(\n",
    "        os.path.join(src, \"./data\"),\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(transform),\n",
    "    )\n",
    "\n",
    "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
    "    targets = np.array(trainset.targets)\n",
    "    idxs = np.array(range(len(targets)))\n",
    "    idxs_targets = [idxs, targets]\n",
    "    train_partitions, _ = fl.dataset.utils.common.create_lda_partitions(\n",
    "        idxs_targets,\n",
    "        num_partitions=num_clients,\n",
    "        concentration=concentration,\n",
    "        accept_imbalanced=False,\n",
    "    )\n",
    "\n",
    "    # Split each partition into train/val and create DataLoader\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for ds in map(lambda p: Subset(trainset, p[0]), train_partitions):\n",
    "        len_val = len(ds) // 10  # 10 % validation set\n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator())\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
    "    return trainloaders, valloaders, testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2X3cVBXMpP6w",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def train(net, trainloader, epochs: int, lr: float = 0.1):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "    optimizer = torch.optim.SGD(\n",
    "        net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4\n",
    "    )\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss.item() * labels.size(0)\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "def test(net: nn.Module, testloader: DataLoader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test loss {loss}, accuracy {accuracy}\")\n",
    "    return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZH3f2rt7h-Ih",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class FlowerClient(PeerReviewClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net.to(DEVICE)\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def train(self, parameters, config):\n",
    "        print(\"training\")\n",
    "        # Read values from config\n",
    "        current_round = config[\"current_round\"]\n",
    "        local_epochs = config[\"local_epochs\"]\n",
    "        lr = config[\"lr\"]\n",
    "        # Use values provided by the config\n",
    "        print(f\"[Client {self.cid}, round {current_round}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, local_epochs)\n",
    "        print(\"trained\")\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def review(self, parameters, config):\n",
    "        print(\"reviewing\")\n",
    "        loss, num_examples, metrics = self.evaluate(parameters, config)\n",
    "        metrics[PrConfig.REVIEW_SCORE] = loss\n",
    "        print(\"reviewed\")\n",
    "        return [], num_examples, metrics\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPeFWwyFrY9f",
    "outputId": "ef5d5467-ac26-469c-b1ee-97f91ad2f34b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "62006\n"
     ]
    }
   ],
   "source": [
    "set_seed(SEED)\n",
    "\n",
    "# Load data\n",
    "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS, DATASET, 1 / 3, \"../../../\")\n",
    "NUM_CLASSES = len(np.unique(testloader.dataset.targets))\n",
    "\n",
    "# Create an instance of the model and get the parameters\n",
    "net = Net(NUM_CLASSES).to(DEVICE)\n",
    "params = get_parameters(net)\n",
    "print(sum(p.numel() for p in net.parameters() if p.requires_grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "9QP5CZ2yGXbb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SelectionCriterion(Criterion):\n",
    "    def __init__(self, cid: int):\n",
    "        self.cid = cid\n",
    "\n",
    "    def select(self, client: ClientProxy) -> bool:\n",
    "        return True if client.cid != self.cid else False\n",
    "\n",
    "\n",
    "class FedEs(PeerReviewStrategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        replay_buffer_maxsize: int = 10,\n",
    "        fraction_review: float = 0.1,\n",
    "        fraction_fit: float = 0.1,\n",
    "        fraction_eval: float = 0.1,\n",
    "        min_fit_clients: int = 2,\n",
    "        min_eval_clients: int = 2,\n",
    "        min_available_clients: int = 2,\n",
    "        eval_fn: Optional[\n",
    "            Callable[[Weights], Optional[Tuple[float, Dict[str, Scalar]]]]\n",
    "        ] = None,\n",
    "        on_review_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
    "        on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
    "        on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
    "        accept_failures: bool = True,\n",
    "        initial_parameters: Optional[Parameters] = None,\n",
    "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "    ) -> None:\n",
    "        self.current_loss: float = None\n",
    "        self.replay_buffer: List[Dict] = list()\n",
    "        self.replay_buffer_maxsize = replay_buffer_maxsize\n",
    "        self.fraction_review = fraction_review\n",
    "        self.on_review_config_fn = on_review_config_fn\n",
    "        self.fedavg = FedAvg(\n",
    "            fraction_fit=fraction_fit,\n",
    "            fraction_eval=fraction_eval,\n",
    "            min_fit_clients=min_fit_clients,\n",
    "            min_eval_clients=min_eval_clients,\n",
    "            min_available_clients=min_available_clients,\n",
    "            eval_fn=eval_fn,\n",
    "            on_fit_config_fn=on_fit_config_fn,\n",
    "            on_evaluate_config_fn=on_evaluate_config_fn,\n",
    "            accept_failures=accept_failures,\n",
    "            initial_parameters=initial_parameters,\n",
    "            fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,\n",
    "            evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def copy_extend_dict(source: Dict, extension: Dict):\n",
    "        new = deepcopy(source)\n",
    "        for key, val in extension.items():\n",
    "            new[key] = val\n",
    "        return new\n",
    "\n",
    "    def num_review_clients(self, num_available_clients: int):\n",
    "        \"\"\"Return the sample size and the required number of available\n",
    "        clients.\"\"\"\n",
    "        num_clients = int(num_available_clients * self.fraction_review)\n",
    "        return (\n",
    "            max(num_clients, self.fedavg.min_fit_clients),\n",
    "            self.fedavg.min_available_clients,\n",
    "        )\n",
    "\n",
    "    def add_to_replay_buffer(self, parameters: Parameters):\n",
    "        if self.replay_buffer_maxsize > len(self.replay_buffer):\n",
    "            self.replay_buffer.append({\"params\": parameters})\n",
    "        else:\n",
    "            self.replay_buffer.pop(0)\n",
    "            self.replay_buffer.append({\"params\": parameters})\n",
    "\n",
    "    # Standard strategy\n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        return self.fedavg.initialize_parameters(client_manager)\n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, rnd: int, parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        return self.fedavg.configure_evaluate(rnd, parameters, client_manager)\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        rnd: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: BaseException,\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        return self.fedavg.aggregate_evaluate(rnd, results, failures)\n",
    "\n",
    "    def evaluate(\n",
    "        self, parameters: Parameters\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        loss, metrics = self.fedavg.evaluate(parameters)\n",
    "        self.current_loss = loss\n",
    "        return loss, metrics\n",
    "\n",
    "    # Multiple reviews strategy\n",
    "    def configure_train(\n",
    "        self, rnd: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        print(\"configure_train\", flush=True)\n",
    "        return self.fedavg.configure_fit(rnd, parameters, client_manager)\n",
    "\n",
    "    def aggregate_train(\n",
    "        self,\n",
    "        rnd: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[BaseException],\n",
    "    ) -> List[Tuple[Optional[Parameters], Dict[str, Scalar]]]:\n",
    "        print(\"aggregate_train\", flush=True)\n",
    "        if not results:\n",
    "            return []\n",
    "        # Do not aggregate if there are failures and failures are not accepted\n",
    "        if not self.fedavg.accept_failures and failures:\n",
    "            return []\n",
    "        # Convert results\n",
    "        weights_aggregated = aggregate(\n",
    "            [\n",
    "                (parameters_to_weights(fit_res.parameters), fit_res.num_examples)\n",
    "                for _, fit_res in results\n",
    "            ]\n",
    "        )\n",
    "        print(weights_aggregated[-1])\n",
    "        return [(weights_to_parameters(weights_aggregated), {})]\n",
    "\n",
    "    def configure_review(\n",
    "        self,\n",
    "        rnd: int,\n",
    "        review_rnd: int,\n",
    "        parameters: Parameters,\n",
    "        client_manager: ClientManager,\n",
    "        parameters_aggregated: List[Optional[Parameters]],\n",
    "        metrics_aggregated: List[Dict[str, Scalar]],\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        print(\"configure_review\", flush=True)\n",
    "        # Do not configure federated review if fraction_review is 0\n",
    "        if self.fraction_review == 0.0:\n",
    "            return []\n",
    "        # Parameters and config\n",
    "        config = {}\n",
    "        if self.on_review_config_fn is not None:\n",
    "            # Custom fit config function provided\n",
    "            config = self.on_review_config_fn(rnd)\n",
    "        # Prepare review instructions\n",
    "        config_ins = self.copy_extend_dict(\n",
    "            config, {\"rnd\": rnd, \"review_rnd\": review_rnd, PrConfig.REVIEW_FLAG: True}\n",
    "        )\n",
    "        params = parameters_aggregated.pop(0)\n",
    "        review_ins = FitIns(params, config_ins)\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_review_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "        # Save parameters in replay buffer\n",
    "        self.add_to_replay_buffer(parameters_to_weights(params))\n",
    "        print(\"replay buffer size:\", len(self.replay_buffer))\n",
    "        # Return client/config pairs\n",
    "        return [(client, review_ins) for client in clients]\n",
    "\n",
    "    def aggregate_review(\n",
    "        self,\n",
    "        rnd: int,\n",
    "        review_rnd: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[BaseException],\n",
    "    ) -> List[Tuple[Optional[Parameters], Dict[str, Scalar]]]:\n",
    "        print(\"aggregate_review\", flush=True)\n",
    "        if not results:\n",
    "            return []\n",
    "        # Do not aggregate if there are failures and failures are not accepted\n",
    "        if not self.fedavg.accept_failures and failures:\n",
    "            return []\n",
    "        # Aggregate results\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (review_res.num_examples, review_res.metrics[PrConfig.REVIEW_SCORE])\n",
    "                for _, review_res in results\n",
    "            ]\n",
    "        )\n",
    "        self.replay_buffer[-1].setdefault(\"loss\", loss_aggregated)\n",
    "        return [(None, None)]\n",
    "\n",
    "    def aggregate_after_review(\n",
    "        self,\n",
    "        rnd: int,\n",
    "        parameters_aggregated: List[Optional[Parameters]],\n",
    "        metrics_aggregated: List[Dict[str, Scalar]],\n",
    "        parameters: Optional[Parameters],\n",
    "    ) -> Optional[Parameters]:\n",
    "        print(\"aggregate_after_review\", flush=True)\n",
    "        # Check passed arguments\n",
    "        assert parameters_aggregated[0] is None and len(parameters_aggregated) == 1\n",
    "        assert metrics_aggregated[0] is None and len(metrics_aggregated) == 1\n",
    "        \n",
    "        # Get weigths and losses\n",
    "        parameters = parameters_to_weights(parameters)\n",
    "        print(self.replay_buffer[0][\"params\"][-1])\n",
    "        weights_in_buffer = [record[\"params\"] for record in self.replay_buffer]\n",
    "        losses_in_buffer = [record[\"loss\"] for record in self.replay_buffer]\n",
    "        print(\"mean losses:\", losses_in_buffer)\n",
    "        N = len(self.replay_buffer)\n",
    "        print(\"replay buffer size:\", N)\n",
    "        \n",
    "        # Compute lr\n",
    "        eta = 1 / 2.302585093\n",
    "        print(\"lr:\", eta)\n",
    "        alpha = eta / N\n",
    "        \n",
    "        # Compute update\n",
    "        parameters_prime = deepcopy(parameters)\n",
    "        for i, weights in enumerate(weights_in_buffer):\n",
    "            for j, tensor in enumerate(weights):\n",
    "                parameters_prime[j] += alpha * (losses_in_buffer[i] - self.current_loss) * (tensor - parameters[j])\n",
    "        print(parameters[-1])\n",
    "        print(parameters_prime[-1])\n",
    "        \n",
    "        # Return\n",
    "        return weights_to_parameters(parameters_prime)\n",
    "\n",
    "    def stop_review(\n",
    "        self,\n",
    "        rnd: int,\n",
    "        review_rnd: int,\n",
    "        parameters: Parameters,\n",
    "        client_manager: ClientManager,\n",
    "        parameters_aggregated: List[Optional[Parameters]],\n",
    "        metrics_aggregated: List[Dict[str, Scalar]],\n",
    "    ) -> bool:\n",
    "        print(\"stop_review\", flush=True)\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62006,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(list(map(lambda t: t.flatten(), params))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from prflwr.peer_reviewed import prserver\n",
    "reload(prserver)\n",
    "from prflwr.peer_reviewed.prserver import PeerReviewServer\n",
    "from prflwr.peer_reviewed import prclient\n",
    "reload(prclient)\n",
    "from prflwr.peer_reviewed.prclient import PeerReviewClient\n",
    "from prflwr.peer_reviewed.strategies import prfedavg\n",
    "reload(prfedavg)\n",
    "from prflwr.peer_reviewed.strategies.prfedavg import PeerReviewedFedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "xfZ5cDTNF_WC",
    "outputId": "fecb9d61-8061-4ebd-c2a6-c390b745634e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-06-05 16:02:17,390 | app.py:135 | Ray initialized with resources: {'CPU': 8.0, 'node:127.0.0.1': 1.0, 'object_store_memory': 981633024.0, 'memory': 1963266048.0}\n",
      "INFO flower 2022-06-05 16:02:17,391 | app.py:151 | Starting Flower simulation running: Config(num_rounds=3, round_timeout=None)\n",
      "INFO flower 2022-06-05 16:02:17,391 | prserver.py:86 | Initializing global parameters\n",
      "INFO flower 2022-06-05 16:02:17,393 | server.py:252 | Using initial parameters provided by strategy\n",
      "INFO flower 2022-06-05 16:02:17,393 | prserver.py:88 | Evaluating initial parameters\n",
      "INFO flower 2022-06-05 16:02:20,791 | prserver.py:91 | initial parameters (loss, other metrics): 2.3050458293914793, {'accuracy': 0.1011}\n",
      "INFO flower 2022-06-05 16:02:20,792 | prserver.py:47 | FL starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 2.3050458293914793, accuracy 0.1011\n",
      "configure_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-05 16:02:20,794 | prserver.py:189 | train_round: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n",
      "training\n",
      "[Client 3, round 1] fit, config: {'current_round': 1, 'local_epochs': 1, 'lr': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n",
      "DEBUG flower 2022-06-05 16:02:32,696 | prserver.py:202 | train_round received 1 results and 2 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss 1.4552568594614665, accuracy 0.4216888888888889\n",
      "trained\n",
      "aggregate_train\n",
      "[ 0.76347214  0.2699653  -0.2676705  -0.7569819   1.3095396   1.2966262\n",
      " -0.7448482  -0.7922462  -0.8562691  -0.31524324]\n",
      "configure_review\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-05 16:02:32,708 | prserver.py:251 | review_round: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replay buffer size: 1\n",
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewing\n",
      "[Client 0] evaluate, config: {'rnd': 1, 'review_rnd': 1, 'review': True}\n",
      "Test loss 7.08559429397583, accuracy 0.1024\n",
      "reviewed\n",
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n",
      "reviewing\n",
      "[Client 1] evaluate, config: {'rnd': 1, 'review_rnd': 1, 'review': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n",
      "DEBUG flower 2022-06-05 16:02:41,407 | prserver.py:264 | review_round received 2 results and 3 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 5.091607949066162, accuracy 0.0712\n",
      "reviewed\n",
      "aggregate_review\n",
      "stop_review\n",
      "aggregate_after_review\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-05 16:02:41,418 | prserver.py:122 | updated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.76347214  0.2699653  -0.2676705  -0.7569819   1.3095396   1.2966262\n",
      " -0.7448482  -0.7922462  -0.8562691  -0.31524324]\n",
      "mean losses: [6.0886011215209965]\n",
      "replay buffer size: 1\n",
      "lr: 0.4342944819021288\n",
      "[ 0.00508047 -0.07531627 -0.04354333  0.1037055   0.07243552 -0.07773241\n",
      "  0.098202   -0.09954937 -0.1017308   0.02100436]\n",
      "[ 1.2512523   0.49204248 -0.411824   -1.3105564   2.1052167   2.1805825\n",
      " -1.2870789  -1.2377731  -1.341571   -0.53151   ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-06-05 16:02:45,498 | prserver.py:132 | fit progress: (1, 19.08459862060547, {'accuracy': 0.1648}, 24.705185413360596)\n",
      "INFO flower 2022-06-05 16:02:45,499 | server.py:155 | evaluate_round: no clients selected, cancel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 19.08459862060547, accuracy 0.1648\n",
      "configure_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-05 16:02:45,500 | prserver.py:189 | train_round: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n",
      "training\n",
      "[Client 0, round 2] fit, config: {'current_round': 2, 'local_epochs': 1, 'lr': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n",
      "DEBUG flower 2022-06-05 16:03:00,493 | prserver.py:202 | train_round received 1 results and 2 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss 2.1815696652730305, accuracy 0.3608\n",
      "trained\n",
      "aggregate_train\n",
      "[ 0.5495235  -0.816131   -1.1917092   2.6052225   0.32917452  0.65393096\n",
      " -1.7426553  -1.7512741   2.639374   -1.3631262 ]\n",
      "configure_review\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-05 16:03:00,502 | prserver.py:251 | review_round: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replay buffer size: 2\n",
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewingreviewing\n",
      "[Client 2] evaluate, config: {'rnd': 2, 'review_rnd': 1, 'review': True}\n",
      "reviewing\n",
      "[Client 1] evaluate, config: {'rnd': 2, 'review_rnd': 1, 'review': True}\n",
      "\n",
      "[Client 0] evaluate, config: {'rnd': 2, 'review_rnd': 1, 'review': True}\n",
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewing\n",
      "[Client 3] evaluate, config: {'rnd': 2, 'review_rnd': 1, 'review': True}\n",
      "Test loss 4.352163667297363, accuracy 0.0\n",
      "reviewed\n",
      "Test loss 5.237857759857178, accuracy 0.0\n",
      "reviewed\n",
      "Test loss 3.529428156661987, accuracy 0.0\n",
      "reviewed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-05 16:03:55,708 | prserver.py:264 | review_round received 4 results and 1 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 1.4228649824142456, accuracy 0.416\n",
      "reviewed\n",
      "aggregate_review\n",
      "stop_review\n",
      "aggregate_after_review\n",
      "[ 0.76347214  0.2699653  -0.2676705  -0.7569819   1.3095396   1.2966262\n",
      " -0.7448482  -0.7922462  -0.8562691  -0.31524324]\n",
      "mean losses: [6.0886011215209965, 3.635578641557694]\n",
      "replay buffer size: 2\n",
      "lr: 0.2171472409510644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-05 16:03:57,686 | prserver.py:122 | updated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.2512523   0.49204248 -0.411824   -1.3105564   2.1052167   2.1805825\n",
      " -1.2870789  -1.2377731  -1.341571   -0.53151   ]\n",
      "[  4.981888     5.5072994    1.7976584  -16.009079    10.3087635\n",
      "   9.796623    -1.2889507   -0.77242184 -16.066038     1.6480083 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-06-05 16:04:01,464 | prserver.py:132 | fit progress: (2, 185257835154.6368, {'accuracy': 0.1}, 100.67142939567566)\n",
      "INFO flower 2022-06-05 16:04:01,466 | server.py:155 | evaluate_round: no clients selected, cancel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 185257835154.6368, accuracy 0.1\n",
      "configure_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-05 16:04:01,468 | prserver.py:189 | train_round: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n",
      "training\n",
      "[Client 3, round 3] fit, config: {'current_round': 3, 'local_epochs': 1, 'lr': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n",
      ":task_name:launch_and_fit\n",
      "DEBUG flower 2022-06-05 16:04:17,346 | prserver.py:202 | train_round received 1 results and 2 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss 4.924054049558557e+28, accuracy 0.30462222222222224\n",
      "trained\n",
      "aggregate_train\n",
      "[  6.2897      6.777806    3.2472708 -15.386651    5.542212    5.854468\n",
      "  -1.2435082  -0.7501158 -15.441397    5.017713 ]\n",
      "configure_review\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-06-05 16:04:17,357 | prserver.py:251 | review_round: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replay buffer size: 3\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net(NUM_CLASSES).to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    weights: fl.common.Weights,\n",
    ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
    "    net = Net(NUM_CLASSES).to(DEVICE)\n",
    "    set_parameters(net, weights)  # Update model with the latest parameters\n",
    "    loss, accuracy = test(net, testloader)\n",
    "    return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "def fit_config(rnd: int):\n",
    "    lr = LR\n",
    "    if MILESTONES is not None and LR_DECAY is not None:\n",
    "        lr *= LR_DECAY ** sum([1 if rnd >= e else 0 for e in MILESTONES])\n",
    "    config = {\n",
    "        \"current_round\": rnd,\n",
    "        \"local_epochs\": 1 if rnd < 2 else LOCAL_EPOCHS,\n",
    "        \"lr\": lr\n",
    "    }\n",
    "    return config\n",
    "\n",
    "\n",
    "strategy = FedEs(\n",
    "    fraction_review=FRACTION_REV,\n",
    "    fraction_fit=FRACTION_FIT,\n",
    "    fraction_eval=FRACTION_EVAL,\n",
    "    min_fit_clients=int(FRACTION_FIT * NUM_CLIENTS),\n",
    "    min_eval_clients=int(FRACTION_EVAL * NUM_CLIENTS),\n",
    "    min_available_clients=NUM_CLIENTS,\n",
    "    initial_parameters=fl.common.weights_to_parameters(get_parameters(net)),\n",
    "    on_fit_config_fn=fit_config,\n",
    "    eval_fn=evaluate,\n",
    ")\n",
    "\"\"\"strategy = PeerReviewedFedAvg(\n",
    "    fraction_review=1,\n",
    "    fraction_fit=1,\n",
    "    fraction_eval=1,\n",
    "    min_fit_clients=1,\n",
    "    min_eval_clients=1,\n",
    "    min_available_clients=NUM_CLIENTS,\n",
    "    initial_parameters=fl.common.weights_to_parameters(get_parameters(net)),\n",
    "    on_fit_config_fn=fit_config,\n",
    "    eval_fn=evaluate,\n",
    ")\"\"\"\n",
    "client_manager = SimpleClientManager()\n",
    "\n",
    "start_simulation(\n",
    "    server=PeerReviewServer(client_manager, strategy),\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    num_rounds=NUM_ROUNDS,\n",
    "    strategy=strategy,\n",
    "    client_manager=client_manager,\n",
    "    client_resources={\"num_cpus\": 1, \"num_gpus\": 1},\n",
    "    ray_init_args={\"local_mode\": True, \"include_dashboard\": False}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sim_fedes_gpu",
   "provenance": []
  },
  "interpreter": {
   "hash": "567eb23278dc48458ee3370825b5f7f3a84494f863de725a2aacc447ea9c55e5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}