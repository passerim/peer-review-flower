{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eTrCL2FmC5U5",
    "outputId": "939ed4cb-4c86-49d3-8e0b-fb45e55f756b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MetBook\\Documents\\UNIVERSITA\\MAGISTRALE\\SD21\\PROGETTO\\FLWR\\peer_reviewed_fl\\envs\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'flwr.dataset.utils.common' from 'c:\\\\Users\\\\MetBook\\\\Documents\\\\UNIVERSITA\\\\MAGISTRALE\\\\SD21\\\\PROGETTO\\\\FLWR\\\\peer_reviewed_fl\\\\envs\\\\lib\\\\site-packages\\\\flwr\\\\dataset\\\\utils\\\\common.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import os\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torchvision import datasets\n",
    "\n",
    "importlib.import_module(\".common\", \"flwr.dataset.utils\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4bKI8oK2Ubx",
    "outputId": "839690a3-d10d-40ca-8908-aebd973448a4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"CIFAR10\"  # possible values: \"CIFAR10\" or \"CIFAR100\"\n",
    "NUM_CLIENTS = 50\n",
    "NUM_ROUNDS = 10\n",
    "LOCAL_EPOCHS = 2\n",
    "BATCH_SIZE = 128\n",
    "LR = 0.1\n",
    "MILESTONES = [60, 120, 160]\n",
    "LR_DECAY = 0.2\n",
    "W_DECAY = 5e-04\n",
    "FRACTION_FIT = 1 / 3\n",
    "FRACTION_EVAL = 0\n",
    "SEED = 0\n",
    "# Set the start method for multiprocessing in case Python version is under 3.8.1\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BpLBow6s-CNy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "J4Em7BPNTXeX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_datasets(num_clients: int, dataset: str = \"CIFAR10\", src: str = \".\"):\n",
    "    if dataset not in [\"CIFAR10\", \"CIFAR100\"]:\n",
    "        raise ValueError(\n",
    "            \"Unknown dataset! Admissible values are: 'CIFAR10' or 'CIFAR100'.\"\n",
    "        )\n",
    "    # Download and transform CIFAR dataset (train and test)\n",
    "    augmentation = [\n",
    "        transforms.Pad(4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32),\n",
    "    ]\n",
    "    transform = [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    "    trainset = getattr(datasets, dataset)(\n",
    "        os.path.join(src, \"./data\"),\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([*augmentation, *transform]),\n",
    "    )\n",
    "    testset = getattr(datasets, dataset)(\n",
    "        os.path.join(src, \"./data\"),\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(transform),\n",
    "    )\n",
    "\n",
    "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
    "    targets = np.array(trainset.targets)\n",
    "    idxs = np.array(range(len(targets)))\n",
    "    dataset = [idxs, targets]\n",
    "    train_partitions, _ = fl.dataset.utils.common.create_lda_partitions(\n",
    "        dataset,\n",
    "        num_partitions=NUM_CLIENTS,\n",
    "        concentration=1 / 3,\n",
    "        accept_imbalanced=False,\n",
    "    )\n",
    "\n",
    "    # Split each partition into train/val and create DataLoader\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for ds in map(lambda p: Subset(trainset, p[0]), train_partitions):\n",
    "        len_val = len(ds) // 10  # 10 % validation set\n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator())\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
    "    return trainloaders, valloaders, testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2X3cVBXMpP6w",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def train(net, trainloader, epochs: int, lr: float = 0.1):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "    optimizer = torch.optim.SGD(\n",
    "        net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4\n",
    "    )\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss.item() * labels.size(0)\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "def test(net: nn.Module, testloader: DataLoader, return_dict=None):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZH3f2rt7h-Ih",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net.to(DEVICE)\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        # Read values from config\n",
    "        current_round = config[\"current_round\"]\n",
    "        local_epochs = config[\"local_epochs\"]\n",
    "        lr = config[\"lr\"]\n",
    "        # Use values provided by the config\n",
    "        print(f\"[Client {self.cid}, round {current_round}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, local_epochs)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPeFWwyFrY9f",
    "outputId": "70fec6d8-5ea9-4722-b57c-1491b9a8889a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../../.././data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170499072it [00:30, 5608281.93it/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../.././data\\cifar-10-python.tar.gz to ../../.././data\n",
      "Files already downloaded and verified\n",
      "62006\n"
     ]
    }
   ],
   "source": [
    "set_seed(SEED)\n",
    "\n",
    "# Load data\n",
    "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS, DATASET, \"../../../\")\n",
    "NUM_CLASSES = len(np.unique(testloader.dataset.targets))\n",
    "\n",
    "# Create an instance of the model and get the parameters\n",
    "net = Net(NUM_CLASSES).to(DEVICE)\n",
    "params = get_parameters(net)\n",
    "print(sum(p.numel() for p in net.parameters() if p.requires_grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zVTrw7OsttE7",
    "outputId": "4a91290f-177e-4b9d-82a1-dee0e58df6c8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-06-02 23:42:41,003 | app.py:155 | Ray initialized with resources: {'object_store_memory': 191444582.0, 'CPU': 8.0, 'memory': 382889166.0, 'GPU': 1.0, 'node:127.0.0.1': 1.0}\n",
      "INFO flower 2022-06-02 23:42:41,007 | app.py:171 | Starting Flower simulation running: Config(num_rounds=10, round_timeout=None)\n",
      "INFO flower 2022-06-02 23:42:41,016 | server.py:84 | Initializing global parameters\n",
      "INFO flower 2022-06-02 23:42:41,018 | server.py:252 | Using initial parameters provided by strategy\n",
      "INFO flower 2022-06-02 23:42:41,022 | server.py:86 | Evaluating initial parameters\n"
     ]
    }
   ],
   "source": [
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net(NUM_CLASSES).to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    weights: fl.common.Weights,\n",
    ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
    "    net = Net(NUM_CLASSES).to(DEVICE)\n",
    "    set_parameters(net, weights)  # Update model with the latest parameters\n",
    "    loss, accuracy = test(net, testloader)\n",
    "    return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "def fit_config(rnd: int):\n",
    "    lr = LR\n",
    "    if MILESTONES is not None and LR_DECAY is not None:\n",
    "        lr *= LR_DECAY ** sum([1 if rnd >= e else 0 for e in MILESTONES])\n",
    "    config = {\n",
    "        \"current_round\": rnd,\n",
    "        \"local_epochs\": 1 if rnd < 2 else LOCAL_EPOCHS,\n",
    "        \"lr\": lr,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=FRACTION_FIT,\n",
    "    fraction_eval=FRACTION_EVAL,\n",
    "    min_fit_clients=int(FRACTION_FIT * NUM_CLIENTS),\n",
    "    min_eval_clients=int(FRACTION_EVAL * NUM_CLIENTS),\n",
    "    min_available_clients=NUM_CLIENTS,\n",
    "    initial_parameters=fl.common.weights_to_parameters(get_parameters(net)),\n",
    "    on_fit_config_fn=fit_config,\n",
    "    eval_fn=evaluate,\n",
    ")\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    num_rounds=10,\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 1, \"num_gpus\": 1},\n",
    "    ray_init_args={\"local_mode\": True, \"include_dashboard\": False},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sim_fedavg_gpu",
   "provenance": []
  },
  "interpreter": {
   "hash": "567eb23278dc48458ee3370825b5f7f3a84494f863de725a2aacc447ea9c55e5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}