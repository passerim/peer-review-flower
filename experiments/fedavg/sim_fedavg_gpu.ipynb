{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install flwr[\"simulation\"]==0.19"
   ],
   "metadata": {
    "id": "h2-VkSGHJIT_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTrCL2FmC5U5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torchvision import datasets\n",
    "\n",
    "import os\n",
    "import random\n",
    "import importlib\n",
    "importlib.import_module(\".common\", \"flwr.dataset.utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpLBow6s-CNy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i4bKI8oK2Ubx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setting random seed for reproducibility\n",
    "SEED = 123\n",
    "set_seed(SEED)\n",
    "\n",
    "# Experimental settings\n",
    "DATASET = \"CIFAR10\"  # possible values: \"CIFAR10\" or \"CIFAR100\"\n",
    "NUM_EPOCHS = 50\n",
    "NUM_CLIENTS = 50\n",
    "LOCAL_EPOCHS = 2\n",
    "BATCH_SIZE = 32\n",
    "FRACTION_FIT = 1/4\n",
    "FRACTION_EVAL = 0\n",
    "NUM_ROUNDS = int(NUM_EPOCHS / (LOCAL_EPOCHS * FRACTION_FIT) + 0.5)\n",
    "\n",
    "# Device to use for training and evaluation\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "print(f\"Training on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4Em7BPNTXeX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_datasets(\n",
    "    num_clients: int, \n",
    "    dataset: str = \"CIFAR10\",\n",
    "    src: str = \".\",\n",
    "    iid: bool = True,\n",
    "    concentration: float = 1,\n",
    "    use_augmentation: bool = False\n",
    ") -> Tuple[List[DataLoader], List[DataLoader], DataLoader]:\n",
    "    if dataset not in [\"CIFAR10\", \"CIFAR100\"]:\n",
    "        raise ValueError(\n",
    "            \"Unknown dataset! Admissible values are: 'CIFAR10' or 'CIFAR100'.\"\n",
    "        )\n",
    "\n",
    "    # Download and transform CIFAR dataset (train and test)\n",
    "    augmentation = [\n",
    "        transforms.Pad(4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32),\n",
    "    ] if use_augmentation else []\n",
    "    transform = [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    "    trainset = getattr(datasets, dataset)(\n",
    "        os.path.join(src, \"./data\"),\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([*augmentation, *transform]),\n",
    "    )\n",
    "    testset = getattr(datasets, dataset)(\n",
    "        os.path.join(src, \"./data\"),\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([*transform]),\n",
    "    )\n",
    "\n",
    "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
    "    if not iid:\n",
    "        targets = np.array(trainset.targets)\n",
    "        idxs = np.array(range(len(targets)))\n",
    "        dataset = [idxs, targets]\n",
    "        train_partitions, _ = fl.dataset.utils.common.create_lda_partitions(\n",
    "            dataset,\n",
    "            num_partitions=num_clients,\n",
    "            concentration=concentration,\n",
    "            accept_imbalanced=False,\n",
    "        )\n",
    "        subsets = list(map(lambda p: Subset(trainset, p[0]), train_partitions))\n",
    "    else:\n",
    "        partition_size = len(trainset) // num_clients\n",
    "        lengths = [partition_size] * num_clients\n",
    "        subsets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "    # Split each partition into train/val and create DataLoader\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for ds in subsets:\n",
    "        len_val = len(ds) // 10  # 10 % validation set\n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
    "    return trainloaders, valloaders, testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2X3cVBXMpP6w",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(512, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 512)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss.item() * labels.size(0)\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= total\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "def test(net: nn.Module, testloader: DataLoader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= total\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZH3f2rt7h-Ih",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        # Read values from config\n",
    "        current_round = config[\"current_round\"]\n",
    "        local_epochs = config[\"local_epochs\"]\n",
    "        # Use values provided by the config\n",
    "        print(f\"[Client {self.cid}, round {current_round}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, local_epochs)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPeFWwyFrY9f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS, DATASET)\n",
    "NUM_CLASSES = len(np.unique(testloader.dataset.targets))\n",
    "\n",
    "# Create an instance of the model\n",
    "net = Net(NUM_CLASSES).to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    assert net(torch.randn((3, 32, 32), device=DEVICE)).shape == torch.Size([1, NUM_CLASSES])\n",
    "\n",
    "# Print some stats about the model and the data\n",
    "print(\"Model parameters:\", sum(p.numel() for p in net.parameters() if p.requires_grad))\n",
    "print(\"Client's trainset size:\", len(trainloaders[0].dataset))\n",
    "print(\"Client's validation set size:\", len(valloaders[0].dataset))\n",
    "print(\"Server's testset size:\", len(testloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVTrw7OsttE7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net(NUM_CLASSES).to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    weights: fl.common.Weights,\n",
    ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
    "    net = Net(NUM_CLASSES).to(DEVICE)\n",
    "    set_parameters(net, weights)  # Update model with the latest parameters\n",
    "    loss, accuracy = test(net, testloader)\n",
    "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
    "    return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "def fit_config(rnd: int):\n",
    "    \"\"\"Return training configuration dict for each round.\n",
    "    \n",
    "    Perform two rounds of training with one local epoch, increase to two local\n",
    "    epochs afterwards.\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        \"current_round\": rnd,  # The current round of federated learning\n",
    "        \"local_epochs\": 1 if rnd < 2 else LOCAL_EPOCHS,  # \n",
    "    }\n",
    "    return config\n",
    "\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=FRACTION_FIT,\n",
    "    fraction_eval=FRACTION_EVAL,\n",
    "    min_fit_clients=int(FRACTION_FIT * NUM_CLIENTS),\n",
    "    min_eval_clients=int(FRACTION_EVAL * NUM_CLIENTS),\n",
    "    min_available_clients=NUM_CLIENTS,\n",
    "    initial_parameters=fl.common.weights_to_parameters(get_parameters(net)),\n",
    "    on_fit_config_fn=fit_config,\n",
    "    eval_fn=evaluate,\n",
    ")\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    num_rounds=NUM_ROUNDS,\n",
    "    strategy=strategy,\n",
    "    client_resources={\"num_cpus\": 1, \"num_gpus\": (1 if torch.cuda.is_available() else 0)},\n",
    "    ray_init_args={\"local_mode\": True, \"include_dashboard\": False},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sim_fedavg_gpu.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "567eb23278dc48458ee3370825b5f7f3a84494f863de725a2aacc447ea9c55e5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}