{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cz71fPGrpRiQ"
      },
      "source": [
        "# **Federated Learning with (PeerReview)Flower and FedAvg**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D4KiTMTpiort"
      },
      "source": [
        "### Installing dependencies\n",
        "\n",
        "First of all, we install the necessary packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PAxbNFt6in6"
      },
      "outputs": [],
      "source": [
        "# Multiple ways to import prflwr whether it is installed\n",
        "# as a Python module, in a Colab environment or if source\n",
        "# code is in a parent directory for local development.\n",
        "def import_prflwr():\n",
        "    import os\n",
        "    try: import prflwr; return\n",
        "    except: pass\n",
        "    if \"setup.py\" in os.listdir(\"../..\"):\n",
        "        os.chdir(\"../..\")\n",
        "        try: import prflwr\n",
        "        except: pass\n",
        "        finally: os.chdir(\"experiments/fedls\")\n",
        "        if prflwr: return\n",
        "    try:\n",
        "        import google.colab\n",
        "        os.system(\n",
        "            \"pip install git+https://github.com/passerim/peer-review-flower.git\"\n",
        "        )\n",
        "        import prflwr; return\n",
        "    except: raise ModuleNotFoundError(\"No module named 'prflwr'\")\n",
        "\n",
        "\n",
        "import_prflwr()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "abtAKdBl6in6"
      },
      "source": [
        "Now that we have all dependencies installed, we can import everything we need for this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTrCL2FmC5U5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import flwr as fl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from prflwr.simulation import start_simulation\n",
        "from prflwr.utils import non_iid_partitions\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "from torchvision import transforms"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TllM4BjqxRrG"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Set useful constants, experiments settings and random seed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RV_Mu96KhHBu"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxsPYpBPhOvN",
        "outputId": "7c6cdfa7-977d-4001-8011-89e32a10efd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 30 rounds\n",
            "Training on cpu\n"
          ]
        }
      ],
      "source": [
        "# Setting random seed for reproducibility\n",
        "SEED = 123\n",
        "set_seed(SEED)\n",
        "\n",
        "# Experimental settings\n",
        "DATASET = \"CIFAR10\"  # admissible values: \"CIFAR10\" or \"CIFAR100\"\n",
        "NUM_ROUNDS = 30\n",
        "NUM_CLIENTS = 100\n",
        "LOCAL_EPOCHS = 5\n",
        "BATCH_SIZE = 25\n",
        "FRACTION_FIT = 0.1\n",
        "FRACTION_EVAL = 0  # Model performance will be evaluated in a centralized way\n",
        "print(f\"Training for {NUM_ROUNDS} rounds\")\n",
        "\n",
        "# Device to use for training and evaluation\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "print(f\"Training on {DEVICE}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JVcgAAiaihnx"
      },
      "source": [
        "## Data loading\n",
        "\n",
        "Let's now load the CIFAR-10 (or CIFAR-100) training and test set, partition them into `NUM_CLIENTS` smaller datasets (each split into training and validation set) and wrap everything in their own `DataLoader`. Test data will be used to evaluate the performance of the model in a centralized way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4Em7BPNTXeX",
        "outputId": "ecf2537e-7e0b-4cc8-a92f-546bd7018583"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 100211577.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "def load_datasets(\n",
        "    num_clients: int,\n",
        "    dataset: str = \"CIFAR10\",\n",
        "    src: str = \"./data\",\n",
        "    iid: bool = True,\n",
        "    concentration: float = 1,\n",
        "    use_augmentation: bool = True,\n",
        ") -> Tuple[List[DataLoader], List[DataLoader], DataLoader]:\n",
        "    if dataset not in [\"CIFAR10\", \"CIFAR100\"]:\n",
        "        raise ValueError(\n",
        "            \"Unknown dataset! Admissible values are: 'CIFAR10' or 'CIFAR100'.\"\n",
        "        )\n",
        "\n",
        "    # Download and transform CIFAR dataset (train and test)\n",
        "    augmentation = (\n",
        "        [\n",
        "            transforms.RandomCrop(24),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "        ]\n",
        "        if use_augmentation\n",
        "        else []\n",
        "    )\n",
        "    transform = [\n",
        "        transforms.CenterCrop(24),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ]\n",
        "    trainset = getattr(torchvision.datasets, dataset)(\n",
        "        src,\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([*augmentation, *transform]),\n",
        "    )\n",
        "    testset = getattr(torchvision.datasets, dataset)(\n",
        "        src,\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([*transform]),\n",
        "    )\n",
        "\n",
        "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
        "    if not iid:\n",
        "        targets = np.array(trainset.targets)\n",
        "        idxs = np.array(range(len(targets)))\n",
        "        dataset = [idxs, targets]\n",
        "        train_partitions = non_iid_partitions(\n",
        "            dataset,\n",
        "            num_partitions=num_clients,\n",
        "            concentration=concentration,\n",
        "        )\n",
        "        subsets = list(map(lambda p: Subset(trainset, p), train_partitions))\n",
        "    else:\n",
        "        partition_size = len(trainset) // num_clients\n",
        "        lengths = [partition_size] * num_clients\n",
        "        subsets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in subsets:\n",
        "        len_val = len(ds) // 10  #  use 10% of client's data as validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OBp7kB4G0sPB"
      },
      "source": [
        "## Model training/evaluation\n",
        "\n",
        "Let's continue with the usual model definition (including `set_parameters` and `get_parameters`), training and test functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2X3cVBXMpP6w"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes: int) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 8, 5, 1, 1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(8, 16, 5, 1, 1)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def train(net, trainloader, optimizer, epochs=1, verbose=True):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    net.train()\n",
        "    device = next(net.parameters()).device\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for batch, (images, labels) in enumerate(trainloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= batch + 1\n",
        "        epoch_acc = correct / total\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, train accuracy {epoch_acc}\")\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the test set.\"\"\"\n",
        "    net.eval()\n",
        "    device = next(net.parameters()).device\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch, (images, labels) in enumerate(testloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= batch + 1\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FZlzx1tbdnGz"
      },
      "source": [
        "Let's check model's correctness, then print some info about the datasets and splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQmFLwyrcZ4U",
        "outputId": "81c60b3b-e2a5-4b49-d887-2b536e5818bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model parameters: 45626\n",
            "Client's trainset size: 450\n",
            "Client's validation set size: 50\n",
            "Server's testset size: 10000\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of the model\n",
        "NUM_CLASSES = len(np.unique(testloader.dataset.targets))\n",
        "net = Net(NUM_CLASSES).to(DEVICE)\n",
        "with torch.no_grad():\n",
        "    assert net(torch.randn((3, 24, 24), device=DEVICE)).shape == torch.Size(\n",
        "        [1, NUM_CLASSES]\n",
        "    )\n",
        "\n",
        "# Print some stats about the model and the data\n",
        "print(\"Model parameters:\", sum(p.numel() for p in net.parameters() if p.requires_grad))\n",
        "print(\"Client's trainset size:\", len(trainloaders[0].dataset))\n",
        "print(\"Client's validation set size:\", len(valloaders[0].dataset))\n",
        "print(\"Server's testset size:\", len(testloader.dataset))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-yW_cnCapDN9"
      },
      "source": [
        "## Flower client\n",
        "\n",
        "To implement the Flower client, we create a subclass of `flwr.client.NumPyClient` and implement the three methods `get_parameters`, `fit`, and `evaluate`. Here, we also pass the `cid` to the client and use it to log additional details."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1lCf3oljdClM"
      },
      "source": [
        "### Sending/receiving arbitrary values to/from clients\n",
        "\n",
        "In some situations, we want to dinamically configure client side training and evaluation from the server-side, for example by setting the learning rate or the local epochs. Flower provides a way to send configuration values from the server to the clients using a dictionary. Clients receive values from the server through the `config` parameter and can read values from this dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZH3f2rt7h-Ih"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        # Read values from config\n",
        "        server_round = config[\"server_round\"]\n",
        "        local_epochs = config[\"local_epochs\"]\n",
        "        # Use values provided by the config\n",
        "        print(f\"[Client {self.cid}, round {server_round}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        optimizer = torch.optim.Adam(self.net.parameters())\n",
        "        train(self.net, self.trainloader, optimizer, local_epochs)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    net = Net(NUM_CLASSES).to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F8eKOYYsix3W"
      },
      "source": [
        "We can send the config dictionary from the server to the clients providing a function to the strategy that gets called every round of federated learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlqLKGdJgVRg"
      },
      "outputs": [],
      "source": [
        "def fit_config(server_round: int):\n",
        "    config = {\n",
        "        \"server_round\": server_round,  # The current round of federated learning\n",
        "        \"local_epochs\":  LOCAL_EPOCHS,\n",
        "    }\n",
        "    return config"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "axzXSMtlfhXU"
      },
      "source": [
        "## Customizing the FedAvg strategy\n",
        "\n",
        "The strategy encapsulates the federated learning algorithm, in this notebook we will use the standard version of FedAvg. We will also customize the parameters initilization of the global model and the centralized model evaluation."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "p6FHRf8HrbzV"
      },
      "source": [
        "### Server-side parameter **initialization**\n",
        "\n",
        "Flower, by default, initializes the global model by asking one random client for the initial parameters, however when more control on the initialization is needed passing `initial_parameters` to the `FedAvg` strategy prevents Flower from asking one of the clients for the initial parameters and allows the developer to set custom parameters for the initial model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50Y2yxJOjw4z"
      },
      "outputs": [],
      "source": [
        "initial_parameters = fl.common.ndarrays_to_parameters(get_parameters(Net(NUM_CLASSES)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wt3_SmQKnpRO"
      },
      "source": [
        "### Server-side parameter **evaluation**\n",
        "\n",
        "With Flower, we can evaluate the aggregated model on the server-side or on the client-side. Centralized evaluation is conceptually simpler: if there is a server-side dataset that can be used for evaluation purposes, then we can evaluate the newly aggregated model after each round of training without having to send the model to clients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDovnUvsn7if"
      },
      "outputs": [],
      "source": [
        "# The `evaluate` function will be called by Flower after every round\n",
        "def evaluate(\n",
        "    server_round: int, parameters: fl.common.NDArrays, config: Dict[str, fl.common.Scalar]\n",
        ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "    net = Net(NUM_CLASSES).to(DEVICE)\n",
        "    set_parameters(net, parameters)  # Update model with the latest parameters\n",
        "    loss, accuracy = test(net, testloader)\n",
        "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
        "    return loss, {\"accuracy\": accuracy}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "POBApsmwuCx2"
      },
      "source": [
        "## Running federated learning\n",
        "\n",
        "Let's run a federated learning experiment with a large number of clients. We have 100 partitions, each holding 450 training and 50 validation examples. We configure the clients to perform 5 local training epochs. The federated learning simulation is started by the function `start_simulation`, in this case we will use the concurrent simulation implemented in PeerReviewFlower. The `start_simulation` function accepts a number of arguments:\n",
        "* `client_fn` is used to create `FlowerClient` instances,\n",
        "* the number of clients to simulate is specified by `num_clients`,\n",
        "* the number of rounds `num_rounds` is encapsulated in a `flwr.server.ServerConfig`,\n",
        "* `strategy` is used to specify the custom strategy we configured above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVTrw7OsttE7",
        "outputId": "552dc4c2-40c6-4486-e959-74719d4384db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:09:42,903 | app.py:69 | Starting Flower simulation, config: ServerConfig(num_rounds=30, round_timeout=None)\n",
            "INFO:flower:Starting Flower simulation, config: ServerConfig(num_rounds=30, round_timeout=None)\n",
            "INFO flower 2023-05-25 22:09:43,307 | server.py:86 | Initializing global parameters\n",
            "INFO:flower:Initializing global parameters\n",
            "INFO flower 2023-05-25 22:09:43,314 | server.py:266 | Using initial parameters provided by strategy\n",
            "INFO:flower:Using initial parameters provided by strategy\n",
            "INFO flower 2023-05-25 22:09:43,323 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flower:Evaluating initial parameters\n",
            "INFO flower 2023-05-25 22:09:51,612 | server.py:91 | initial parameters (loss, other metrics): 2.3038880437612534, {'accuracy': 0.1018}\n",
            "INFO:flower:initial parameters (loss, other metrics): 2.3038880437612534, {'accuracy': 0.1018}\n",
            "INFO flower 2023-05-25 22:09:51,619 | server.py:101 | FL starting\n",
            "INFO:flower:FL starting\n",
            "DEBUG flower 2023-05-25 22:09:51,625 | server.py:215 | fit_round 1: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 1: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 2.3038880437612534 / accuracy 0.1018\n",
            "[Client 6, round 1] fit, config: {'server_round': 1, 'local_epochs': 5}\n",
            "[Client 34, round 1] fit, config: {'server_round': 1, 'local_epochs': 5}\n",
            "[Client 11, round 1] fit, config: {'server_round': 1, 'local_epochs': 5}\n",
            "[Client 98, round 1] fit, config: {'server_round': 1, 'local_epochs': 5}\n",
            "[Client 13, round 1] fit, config: {'server_round': 1, 'local_epochs': 5}[Client 52, round 1] fit, config: {'server_round': 1, 'local_epochs': 5}\n",
            "\n",
            "Epoch 1: train loss 2.302466458744473, train accuracy 0.10888888888888888\n",
            "Epoch 1: train loss 2.296084417237176, train accuracy 0.11333333333333333\n",
            "Epoch 1: train loss 2.3011211819118924, train accuracy 0.12666666666666668\n",
            "Epoch 1: train loss 2.2982745700412326, train accuracy 0.1111111111111111\n",
            "Epoch 1: train loss 2.3045119841893515, train accuracy 0.10888888888888888\n",
            "Epoch 1: train loss 2.3040381934907703, train accuracy 0.09777777777777778\n",
            "Epoch 2: train loss 2.266396893395318, train accuracy 0.14888888888888888\n",
            "Epoch 2: train loss 2.2368268039491443, train accuracy 0.15333333333333332\n",
            "Epoch 2: train loss 2.2182370689180164, train accuracy 0.19111111111111112Epoch 2: train loss 2.257731318473816, train accuracy 0.19777777777777777\n",
            "\n",
            "Epoch 2: train loss 2.260303748978509, train accuracy 0.1688888888888889Epoch 2: train loss 2.285263670815362, train accuracy 0.14888888888888888\n",
            "\n",
            "Epoch 3: train loss 2.2145220041275024, train accuracy 0.17777777777777778\n",
            "Epoch 3: train loss 2.170514510737525, train accuracy 0.22444444444444445\n",
            "Epoch 3: train loss 2.1226492855283947, train accuracy 0.18\n",
            "Epoch 3: train loss 2.1200392643610635, train accuracy 0.20222222222222222\n",
            "Epoch 3: train loss 2.1938059992260404, train accuracy 0.18\n",
            "Epoch 3: train loss 2.178950912422604, train accuracy 0.2088888888888889\n",
            "Epoch 4: train loss 2.1865226957533093, train accuracy 0.14\n",
            "Epoch 4: train loss 2.1105098260773554, train accuracy 0.2511111111111111\n",
            "Epoch 4: train loss 2.0752870440483093, train accuracy 0.2222222222222222\n",
            "Epoch 4: train loss 2.1600468357404075, train accuracy 0.18\n",
            "Epoch 4: train loss 2.07460610071818, train accuracy 0.21555555555555556\n",
            "Epoch 4: train loss 2.130881587664286, train accuracy 0.2222222222222222\n",
            "Epoch 5: train loss 2.1530618932512073, train accuracy 0.20222222222222222\n",
            "[Client 4, round 1] fit, config: {'server_round': 1, 'local_epochs': 5}\n",
            "Epoch 5: train loss 2.136254827181498, train accuracy 0.18666666666666668\n",
            "[Client 48, round 1] fit, config: {'server_round': 1, 'local_epochs': 5}\n",
            "Epoch 5: train loss 2.045274078845978, train accuracy 0.27111111111111114\n",
            "Epoch 5: train loss 2.08516479200787, train accuracy 0.24888888888888888\n",
            "[Client 68, round 1] fit, config: {'server_round': 1, 'local_epochs': 5}\n",
            "[Client 71, round 1] fit, config: {'server_round': 1, 'local_epochs': 5}\n",
            "Epoch 5: train loss 2.032887644237942, train accuracy 0.23333333333333334\n",
            "Epoch 5: train loss 2.0928222470813327, train accuracy 0.2\n",
            "Epoch 1: train loss 2.2888156043158636, train accuracy 0.13111111111111112\n",
            "Epoch 1: train loss 2.3010416163338556, train accuracy 0.10222222222222223\n",
            "Epoch 1: train loss 2.2924723757637873, train accuracy 0.10444444444444445\n",
            "Epoch 1: train loss 2.3003866407606335, train accuracy 0.12444444444444444\n",
            "Epoch 2: train loss 2.2180181741714478, train accuracy 0.18444444444444444\n",
            "Epoch 2: train loss 2.25537731912401, train accuracy 0.13333333333333333\n",
            "Epoch 2: train loss 2.2380646732118397, train accuracy 0.20222222222222222\n",
            "Epoch 2: train loss 2.2162190013461642, train accuracy 0.19555555555555557\n",
            "Epoch 3: train loss 2.1802437437905207, train accuracy 0.22\n",
            "Epoch 3: train loss 2.151446157031589, train accuracy 0.20444444444444446\n",
            "Epoch 3: train loss 2.1985263692008123, train accuracy 0.20222222222222222\n",
            "Epoch 3: train loss 2.1346716152297125, train accuracy 0.17555555555555555\n",
            "Epoch 4: train loss 2.0917596088515387, train accuracy 0.27555555555555555Epoch 4: train loss 2.103151970439487, train accuracy 0.24888888888888888\n",
            "\n",
            "Epoch 4: train loss 2.176690525478787, train accuracy 0.18666666666666668\n",
            "Epoch 4: train loss 2.075582630104489, train accuracy 0.22444444444444445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:10:09,107 | server.py:229 | fit_round 1 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 1 received 10 results and 0 failures\n",
            "WARNING flower 2023-05-25 22:10:09,151 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flower:No fit_metrics_aggregation_fn provided\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 2.067408707406786, train accuracy 0.23777777777777778\n",
            "Epoch 5: train loss 2.0784449179967246, train accuracy 0.21555555555555556\n",
            "Epoch 5: train loss 2.106139255894555, train accuracy 0.18888888888888888\n",
            "Epoch 5: train loss 2.0405496954917908, train accuracy 0.2288888888888889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:10:14,891 | server.py:116 | fit progress: (1, 2.109095280468464, {'accuracy': 0.2227}, 23.265837449999992)\n",
            "INFO:flower:fit progress: (1, 2.109095280468464, {'accuracy': 0.2227}, 23.265837449999992)\n",
            "INFO flower 2023-05-25 22:10:14,898 | server.py:163 | evaluate_round 1: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 1: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:10:14,907 | server.py:215 | fit_round 2: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 2: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 2.109095280468464 / accuracy 0.2227\n",
            "[Client 42, round 2] fit, config: {'server_round': 2, 'local_epochs': 5}\n",
            "[Client 43, round 2] fit, config: {'server_round': 2, 'local_epochs': 5}\n",
            "[Client 6, round 2] fit, config: {'server_round': 2, 'local_epochs': 5}\n",
            "[Client 20, round 2] fit, config: {'server_round': 2, 'local_epochs': 5}\n",
            "[Client 17, round 2] fit, config: {'server_round': 2, 'local_epochs': 5}[Client 71, round 2] fit, config: {'server_round': 2, 'local_epochs': 5}\n",
            "\n",
            "Epoch 1: train loss 2.1369950903786554, train accuracy 0.19555555555555557\n",
            "Epoch 1: train loss 2.1240064567989774, train accuracy 0.21555555555555556\n",
            "Epoch 1: train loss 2.070145567258199, train accuracy 0.2088888888888889\n",
            "Epoch 1: train loss 2.159985065460205, train accuracy 0.19111111111111112\n",
            "Epoch 1: train loss 2.129077739185757, train accuracy 0.20222222222222222\n",
            "Epoch 1: train loss 2.1191437906689115, train accuracy 0.24888888888888888\n",
            "Epoch 2: train loss 2.0947126613722906, train accuracy 0.2088888888888889\n",
            "Epoch 2: train loss 2.0540471540557013, train accuracy 0.2688888888888889\n",
            "Epoch 2: train loss 2.089807477262285, train accuracy 0.24\n",
            "Epoch 2: train loss 2.0112789935535855, train accuracy 0.23777777777777778\n",
            "Epoch 2: train loss 2.0634348260031805, train accuracy 0.2511111111111111\n",
            "Epoch 2: train loss 2.0570102797614203, train accuracy 0.24222222222222223\n",
            "Epoch 3: train loss 2.007066395547655, train accuracy 0.26666666666666666\n",
            "Epoch 3: train loss 2.0777372320493064, train accuracy 0.23555555555555555\n",
            "Epoch 3: train loss 2.079682800504896, train accuracy 0.22\n",
            "Epoch 3: train loss 1.965774695078532, train accuracy 0.25333333333333335\n",
            "Epoch 3: train loss 2.0470873448583813, train accuracy 0.24222222222222223\n",
            "Epoch 3: train loss 2.057728409767151, train accuracy 0.26222222222222225\n",
            "Epoch 4: train loss 2.0430776013268366, train accuracy 0.24444444444444444\n",
            "Epoch 4: train loss 1.9766661061180963, train accuracy 0.2777777777777778\n",
            "Epoch 4: train loss 2.044275595082177, train accuracy 0.23777777777777778\n",
            "Epoch 4: train loss 1.939642435974545, train accuracy 0.2777777777777778\n",
            "Epoch 4: train loss 2.0476225747002497, train accuracy 0.24888888888888888\n",
            "Epoch 4: train loss 2.0307430691189237, train accuracy 0.2688888888888889\n",
            "Epoch 5: train loss 2.0219935841030545, train accuracy 0.23333333333333334\n",
            "[Client 89, round 2] fit, config: {'server_round': 2, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.9630864262580872, train accuracy 0.28888888888888886\n",
            "[Client 31, round 2] fit, config: {'server_round': 2, 'local_epochs': 5}\n",
            "Epoch 5: train loss 2.0224829051229687, train accuracy 0.27111111111111114\n",
            "[Client 0, round 2] fit, config: {'server_round': 2, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.960566759109497, train accuracy 0.25555555555555554\n",
            "[Client 55, round 2] fit, config: {'server_round': 2, 'local_epochs': 5}\n",
            "Epoch 5: train loss 2.034978191057841, train accuracy 0.26666666666666666\n",
            "Epoch 5: train loss 1.9988462262683444, train accuracy 0.2688888888888889\n",
            "Epoch 1: train loss 2.1299391123983593, train accuracy 0.19777777777777777\n",
            "Epoch 1: train loss 2.081533988316854, train accuracy 0.2311111111111111\n",
            "Epoch 1: train loss 2.109831326537662, train accuracy 0.17777777777777778\n",
            "Epoch 1: train loss 2.1449791457917957, train accuracy 0.21333333333333335\n",
            "Epoch 2: train loss 2.0320218669043646, train accuracy 0.25555555555555554\n",
            "Epoch 2: train loss 2.074004590511322, train accuracy 0.2\n",
            "Epoch 2: train loss 2.0402574936548867, train accuracy 0.2222222222222222\n",
            "Epoch 2: train loss 2.07455747657352, train accuracy 0.23777777777777778\n",
            "Epoch 3: train loss 2.0024548835224576, train accuracy 0.22444444444444445\n",
            "Epoch 3: train loss 2.0426682101355658, train accuracy 0.22444444444444445\n",
            "Epoch 3: train loss 2.041445189052158, train accuracy 0.2111111111111111\n",
            "Epoch 3: train loss 2.0410198304388256, train accuracy 0.24\n",
            "Epoch 4: train loss 1.955471807056003, train accuracy 0.29333333333333333\n",
            "Epoch 4: train loss 1.989490032196045, train accuracy 0.2733333333333333\n",
            "Epoch 4: train loss 2.027900867991977, train accuracy 0.2644444444444444\n",
            "Epoch 4: train loss 2.0263237357139587, train accuracy 0.21333333333333335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:10:33,240 | server.py:229 | fit_round 2 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 2 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.9237275918324788, train accuracy 0.27111111111111114\n",
            "Epoch 5: train loss 1.9292448494169447, train accuracy 0.2866666666666667\n",
            "Epoch 5: train loss 2.03671262661616, train accuracy 0.24\n",
            "Epoch 5: train loss 2.003323641088274, train accuracy 0.26666666666666666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:10:37,089 | server.py:116 | fit progress: (2, 1.972492690384388, {'accuracy': 0.2673}, 45.463350521999985)\n",
            "INFO:flower:fit progress: (2, 1.972492690384388, {'accuracy': 0.2673}, 45.463350521999985)\n",
            "INFO flower 2023-05-25 22:10:37,094 | server.py:163 | evaluate_round 2: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 2: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:10:37,100 | server.py:215 | fit_round 3: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 3: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.972492690384388 / accuracy 0.2673\n",
            "[Client 99, round 3] fit, config: {'server_round': 3, 'local_epochs': 5}\n",
            "[Client 11, round 3] fit, config: {'server_round': 3, 'local_epochs': 5}\n",
            "[Client 76, round 3] fit, config: {'server_round': 3, 'local_epochs': 5}\n",
            "[Client 48, round 3] fit, config: {'server_round': 3, 'local_epochs': 5}\n",
            "[Client 8, round 3] fit, config: {'server_round': 3, 'local_epochs': 5}\n",
            "[Client 0, round 3] fit, config: {'server_round': 3, 'local_epochs': 5}\n",
            "Epoch 1: train loss 2.055303520626492, train accuracy 0.2288888888888889Epoch 1: train loss 1.9568774700164795, train accuracy 0.2777777777777778Epoch 1: train loss 1.9696391820907593, train accuracy 0.24444444444444444\n",
            "\n",
            "\n",
            "Epoch 1: train loss 2.0653407639927335, train accuracy 0.21555555555555556\n",
            "Epoch 1: train loss 2.006499595112271, train accuracy 0.24888888888888888\n",
            "Epoch 1: train loss 2.0454425745540195, train accuracy 0.2311111111111111\n",
            "Epoch 2: train loss 1.9285466074943542, train accuracy 0.25555555555555554\n",
            "Epoch 2: train loss 2.012515856160058, train accuracy 0.2311111111111111\n",
            "Epoch 2: train loss 1.9958271318011813, train accuracy 0.28444444444444444\n",
            "Epoch 2: train loss 1.9710876478089228, train accuracy 0.24888888888888888\n",
            "Epoch 2: train loss 1.9766406218210857, train accuracy 0.2777777777777778\n",
            "Epoch 2: train loss 1.9812469614876642, train accuracy 0.2777777777777778\n",
            "Epoch 3: train loss 1.930464314089881, train accuracy 0.2644444444444444\n",
            "Epoch 3: train loss 1.931270142396291, train accuracy 0.3\n",
            "Epoch 3: train loss 1.9094251261817083, train accuracy 0.27111111111111114\n",
            "Epoch 3: train loss 1.9685330390930176, train accuracy 0.3088888888888889\n",
            "Epoch 3: train loss 2.0192015369733176, train accuracy 0.24666666666666667\n",
            "Epoch 3: train loss 1.9400831659634907, train accuracy 0.2688888888888889\n",
            "Epoch 4: train loss 1.8758500218391418, train accuracy 0.3022222222222222\n",
            "Epoch 4: train loss 1.9686572154362996, train accuracy 0.2688888888888889\n",
            "Epoch 4: train loss 1.955611699157291, train accuracy 0.26222222222222225\n",
            "Epoch 4: train loss 1.935287144449022, train accuracy 0.3022222222222222\n",
            "Epoch 4: train loss 1.911681850751241, train accuracy 0.27111111111111114\n",
            "Epoch 4: train loss 1.9199750820795696, train accuracy 0.3\n",
            "Epoch 5: train loss 1.8612800240516663, train accuracy 0.2911111111111111\n",
            "[Client 40, round 3] fit, config: {'server_round': 3, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.9458897908528645, train accuracy 0.2577777777777778\n",
            "[Client 93, round 3] fit, config: {'server_round': 3, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.9335959288809035, train accuracy 0.2733333333333333\n",
            "[Client 57, round 3] fit, config: {'server_round': 3, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.907860643333859, train accuracy 0.2866666666666667\n",
            "[Client 13, round 3] fit, config: {'server_round': 3, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.8628581960995991, train accuracy 0.3111111111111111\n",
            "Epoch 5: train loss 1.8938055038452148, train accuracy 0.28\n",
            "Epoch 1: train loss 2.0854140983687506, train accuracy 0.22\n",
            "Epoch 1: train loss 2.0529646741019354, train accuracy 0.21333333333333335\n",
            "Epoch 1: train loss 2.0287476778030396, train accuracy 0.27111111111111114\n",
            "Epoch 1: train loss 2.0798659722010293, train accuracy 0.23333333333333334\n",
            "Epoch 2: train loss 1.9819891055425007, train accuracy 0.25333333333333335\n",
            "Epoch 2: train loss 2.0329388115141125, train accuracy 0.24888888888888888\n",
            "Epoch 2: train loss 2.0128158132235208, train accuracy 0.2222222222222222\n",
            "Epoch 2: train loss 2.049540897210439, train accuracy 0.24\n",
            "Epoch 3: train loss 1.989562643898858, train accuracy 0.2688888888888889\n",
            "Epoch 3: train loss 1.9729059934616089, train accuracy 0.2577777777777778\n",
            "Epoch 3: train loss 1.970418910185496, train accuracy 0.27111111111111114\n",
            "Epoch 3: train loss 2.016519890891181, train accuracy 0.2511111111111111\n",
            "Epoch 4: train loss 1.9344682693481445, train accuracy 0.29333333333333333Epoch 4: train loss 1.9892137050628662, train accuracy 0.2644444444444444\n",
            "\n",
            "Epoch 4: train loss 1.9094161722395155, train accuracy 0.29555555555555557\n",
            "Epoch 4: train loss 1.9851133690940008, train accuracy 0.27111111111111114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:10:57,440 | server.py:229 | fit_round 3 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 3 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.9081379638777838, train accuracy 0.29555555555555557\n",
            "Epoch 5: train loss 1.955468065208859, train accuracy 0.2866666666666667\n",
            "Epoch 5: train loss 1.9307510322994657, train accuracy 0.2866666666666667\n",
            "Epoch 5: train loss 1.9445765217145283, train accuracy 0.2733333333333333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:11:01,393 | server.py:116 | fit progress: (3, 1.8904584163427354, {'accuracy': 0.2992}, 69.76757302300001)\n",
            "INFO:flower:fit progress: (3, 1.8904584163427354, {'accuracy': 0.2992}, 69.76757302300001)\n",
            "INFO flower 2023-05-25 22:11:01,397 | server.py:163 | evaluate_round 3: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 3: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:11:01,400 | server.py:215 | fit_round 4: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 4: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.8904584163427354 / accuracy 0.2992\n",
            "[Client 5, round 4] fit, config: {'server_round': 4, 'local_epochs': 5}\n",
            "[Client 11, round 4] fit, config: {'server_round': 4, 'local_epochs': 5}\n",
            "[Client 85, round 4] fit, config: {'server_round': 4, 'local_epochs': 5}\n",
            "[Client 18, round 4] fit, config: {'server_round': 4, 'local_epochs': 5}\n",
            "[Client 16, round 4] fit, config: {'server_round': 4, 'local_epochs': 5}\n",
            "[Client 2, round 4] fit, config: {'server_round': 4, 'local_epochs': 5}\n",
            "Epoch 1: train loss 2.004817876550886, train accuracy 0.2511111111111111\n",
            "Epoch 1: train loss 1.9653313557306926, train accuracy 0.2733333333333333\n",
            "Epoch 1: train loss 1.9042387008666992, train accuracy 0.3111111111111111\n",
            "Epoch 1: train loss 1.9027976195017497, train accuracy 0.29777777777777775\n",
            "Epoch 1: train loss 1.969014671113756, train accuracy 0.26666666666666666\n",
            "Epoch 1: train loss 1.9582062363624573, train accuracy 0.25555555555555554\n",
            "Epoch 2: train loss 1.854750547144148, train accuracy 0.32666666666666666\n",
            "Epoch 2: train loss 1.9665230645073786, train accuracy 0.2866666666666667\n",
            "Epoch 2: train loss 1.9053604337904189, train accuracy 0.26\n",
            "Epoch 2: train loss 1.8500622312227886, train accuracy 0.32\n",
            "Epoch 2: train loss 1.9117550982369318, train accuracy 0.3022222222222222\n",
            "Epoch 2: train loss 1.9437197777960036, train accuracy 0.28888888888888886\n",
            "Epoch 3: train loss 1.8574631081687079, train accuracy 0.31333333333333335\n",
            "Epoch 3: train loss 1.874807443883684, train accuracy 0.31555555555555553\n",
            "Epoch 3: train loss 1.823023749722375, train accuracy 0.31777777777777777\n",
            "Epoch 3: train loss 1.932468765311771, train accuracy 0.2577777777777778\n",
            "Epoch 3: train loss 1.8727632363637288, train accuracy 0.3111111111111111\n",
            "Epoch 3: train loss 1.9125407271915011, train accuracy 0.30444444444444446\n",
            "Epoch 4: train loss 1.848537762959798, train accuracy 0.3111111111111111\n",
            "Epoch 4: train loss 1.8744280338287354, train accuracy 0.31333333333333335\n",
            "Epoch 4: train loss 1.8110515077908833, train accuracy 0.33111111111111113\n",
            "Epoch 4: train loss 1.9374121758672926, train accuracy 0.2733333333333333\n",
            "Epoch 4: train loss 1.8629951543278165, train accuracy 0.3111111111111111\n",
            "Epoch 4: train loss 1.8970770570966933, train accuracy 0.2822222222222222\n",
            "Epoch 5: train loss 1.8270153734419081, train accuracy 0.3111111111111111\n",
            "[Client 37, round 4] fit, config: {'server_round': 4, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.7691797150505915, train accuracy 0.3688888888888889\n",
            "[Client 55, round 4] fit, config: {'server_round': 4, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.7906905280219183, train accuracy 0.32222222222222224\n",
            "[Client 73, round 4] fit, config: {'server_round': 4, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.9163010319073994, train accuracy 0.3111111111111111\n",
            "[Client 61, round 4] fit, config: {'server_round': 4, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.8136635488933988, train accuracy 0.31777777777777777\n",
            "Epoch 5: train loss 1.8376019795735676, train accuracy 0.32222222222222224\n",
            "Epoch 1: train loss 1.9782226946618822, train accuracy 0.26222222222222225\n",
            "Epoch 1: train loss 1.9847405751546223, train accuracy 0.2733333333333333\n",
            "Epoch 1: train loss 1.9729181660546198, train accuracy 0.27111111111111114\n",
            "Epoch 1: train loss 1.9899023705058627, train accuracy 0.2644444444444444\n",
            "Epoch 2: train loss 1.918363372484843, train accuracy 0.29555555555555557\n",
            "Epoch 2: train loss 1.9148310489124722, train accuracy 0.2777777777777778\n",
            "Epoch 2: train loss 1.8986462619569566, train accuracy 0.31777777777777777\n",
            "Epoch 2: train loss 1.9211747580104404, train accuracy 0.2733333333333333\n",
            "Epoch 3: train loss 1.9066816965738933, train accuracy 0.28\n",
            "Epoch 3: train loss 1.8812289436658223, train accuracy 0.29333333333333333\n",
            "Epoch 3: train loss 1.8776035904884338, train accuracy 0.31555555555555553\n",
            "Epoch 3: train loss 1.9030442701445685, train accuracy 0.26222222222222225\n",
            "Epoch 4: train loss 1.8858267532454596, train accuracy 0.3333333333333333\n",
            "Epoch 4: train loss 1.9016655683517456, train accuracy 0.3088888888888889\n",
            "Epoch 4: train loss 1.888834814230601, train accuracy 0.30444444444444446\n",
            "Epoch 4: train loss 1.8559297654363844, train accuracy 0.35333333333333333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:11:19,533 | server.py:229 | fit_round 4 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 4 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.8396325839890375, train accuracy 0.3088888888888889\n",
            "Epoch 5: train loss 1.8805137342876859, train accuracy 0.3\n",
            "Epoch 5: train loss 1.8429253432485793, train accuracy 0.3111111111111111\n",
            "Epoch 5: train loss 1.8571857810020447, train accuracy 0.32222222222222224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:11:24,208 | server.py:116 | fit progress: (4, 1.8255807301402092, {'accuracy': 0.3253}, 92.58231799599997)\n",
            "INFO:flower:fit progress: (4, 1.8255807301402092, {'accuracy': 0.3253}, 92.58231799599997)\n",
            "INFO flower 2023-05-25 22:11:24,211 | server.py:163 | evaluate_round 4: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 4: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:11:24,214 | server.py:215 | fit_round 5: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 5: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.8255807301402092 / accuracy 0.3253\n",
            "[Client 33, round 5] fit, config: {'server_round': 5, 'local_epochs': 5}\n",
            "[Client 60, round 5] fit, config: {'server_round': 5, 'local_epochs': 5}\n",
            "[Client 4, round 5] fit, config: {'server_round': 5, 'local_epochs': 5}\n",
            "[Client 39, round 5] fit, config: {'server_round': 5, 'local_epochs': 5}[Client 98, round 5] fit, config: {'server_round': 5, 'local_epochs': 5}\n",
            "\n",
            "[Client 43, round 5] fit, config: {'server_round': 5, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.9260514047410753, train accuracy 0.26\n",
            "Epoch 1: train loss 1.9748310380511813, train accuracy 0.2644444444444444\n",
            "Epoch 1: train loss 1.9390886425971985, train accuracy 0.27111111111111114\n",
            "Epoch 1: train loss 1.9124934805764093, train accuracy 0.3022222222222222\n",
            "Epoch 1: train loss 1.8786295652389526, train accuracy 0.29777777777777775\n",
            "Epoch 1: train loss 1.950356039736006, train accuracy 0.25333333333333335\n",
            "Epoch 2: train loss 1.8749076128005981, train accuracy 0.3244444444444444\n",
            "Epoch 2: train loss 1.9366830322477553, train accuracy 0.3\n",
            "Epoch 2: train loss 1.8308796021673415, train accuracy 0.2822222222222222\n",
            "Epoch 2: train loss 1.8762111994955275, train accuracy 0.32666666666666666\n",
            "Epoch 2: train loss 1.9030253158675299, train accuracy 0.30444444444444446\n",
            "Epoch 2: train loss 1.9024052222569783, train accuracy 0.28888888888888886\n",
            "Epoch 3: train loss 1.8797574374410841, train accuracy 0.29777777777777775\n",
            "Epoch 3: train loss 1.8153859244452581, train accuracy 0.3\n",
            "Epoch 3: train loss 1.9032592707210116, train accuracy 0.29333333333333333\n",
            "Epoch 3: train loss 1.8672600322299533, train accuracy 0.29555555555555557\n",
            "Epoch 3: train loss 1.8343778914875455, train accuracy 0.33555555555555555\n",
            "Epoch 3: train loss 1.8163667453659906, train accuracy 0.32666666666666666\n",
            "Epoch 4: train loss 1.8313096430566576, train accuracy 0.33555555555555555\n",
            "Epoch 4: train loss 1.8101720213890076, train accuracy 0.29777777777777775\n",
            "Epoch 4: train loss 1.8595474627282884, train accuracy 0.31555555555555553\n",
            "Epoch 4: train loss 1.8986298905478582, train accuracy 0.3333333333333333\n",
            "Epoch 4: train loss 1.861035903294881, train accuracy 0.3244444444444444\n",
            "Epoch 4: train loss 1.8590570754475064, train accuracy 0.32\n",
            "Epoch 5: train loss 1.8260927928818598, train accuracy 0.3244444444444444\n",
            "[Client 66, round 5] fit, config: {'server_round': 5, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.756683395968543, train accuracy 0.33111111111111113\n",
            "[Client 61, round 5] fit, config: {'server_round': 5, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.850863390498691, train accuracy 0.31777777777777777\n",
            "[Client 26, round 5] fit, config: {'server_round': 5, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.8550286425484552, train accuracy 0.31777777777777777\n",
            "[Client 77, round 5] fit, config: {'server_round': 5, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.7985534601741366, train accuracy 0.3288888888888889\n",
            "Epoch 5: train loss 1.792374160554674, train accuracy 0.3688888888888889\n",
            "Epoch 1: train loss 1.9044753445519342, train accuracy 0.2866666666666667Epoch 1: train loss 1.9293657143910725, train accuracy 0.26666666666666666\n",
            "\n",
            "Epoch 1: train loss 1.9093749854299757, train accuracy 0.28888888888888886\n",
            "Epoch 1: train loss 1.9202939073244731, train accuracy 0.2911111111111111\n",
            "Epoch 2: train loss 1.8291189471880596, train accuracy 0.30666666666666664\n",
            "Epoch 2: train loss 1.9049254655838013, train accuracy 0.2644444444444444\n",
            "Epoch 2: train loss 1.8893390695254009, train accuracy 0.31777777777777777\n",
            "Epoch 2: train loss 1.8674277000957065, train accuracy 0.3111111111111111\n",
            "Epoch 3: train loss 1.8245733115408156, train accuracy 0.3466666666666667\n",
            "Epoch 3: train loss 1.8685879508654277, train accuracy 0.3\n",
            "Epoch 3: train loss 1.8593715959125094, train accuracy 0.3088888888888889\n",
            "Epoch 3: train loss 1.811574445830451, train accuracy 0.3422222222222222\n",
            "Epoch 4: train loss 1.8586695790290833, train accuracy 0.28444444444444444\n",
            "Epoch 4: train loss 1.7793360352516174, train accuracy 0.32666666666666666\n",
            "Epoch 4: train loss 1.8256142271889582, train accuracy 0.31555555555555553\n",
            "Epoch 4: train loss 1.8174024025599163, train accuracy 0.3377777777777778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:11:43,686 | server.py:229 | fit_round 5 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 5 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.8862932191954718, train accuracy 0.2866666666666667\n",
            "Epoch 5: train loss 1.7636981871392992, train accuracy 0.3333333333333333\n",
            "Epoch 5: train loss 1.789891693327162, train accuracy 0.32666666666666666\n",
            "Epoch 5: train loss 1.8074633412890964, train accuracy 0.3422222222222222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:11:48,394 | server.py:116 | fit progress: (5, 1.7847999560832977, {'accuracy': 0.3409}, 116.76897847200001)\n",
            "INFO:flower:fit progress: (5, 1.7847999560832977, {'accuracy': 0.3409}, 116.76897847200001)\n",
            "INFO flower 2023-05-25 22:11:48,400 | server.py:163 | evaluate_round 5: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 5: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:11:48,403 | server.py:215 | fit_round 6: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 6: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.7847999560832977 / accuracy 0.3409\n",
            "[Client 67, round 6] fit, config: {'server_round': 6, 'local_epochs': 5}\n",
            "[Client 81, round 6] fit, config: {'server_round': 6, 'local_epochs': 5}\n",
            "[Client 72, round 6] fit, config: {'server_round': 6, 'local_epochs': 5}\n",
            "[Client 40, round 6] fit, config: {'server_round': 6, 'local_epochs': 5}\n",
            "[Client 1, round 6] fit, config: {'server_round': 6, 'local_epochs': 5}\n",
            "[Client 50, round 6] fit, config: {'server_round': 6, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.8510983321401808, train accuracy 0.31777777777777777\n",
            "Epoch 1: train loss 1.9291153881284926, train accuracy 0.29777777777777775\n",
            "Epoch 1: train loss 1.8636534677611456, train accuracy 0.3022222222222222\n",
            "Epoch 1: train loss 1.8431543972757127, train accuracy 0.30666666666666664\n",
            "Epoch 1: train loss 1.887713657485114, train accuracy 0.2777777777777778\n",
            "Epoch 1: train loss 1.8766740891668532, train accuracy 0.3088888888888889\n",
            "Epoch 2: train loss 1.8397835029496088, train accuracy 0.3244444444444444\n",
            "Epoch 2: train loss 1.8717895216412015, train accuracy 0.3111111111111111\n",
            "Epoch 2: train loss 1.8061177333196003, train accuracy 0.3422222222222222\n",
            "Epoch 2: train loss 1.7468862003750272, train accuracy 0.3488888888888889\n",
            "Epoch 2: train loss 1.8008058932092454, train accuracy 0.32666666666666666\n",
            "Epoch 2: train loss 1.861667765511407, train accuracy 0.3088888888888889\n",
            "Epoch 3: train loss 1.7538788119951885, train accuracy 0.3511111111111111\n",
            "Epoch 3: train loss 1.7695807019869487, train accuracy 0.33555555555555555\n",
            "Epoch 3: train loss 1.737494945526123, train accuracy 0.35777777777777775\n",
            "Epoch 3: train loss 1.8043322364489238, train accuracy 0.36444444444444446\n",
            "Epoch 3: train loss 1.8057877818743389, train accuracy 0.31333333333333335\n",
            "Epoch 3: train loss 1.785449246565501, train accuracy 0.31555555555555553\n",
            "Epoch 4: train loss 1.7836057477527194, train accuracy 0.33555555555555555\n",
            "Epoch 4: train loss 1.702721483177609, train accuracy 0.36666666666666664\n",
            "Epoch 4: train loss 1.8096665077739291, train accuracy 0.3422222222222222\n",
            "Epoch 4: train loss 1.8130914568901062, train accuracy 0.3422222222222222\n",
            "Epoch 4: train loss 1.7743264900313482, train accuracy 0.35555555555555557\n",
            "Epoch 4: train loss 1.7713028126292758, train accuracy 0.36444444444444446\n",
            "Epoch 5: train loss 1.7989733616511028, train accuracy 0.3288888888888889\n",
            "[Client 98, round 6] fit, config: {'server_round': 6, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.722788393497467, train accuracy 0.3688888888888889\n",
            "[Client 82, round 6] fit, config: {'server_round': 6, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.6913953224817913, train accuracy 0.37333333333333335\n",
            "[Client 65, round 6] fit, config: {'server_round': 6, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.7632319662306044, train accuracy 0.34\n",
            "[Client 55, round 6] fit, config: {'server_round': 6, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.785447319348653, train accuracy 0.34444444444444444\n",
            "Epoch 5: train loss 1.7775651680098639, train accuracy 0.32666666666666666\n",
            "Epoch 1: train loss 1.9117866622077093, train accuracy 0.2911111111111111\n",
            "Epoch 1: train loss 1.880998882982466, train accuracy 0.3111111111111111\n",
            "Epoch 1: train loss 1.8661454849772983, train accuracy 0.30444444444444446\n",
            "Epoch 1: train loss 1.8830631971359253, train accuracy 0.31777777777777777\n",
            "Epoch 2: train loss 1.8717249499426947, train accuracy 0.31333333333333335\n",
            "Epoch 2: train loss 1.8237766358587477, train accuracy 0.3377777777777778\n",
            "Epoch 2: train loss 1.7771122323142157, train accuracy 0.3022222222222222\n",
            "Epoch 2: train loss 1.8061598208215501, train accuracy 0.3088888888888889\n",
            "Epoch 3: train loss 1.8260397248797946, train accuracy 0.29333333333333333\n",
            "Epoch 3: train loss 1.7843561304940119, train accuracy 0.32666666666666666\n",
            "Epoch 3: train loss 1.7672573394245572, train accuracy 0.3333333333333333\n",
            "Epoch 3: train loss 1.7684678898917303, train accuracy 0.35333333333333333\n",
            "Epoch 4: train loss 1.8255231181780498, train accuracy 0.32222222222222224\n",
            "Epoch 4: train loss 1.7838500142097473, train accuracy 0.33555555555555555\n",
            "Epoch 4: train loss 1.7420564360088773, train accuracy 0.3488888888888889Epoch 4: train loss 1.7788982258902655, train accuracy 0.34444444444444444\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:12:08,463 | server.py:229 | fit_round 6 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 6 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.8124371237225003, train accuracy 0.32666666666666666\n",
            "Epoch 5: train loss 1.7678530149989657, train accuracy 0.33555555555555555\n",
            "Epoch 5: train loss 1.7468650804625616, train accuracy 0.3333333333333333\n",
            "Epoch 5: train loss 1.7696470022201538, train accuracy 0.32666666666666666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:12:13,691 | server.py:116 | fit progress: (6, 1.742974908053875, {'accuracy': 0.3583}, 142.06606036099998)\n",
            "INFO:flower:fit progress: (6, 1.742974908053875, {'accuracy': 0.3583}, 142.06606036099998)\n",
            "INFO flower 2023-05-25 22:12:13,695 | server.py:163 | evaluate_round 6: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 6: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:12:13,699 | server.py:215 | fit_round 7: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 7: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.742974908053875 / accuracy 0.3583\n",
            "[Client 87, round 7] fit, config: {'server_round': 7, 'local_epochs': 5}\n",
            "[Client 68, round 7] fit, config: {'server_round': 7, 'local_epochs': 5}\n",
            "[Client 81, round 7] fit, config: {'server_round': 7, 'local_epochs': 5}\n",
            "[Client 85, round 7] fit, config: {'server_round': 7, 'local_epochs': 5}\n",
            "[Client 76, round 7] fit, config: {'server_round': 7, 'local_epochs': 5}\n",
            "[Client 62, round 7] fit, config: {'server_round': 7, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.8831026951471965, train accuracy 0.31555555555555553\n",
            "Epoch 1: train loss 1.8719303674168057, train accuracy 0.2822222222222222\n",
            "Epoch 1: train loss 1.9118088748719957, train accuracy 0.2822222222222222\n",
            "Epoch 1: train loss 1.7958363095919292, train accuracy 0.33111111111111113\n",
            "Epoch 1: train loss 1.8973420527246263, train accuracy 0.2866666666666667\n",
            "Epoch 1: train loss 1.8704457812839084, train accuracy 0.34\n",
            "Epoch 2: train loss 1.8215782576137118, train accuracy 0.37555555555555553\n",
            "Epoch 2: train loss 1.820993337366316, train accuracy 0.3422222222222222\n",
            "Epoch 2: train loss 1.8155683543947008, train accuracy 0.3288888888888889\n",
            "Epoch 2: train loss 1.7556049095259771, train accuracy 0.32222222222222224\n",
            "Epoch 2: train loss 1.8629060917430453, train accuracy 0.30666666666666664\n",
            "Epoch 2: train loss 1.799908909532759, train accuracy 0.3422222222222222\n",
            "Epoch 3: train loss 1.7961492670906916, train accuracy 0.3622222222222222\n",
            "Epoch 3: train loss 1.7350840634769864, train accuracy 0.34\n",
            "Epoch 3: train loss 1.7850848303900824, train accuracy 0.31333333333333335\n",
            "Epoch 3: train loss 1.736271275414361, train accuracy 0.3422222222222222\n",
            "Epoch 3: train loss 1.833353877067566, train accuracy 0.3Epoch 3: train loss 1.755934218565623, train accuracy 0.36444444444444446\n",
            "\n",
            "Epoch 4: train loss 1.7600309318966336, train accuracy 0.33555555555555555\n",
            "Epoch 4: train loss 1.7489878866407607, train accuracy 0.37333333333333335\n",
            "Epoch 4: train loss 1.7708304988013372, train accuracy 0.34\n",
            "Epoch 4: train loss 1.7432165874375238, train accuracy 0.33555555555555555\n",
            "Epoch 4: train loss 1.7544816003905401, train accuracy 0.3622222222222222\n",
            "Epoch 4: train loss 1.7970684501859877, train accuracy 0.34444444444444444\n",
            "Epoch 5: train loss 1.7787384589513142, train accuracy 0.3422222222222222\n",
            "[Client 66, round 7] fit, config: {'server_round': 7, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.8047872980435689, train accuracy 0.32\n",
            "Epoch 5: train loss 1.7031306955549452, train accuracy 0.37777777777777777\n",
            "[Client 53, round 7] fit, config: {'server_round': 7, 'local_epochs': 5}\n",
            "[Client 47, round 7] fit, config: {'server_round': 7, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.7320560349358454, train accuracy 0.3622222222222222\n",
            "[Client 65, round 7] fit, config: {'server_round': 7, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.7505500581529405, train accuracy 0.3622222222222222\n",
            "Epoch 5: train loss 1.8302201959821913, train accuracy 0.32\n",
            "Epoch 1: train loss 1.892017536693149, train accuracy 0.30666666666666664\n",
            "Epoch 1: train loss 1.86842280626297, train accuracy 0.3288888888888889\n",
            "Epoch 1: train loss 1.9337824980417888, train accuracy 0.29555555555555557\n",
            "Epoch 1: train loss 1.8569011953141954, train accuracy 0.30666666666666664\n",
            "Epoch 2: train loss 1.8032267888387044, train accuracy 0.33111111111111113\n",
            "Epoch 2: train loss 1.8047105537520514, train accuracy 0.3333333333333333\n",
            "Epoch 2: train loss 1.8538187013732061, train accuracy 0.31333333333333335\n",
            "Epoch 2: train loss 1.7537759343783061, train accuracy 0.36\n",
            "Epoch 3: train loss 1.753253287739224, train accuracy 0.35333333333333333\n",
            "Epoch 3: train loss 1.7756062017546759, train accuracy 0.31555555555555553\n",
            "Epoch 3: train loss 1.776615818341573, train accuracy 0.34\n",
            "Epoch 3: train loss 1.7522652347882588, train accuracy 0.3933333333333333\n",
            "Epoch 4: train loss 1.749891996383667, train accuracy 0.3466666666666667\n",
            "Epoch 4: train loss 1.7539979683028326, train accuracy 0.3244444444444444\n",
            "Epoch 4: train loss 1.7968877289030287, train accuracy 0.3377777777777778\n",
            "Epoch 4: train loss 1.7360224657588534, train accuracy 0.36\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:12:33,639 | server.py:229 | fit_round 7 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 7 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.7108296288384333, train accuracy 0.3933333333333333\n",
            "Epoch 5: train loss 1.7489608195092943, train accuracy 0.3511111111111111\n",
            "Epoch 5: train loss 1.7372014323870342, train accuracy 0.3333333333333333\n",
            "Epoch 5: train loss 1.7233751349978976, train accuracy 0.35333333333333333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:12:39,138 | server.py:116 | fit progress: (7, 1.712778445482254, {'accuracy': 0.3774}, 167.51233028500002)\n",
            "INFO:flower:fit progress: (7, 1.712778445482254, {'accuracy': 0.3774}, 167.51233028500002)\n",
            "INFO flower 2023-05-25 22:12:39,141 | server.py:163 | evaluate_round 7: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 7: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:12:39,146 | server.py:215 | fit_round 8: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 8: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.712778445482254 / accuracy 0.3774\n",
            "[Client 4, round 8] fit, config: {'server_round': 8, 'local_epochs': 5}\n",
            "[Client 96, round 8] fit, config: {'server_round': 8, 'local_epochs': 5}\n",
            "[Client 82, round 8] fit, config: {'server_round': 8, 'local_epochs': 5}\n",
            "[Client 23, round 8] fit, config: {'server_round': 8, 'local_epochs': 5}\n",
            "[Client 92, round 8] fit, config: {'server_round': 8, 'local_epochs': 5}\n",
            "[Client 10, round 8] fit, config: {'server_round': 8, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.8283595972590976, train accuracy 0.3\n",
            "Epoch 1: train loss 1.8106315930684407, train accuracy 0.30444444444444446\n",
            "Epoch 1: train loss 1.817916711171468, train accuracy 0.35777777777777775\n",
            "Epoch 1: train loss 1.7795699901050992, train accuracy 0.33555555555555555\n",
            "Epoch 1: train loss 1.8140388396051195, train accuracy 0.34\n",
            "Epoch 1: train loss 1.8216165171729193, train accuracy 0.3377777777777778\n",
            "Epoch 2: train loss 1.740427401330736, train accuracy 0.37333333333333335\n",
            "Epoch 2: train loss 1.7421803540653653, train accuracy 0.3622222222222222\n",
            "Epoch 2: train loss 1.700790352291531, train accuracy 0.35333333333333333\n",
            "Epoch 2: train loss 1.7569852537579007, train accuracy 0.33555555555555555\n",
            "Epoch 2: train loss 1.7954177326626248, train accuracy 0.3422222222222222\n",
            "Epoch 2: train loss 1.7228840125931635, train accuracy 0.3844444444444444\n",
            "Epoch 3: train loss 1.7323168251249526, train accuracy 0.3622222222222222\n",
            "Epoch 3: train loss 1.7096137934260898, train accuracy 0.4111111111111111\n",
            "Epoch 3: train loss 1.7641321884261236, train accuracy 0.3688888888888889\n",
            "Epoch 3: train loss 1.7110816836357117, train accuracy 0.39555555555555555\n",
            "Epoch 3: train loss 1.7308909628126357, train accuracy 0.36\n",
            "Epoch 3: train loss 1.7384733027882047, train accuracy 0.38666666666666666\n",
            "Epoch 4: train loss 1.6861786842346191, train accuracy 0.37555555555555553\n",
            "Epoch 4: train loss 1.6645312772856817, train accuracy 0.36444444444444446\n",
            "Epoch 4: train loss 1.7462780409389072, train accuracy 0.3711111111111111\n",
            "Epoch 4: train loss 1.7309993240568373, train accuracy 0.38666666666666666\n",
            "Epoch 4: train loss 1.6764742136001587, train accuracy 0.3888888888888889\n",
            "Epoch 4: train loss 1.7584902776612177, train accuracy 0.38222222222222224\n",
            "Epoch 5: train loss 1.6654653482966952, train accuracy 0.36666666666666664Epoch 5: train loss 1.6639638344446819, train accuracy 0.3933333333333333\n",
            "\n",
            "[Client 62, round 8] fit, config: {'server_round': 8, 'local_epochs': 5}\n",
            "[Client 84, round 8] fit, config: {'server_round': 8, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.6848615209261577, train accuracy 0.37777777777777777\n",
            "Epoch 5: train loss 1.7089312606387668, train accuracy 0.38222222222222224\n",
            "[Client 33, round 8] fit, config: {'server_round': 8, 'local_epochs': 5}\n",
            "[Client 21, round 8] fit, config: {'server_round': 8, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.6911663214365642, train accuracy 0.3688888888888889\n",
            "Epoch 5: train loss 1.7172810236612956, train accuracy 0.35333333333333333\n",
            "Epoch 1: train loss 1.8240310218599107, train accuracy 0.33111111111111113\n",
            "Epoch 1: train loss 1.8363272746404011, train accuracy 0.3022222222222222\n",
            "Epoch 1: train loss 1.836006502310435, train accuracy 0.36\n",
            "Epoch 1: train loss 1.7868819104300604, train accuracy 0.33555555555555555\n",
            "Epoch 2: train loss 1.791412697898017, train accuracy 0.35333333333333333\n",
            "Epoch 2: train loss 1.7318802409701877, train accuracy 0.37555555555555553\n",
            "Epoch 2: train loss 1.711859729554918, train accuracy 0.3844444444444444\n",
            "Epoch 2: train loss 1.7530187500847711, train accuracy 0.3488888888888889\n",
            "Epoch 3: train loss 1.7486577497588263, train accuracy 0.3688888888888889\n",
            "Epoch 3: train loss 1.7340530024634466, train accuracy 0.35777777777777775\n",
            "Epoch 3: train loss 1.7144096626175775, train accuracy 0.35555555555555557\n",
            "Epoch 3: train loss 1.7659301890267267, train accuracy 0.32222222222222224\n",
            "Epoch 4: train loss 1.712199158138699, train accuracy 0.37777777777777777\n",
            "Epoch 4: train loss 1.6795185142093234, train accuracy 0.38666666666666666\n",
            "Epoch 4: train loss 1.7680529687139723, train accuracy 0.34444444444444444\n",
            "Epoch 4: train loss 1.7355554501215618, train accuracy 0.32222222222222224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:12:57,159 | server.py:229 | fit_round 8 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 8 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.6509576969676547, train accuracy 0.38\n",
            "Epoch 5: train loss 1.7004949450492859, train accuracy 0.33111111111111113\n",
            "Epoch 5: train loss 1.7122972011566162, train accuracy 0.3977777777777778\n",
            "Epoch 5: train loss 1.7204755809572008, train accuracy 0.3844444444444444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:13:00,996 | server.py:116 | fit progress: (8, 1.6776006150245666, {'accuracy': 0.3846}, 189.37085949199997)\n",
            "INFO:flower:fit progress: (8, 1.6776006150245666, {'accuracy': 0.3846}, 189.37085949199997)\n",
            "INFO flower 2023-05-25 22:13:01,003 | server.py:163 | evaluate_round 8: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 8: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:13:01,008 | server.py:215 | fit_round 9: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 9: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.6776006150245666 / accuracy 0.3846\n",
            "[Client 42, round 9] fit, config: {'server_round': 9, 'local_epochs': 5}\n",
            "[Client 43, round 9] fit, config: {'server_round': 9, 'local_epochs': 5}\n",
            "[Client 70, round 9] fit, config: {'server_round': 9, 'local_epochs': 5}\n",
            "[Client 9, round 9] fit, config: {'server_round': 9, 'local_epochs': 5}\n",
            "[Client 92, round 9] fit, config: {'server_round': 9, 'local_epochs': 5}\n",
            "[Client 50, round 9] fit, config: {'server_round': 9, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.8233773112297058, train accuracy 0.32666666666666666\n",
            "Epoch 1: train loss 1.7840587430530124, train accuracy 0.32222222222222224\n",
            "Epoch 1: train loss 1.7918536398145888, train accuracy 0.32222222222222224\n",
            "Epoch 1: train loss 1.8682206273078918, train accuracy 0.31333333333333335\n",
            "Epoch 1: train loss 1.8656095796161227, train accuracy 0.31333333333333335\n",
            "Epoch 1: train loss 1.6967030896080866, train accuracy 0.3711111111111111\n",
            "Epoch 2: train loss 1.8091319998105366, train accuracy 0.32\n",
            "Epoch 2: train loss 1.7340484923786588, train accuracy 0.34444444444444444Epoch 2: train loss 1.742183334297604, train accuracy 0.3711111111111111\n",
            "\n",
            "Epoch 2: train loss 1.7249772349993389, train accuracy 0.36666666666666664\n",
            "Epoch 2: train loss 1.7814073496394687, train accuracy 0.34444444444444444\n",
            "Epoch 2: train loss 1.663224505053626, train accuracy 0.39111111111111113\n",
            "Epoch 3: train loss 1.787892500559489, train accuracy 0.3377777777777778\n",
            "Epoch 3: train loss 1.7014145718680487, train accuracy 0.37333333333333335\n",
            "Epoch 3: train loss 1.7330177293883429, train accuracy 0.34444444444444444\n",
            "Epoch 3: train loss 1.7663259771135118, train accuracy 0.3488888888888889\n",
            "Epoch 3: train loss 1.627943542268541, train accuracy 0.4088888888888889\n",
            "Epoch 3: train loss 1.6475652654965718, train accuracy 0.37777777777777777\n",
            "Epoch 4: train loss 1.7332262794176738, train accuracy 0.38222222222222224\n",
            "Epoch 4: train loss 1.594286561012268, train accuracy 0.4311111111111111\n",
            "Epoch 4: train loss 1.6966368953386943, train accuracy 0.36444444444444446\n",
            "Epoch 4: train loss 1.6392355693711176, train accuracy 0.39555555555555555\n",
            "Epoch 4: train loss 1.7075354125764635, train accuracy 0.35777777777777775\n",
            "Epoch 4: train loss 1.681086626317766, train accuracy 0.36666666666666664\n",
            "Epoch 5: train loss 1.5331693887710571, train accuracy 0.43777777777777777\n",
            "[Client 58, round 9] fit, config: {'server_round': 9, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.70095474852456, train accuracy 0.37555555555555553\n",
            "[Client 49, round 9] fit, config: {'server_round': 9, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.6515117949909635, train accuracy 0.37333333333333335\n",
            "[Client 73, round 9] fit, config: {'server_round': 9, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.6732103493478563, train accuracy 0.36666666666666664\n",
            "[Client 99, round 9] fit, config: {'server_round': 9, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.6447272565629747, train accuracy 0.3622222222222222\n",
            "Epoch 5: train loss 1.6616005036565993, train accuracy 0.37333333333333335\n",
            "Epoch 1: train loss 1.8673576845063105, train accuracy 0.32666666666666666\n",
            "Epoch 1: train loss 1.823962840769026, train accuracy 0.3333333333333333\n",
            "Epoch 1: train loss 1.7683570848570929, train accuracy 0.33555555555555555\n",
            "Epoch 1: train loss 1.8498910797966852, train accuracy 0.28888888888888886\n",
            "Epoch 2: train loss 1.7113430566257901, train accuracy 0.41555555555555557\n",
            "Epoch 2: train loss 1.7155077854792278, train accuracy 0.37333333333333335\n",
            "Epoch 2: train loss 1.6616807182629902, train accuracy 0.37777777777777777\n",
            "Epoch 2: train loss 1.7322050001886156, train accuracy 0.3488888888888889\n",
            "Epoch 3: train loss 1.6959808998637729, train accuracy 0.41333333333333333\n",
            "Epoch 3: train loss 1.66952117284139, train accuracy 0.38666666666666666\n",
            "Epoch 3: train loss 1.5969240731663175, train accuracy 0.40444444444444444\n",
            "Epoch 3: train loss 1.7112640076213412, train accuracy 0.37777777777777777\n",
            "Epoch 4: train loss 1.6701517502466838, train accuracy 0.4111111111111111\n",
            "Epoch 4: train loss 1.6448412140210469, train accuracy 0.38222222222222224\n",
            "Epoch 4: train loss 1.5694692664676242, train accuracy 0.4311111111111111\n",
            "Epoch 4: train loss 1.6877946654955547, train accuracy 0.3888888888888889\n",
            "Epoch 5: train loss 1.6556775040096707, train accuracy 0.3977777777777778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:13:19,829 | server.py:229 | fit_round 9 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 9 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.5425923599137201, train accuracy 0.43555555555555553\n",
            "Epoch 5: train loss 1.6416058209207323, train accuracy 0.4022222222222222\n",
            "Epoch 5: train loss 1.6679681075943842, train accuracy 0.3711111111111111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:13:24,906 | server.py:116 | fit progress: (9, 1.6379253214597702, {'accuracy': 0.4}, 213.280571403)\n",
            "INFO:flower:fit progress: (9, 1.6379253214597702, {'accuracy': 0.4}, 213.280571403)\n",
            "INFO flower 2023-05-25 22:13:24,913 | server.py:163 | evaluate_round 9: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 9: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:13:24,916 | server.py:215 | fit_round 10: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 10: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.6379253214597702 / accuracy 0.4\n",
            "[Client 43, round 10] fit, config: {'server_round': 10, 'local_epochs': 5}\n",
            "[Client 2, round 10] fit, config: {'server_round': 10, 'local_epochs': 5}\n",
            "[Client 24, round 10] fit, config: {'server_round': 10, 'local_epochs': 5}\n",
            "[Client 11, round 10] fit, config: {'server_round': 10, 'local_epochs': 5}[Client 75, round 10] fit, config: {'server_round': 10, 'local_epochs': 5}\n",
            "\n",
            "[Client 80, round 10] fit, config: {'server_round': 10, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.7903186413976881, train accuracy 0.31555555555555553\n",
            "Epoch 1: train loss 1.785232702891032, train accuracy 0.38\n",
            "Epoch 1: train loss 1.7945445775985718, train accuracy 0.3422222222222222\n",
            "Epoch 1: train loss 1.7382120821211073, train accuracy 0.35555555555555557\n",
            "Epoch 1: train loss 1.805298474099901, train accuracy 0.3333333333333333\n",
            "Epoch 1: train loss 1.7710518836975098, train accuracy 0.31333333333333335\n",
            "Epoch 2: train loss 1.7290356821484036, train accuracy 0.37555555555555553\n",
            "Epoch 2: train loss 1.7236727542347379, train accuracy 0.35555555555555557\n",
            "Epoch 2: train loss 1.7499992847442627, train accuracy 0.35555555555555557\n",
            "Epoch 2: train loss 1.7124109731780157, train accuracy 0.37333333333333335\n",
            "Epoch 2: train loss 1.678868121571011, train accuracy 0.4022222222222222\n",
            "Epoch 2: train loss 1.7092770139376323, train accuracy 0.3622222222222222\n",
            "Epoch 3: train loss 1.6197023193041484, train accuracy 0.38666666666666666\n",
            "Epoch 3: train loss 1.6929328971438937, train accuracy 0.3933333333333333\n",
            "Epoch 3: train loss 1.6731602946917217, train accuracy 0.3711111111111111\n",
            "Epoch 3: train loss 1.685942464404636, train accuracy 0.37333333333333335\n",
            "Epoch 3: train loss 1.6739109887017145, train accuracy 0.3888888888888889\n",
            "Epoch 3: train loss 1.632414440313975, train accuracy 0.4022222222222222\n",
            "Epoch 4: train loss 1.650185181034936, train accuracy 0.4\n",
            "Epoch 4: train loss 1.6565270556343927, train accuracy 0.3933333333333333\n",
            "Epoch 4: train loss 1.6474269893434312, train accuracy 0.36666666666666664\n",
            "Epoch 4: train loss 1.6269526547855802, train accuracy 0.39555555555555555\n",
            "Epoch 4: train loss 1.6859363516171773, train accuracy 0.3422222222222222\n",
            "Epoch 4: train loss 1.6238846447732713, train accuracy 0.4022222222222222\n",
            "Epoch 5: train loss 1.6346829069985285, train accuracy 0.42\n",
            "[Client 46, round 10] fit, config: {'server_round': 10, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.6295969817373488, train accuracy 0.4\n",
            "[Client 1, round 10] fit, config: {'server_round': 10, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.6645007597075567, train accuracy 0.3711111111111111\n",
            "[Client 45, round 10] fit, config: {'server_round': 10, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.6388246946864657, train accuracy 0.3888888888888889\n",
            "[Client 29, round 10] fit, config: {'server_round': 10, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.6854136652416654, train accuracy 0.36\n",
            "Epoch 5: train loss 1.587803926732805, train accuracy 0.3977777777777778\n",
            "Epoch 1: train loss 1.8052222927411397, train accuracy 0.3288888888888889\n",
            "Epoch 1: train loss 1.7247630291514926, train accuracy 0.35777777777777775\n",
            "Epoch 1: train loss 1.77026590373781, train accuracy 0.35555555555555557\n",
            "Epoch 1: train loss 1.7915569278928969, train accuracy 0.3511111111111111\n",
            "Epoch 2: train loss 1.7193902333577473, train accuracy 0.35555555555555557\n",
            "Epoch 2: train loss 1.6949572761853535, train accuracy 0.3622222222222222\n",
            "Epoch 2: train loss 1.7331849998897977, train accuracy 0.3711111111111111\n",
            "Epoch 2: train loss 1.7139651311768427, train accuracy 0.36666666666666664\n",
            "Epoch 3: train loss 1.63054049677319, train accuracy 0.4222222222222222\n",
            "Epoch 3: train loss 1.682797948519389, train accuracy 0.37777777777777777\n",
            "Epoch 3: train loss 1.6830527120166354, train accuracy 0.35777777777777775\n",
            "Epoch 3: train loss 1.7357575231128268, train accuracy 0.3844444444444444\n",
            "Epoch 4: train loss 1.6277345948749118, train accuracy 0.39555555555555555\n",
            "Epoch 4: train loss 1.6888122624821134, train accuracy 0.3888888888888889\n",
            "Epoch 4: train loss 1.7092878023783367, train accuracy 0.37777777777777777\n",
            "Epoch 4: train loss 1.6876438193851047, train accuracy 0.35555555555555557\n",
            "Epoch 5: train loss 1.6209104392263625, train accuracy 0.37777777777777777\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:13:43,607 | server.py:229 | fit_round 10 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 10 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.6972334914737277, train accuracy 0.39111111111111113\n",
            "Epoch 5: train loss 1.6562637620502048, train accuracy 0.40444444444444444\n",
            "Epoch 5: train loss 1.6283752852016025, train accuracy 0.3888888888888889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:13:47,603 | server.py:116 | fit progress: (10, 1.6131660467386246, {'accuracy': 0.4068}, 235.97825295599995)\n",
            "INFO:flower:fit progress: (10, 1.6131660467386246, {'accuracy': 0.4068}, 235.97825295599995)\n",
            "INFO flower 2023-05-25 22:13:47,609 | server.py:163 | evaluate_round 10: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 10: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:13:47,614 | server.py:215 | fit_round 11: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 11: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.6131660467386246 / accuracy 0.4068\n",
            "[Client 51, round 11] fit, config: {'server_round': 11, 'local_epochs': 5}\n",
            "[Client 68, round 11] fit, config: {'server_round': 11, 'local_epochs': 5}\n",
            "[Client 64, round 11] fit, config: {'server_round': 11, 'local_epochs': 5}\n",
            "[Client 7, round 11] fit, config: {'server_round': 11, 'local_epochs': 5}\n",
            "[Client 92, round 11] fit, config: {'server_round': 11, 'local_epochs': 5}\n",
            "[Client 81, round 11] fit, config: {'server_round': 11, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.7793867058224149, train accuracy 0.3844444444444444\n",
            "Epoch 1: train loss 1.7225265900293987, train accuracy 0.3488888888888889\n",
            "Epoch 1: train loss 1.644637021753523, train accuracy 0.4066666666666667\n",
            "Epoch 1: train loss 1.7761435243818495, train accuracy 0.3511111111111111\n",
            "Epoch 1: train loss 1.7264782985051472, train accuracy 0.3711111111111111\n",
            "Epoch 1: train loss 1.763964229159885, train accuracy 0.3688888888888889\n",
            "Epoch 2: train loss 1.623242199420929, train accuracy 0.3977777777777778\n",
            "Epoch 2: train loss 1.6999697552786932, train accuracy 0.34444444444444444\n",
            "Epoch 2: train loss 1.7495878802405462, train accuracy 0.3711111111111111\n",
            "Epoch 2: train loss 1.6676129897435505, train accuracy 0.39111111111111113\n",
            "Epoch 2: train loss 1.7319769197040134, train accuracy 0.3711111111111111\n",
            "Epoch 2: train loss 1.7165268394682143, train accuracy 0.38\n",
            "Epoch 3: train loss 1.5576358371310763, train accuracy 0.42444444444444446\n",
            "Epoch 3: train loss 1.6587912638982136, train accuracy 0.38666666666666666\n",
            "Epoch 3: train loss 1.6859051452742682, train accuracy 0.4088888888888889\n",
            "Epoch 3: train loss 1.677506340874566, train accuracy 0.36666666666666664\n",
            "Epoch 3: train loss 1.6428789628876581, train accuracy 0.38222222222222224\n",
            "Epoch 3: train loss 1.6204189658164978, train accuracy 0.38222222222222224\n",
            "Epoch 4: train loss 1.567247814602322, train accuracy 0.4311111111111111\n",
            "Epoch 4: train loss 1.7042099502351549, train accuracy 0.39111111111111113\n",
            "Epoch 4: train loss 1.6042388280232747, train accuracy 0.39111111111111113\n",
            "Epoch 4: train loss 1.5931875440809462, train accuracy 0.44666666666666666\n",
            "Epoch 4: train loss 1.6304991841316223, train accuracy 0.38\n",
            "Epoch 4: train loss 1.6152948670917087, train accuracy 0.43777777777777777\n",
            "Epoch 5: train loss 1.6167903939882915, train accuracy 0.3688888888888889\n",
            "[Client 36, round 11] fit, config: {'server_round': 11, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.5340476632118225, train accuracy 0.45555555555555555\n",
            "[Client 63, round 11] fit, config: {'server_round': 11, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.5837824675771925, train accuracy 0.4688888888888889\n",
            "[Client 97, round 11] fit, config: {'server_round': 11, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.584591567516327, train accuracy 0.43555555555555553\n",
            "[Client 80, round 11] fit, config: {'server_round': 11, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.6203105648358662, train accuracy 0.4088888888888889\n",
            "Epoch 5: train loss 1.587290518813663, train accuracy 0.39111111111111113\n",
            "Epoch 1: train loss 1.7443333400620356, train accuracy 0.38222222222222224\n",
            "Epoch 1: train loss 1.7645914024776883, train accuracy 0.36666666666666664\n",
            "Epoch 1: train loss 1.7717396815617878, train accuracy 0.34444444444444444\n",
            "Epoch 1: train loss 1.7362215386496649, train accuracy 0.3622222222222222\n",
            "Epoch 2: train loss 1.6871565116776361, train accuracy 0.3844444444444444\n",
            "Epoch 2: train loss 1.6327861613697476, train accuracy 0.41555555555555557\n",
            "Epoch 2: train loss 1.7009139988157485, train accuracy 0.3688888888888889\n",
            "Epoch 2: train loss 1.6469781266318426, train accuracy 0.36666666666666664\n",
            "Epoch 3: train loss 1.644345137808058, train accuracy 0.4066666666666667\n",
            "Epoch 3: train loss 1.645056790775723, train accuracy 0.38222222222222224\n",
            "Epoch 3: train loss 1.6194305684831407, train accuracy 0.3933333333333333\n",
            "Epoch 3: train loss 1.650516602728102, train accuracy 0.36666666666666664\n",
            "Epoch 4: train loss 1.6440536909633212, train accuracy 0.37555555555555553\n",
            "Epoch 4: train loss 1.636330121093326, train accuracy 0.40444444444444444\n",
            "Epoch 4: train loss 1.6032574375470479, train accuracy 0.4177777777777778\n",
            "Epoch 4: train loss 1.6228618555598788, train accuracy 0.4266666666666667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:14:06,989 | server.py:229 | fit_round 11 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 11 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.614983532163832, train accuracy 0.4088888888888889\n",
            "Epoch 5: train loss 1.6446197628974915, train accuracy 0.3844444444444444\n",
            "Epoch 5: train loss 1.6228653457429674, train accuracy 0.4\n",
            "Epoch 5: train loss 1.6457768082618713, train accuracy 0.39555555555555555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:14:10,929 | server.py:116 | fit progress: (11, 1.5919593322277068, {'accuracy': 0.4185}, 259.303760176)\n",
            "INFO:flower:fit progress: (11, 1.5919593322277068, {'accuracy': 0.4185}, 259.303760176)\n",
            "INFO flower 2023-05-25 22:14:10,931 | server.py:163 | evaluate_round 11: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 11: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:14:10,943 | server.py:215 | fit_round 12: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 12: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.5919593322277068 / accuracy 0.4185\n",
            "[Client 92, round 12] fit, config: {'server_round': 12, 'local_epochs': 5}\n",
            "[Client 29, round 12] fit, config: {'server_round': 12, 'local_epochs': 5}\n",
            "[Client 69, round 12] fit, config: {'server_round': 12, 'local_epochs': 5}\n",
            "[Client 61, round 12] fit, config: {'server_round': 12, 'local_epochs': 5}\n",
            "[Client 22, round 12] fit, config: {'server_round': 12, 'local_epochs': 5}\n",
            "[Client 19, round 12] fit, config: {'server_round': 12, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.7484663658671908, train accuracy 0.35333333333333333\n",
            "Epoch 1: train loss 1.6820564203792148, train accuracy 0.36666666666666664\n",
            "Epoch 1: train loss 1.7441795931922064, train accuracy 0.3488888888888889\n",
            "Epoch 1: train loss 1.7387863132688735, train accuracy 0.34\n",
            "Epoch 1: train loss 1.7358534799681768, train accuracy 0.37333333333333335\n",
            "Epoch 1: train loss 1.696917262342241, train accuracy 0.3711111111111111\n",
            "Epoch 2: train loss 1.617538379298316, train accuracy 0.4\n",
            "Epoch 2: train loss 1.673088722758823, train accuracy 0.3688888888888889\n",
            "Epoch 2: train loss 1.698515084054735, train accuracy 0.3711111111111111\n",
            "Epoch 2: train loss 1.7177888684802585, train accuracy 0.36666666666666664\n",
            "Epoch 2: train loss 1.633590579032898, train accuracy 0.36666666666666664\n",
            "Epoch 2: train loss 1.6239293416341145, train accuracy 0.3933333333333333\n",
            "Epoch 3: train loss 1.5972348186704848, train accuracy 0.41333333333333333\n",
            "Epoch 3: train loss 1.6536204351319208, train accuracy 0.3844444444444444\n",
            "Epoch 3: train loss 1.65299787123998, train accuracy 0.3888888888888889\n",
            "Epoch 3: train loss 1.6639200581444635, train accuracy 0.38222222222222224\n",
            "Epoch 3: train loss 1.6743282477060955, train accuracy 0.33111111111111113\n",
            "Epoch 3: train loss 1.6266438166300456, train accuracy 0.38666666666666666\n",
            "Epoch 4: train loss 1.5596102939711676, train accuracy 0.4488888888888889\n",
            "Epoch 4: train loss 1.5799034701453314, train accuracy 0.42444444444444446\n",
            "Epoch 4: train loss 1.6054256425963507, train accuracy 0.4022222222222222\n",
            "Epoch 4: train loss 1.5840978291299608, train accuracy 0.3888888888888889\n",
            "Epoch 4: train loss 1.6390099459224277, train accuracy 0.3688888888888889\n",
            "Epoch 4: train loss 1.5645006563928392, train accuracy 0.4177777777777778\n",
            "Epoch 5: train loss 1.5301596654786005, train accuracy 0.4488888888888889\n",
            "[Client 68, round 12] fit, config: {'server_round': 12, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.651616911093394, train accuracy 0.37555555555555553\n",
            "[Client 56, round 12] fit, config: {'server_round': 12, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.6306080288357205, train accuracy 0.3888888888888889\n",
            "Epoch 5: train loss 1.5734338561693828, train accuracy 0.3933333333333333[Client 48, round 12] fit, config: {'server_round': 12, 'local_epochs': 5}\n",
            "\n",
            "[Client 96, round 12] fit, config: {'server_round': 12, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.6630745927492778, train accuracy 0.35555555555555557\n",
            "Epoch 5: train loss 1.5835493405659993, train accuracy 0.38222222222222224\n",
            "Epoch 1: train loss 1.7912695474094815, train accuracy 0.38\n",
            "Epoch 1: train loss 1.7111212544971042, train accuracy 0.38222222222222224\n",
            "Epoch 1: train loss 1.723488211631775, train accuracy 0.3688888888888889\n",
            "Epoch 1: train loss 1.7561342848671808, train accuracy 0.36666666666666664\n",
            "Epoch 2: train loss 1.6650912563006084, train accuracy 0.4088888888888889\n",
            "Epoch 2: train loss 1.6418941352102492, train accuracy 0.39111111111111113\n",
            "Epoch 2: train loss 1.675884571340349, train accuracy 0.3977777777777778Epoch 2: train loss 1.6390438675880432, train accuracy 0.3933333333333333\n",
            "\n",
            "Epoch 3: train loss 1.6523040533065796, train accuracy 0.43777777777777777\n",
            "Epoch 3: train loss 1.571023682753245, train accuracy 0.43777777777777777\n",
            "Epoch 3: train loss 1.5651527245839436, train accuracy 0.39111111111111113\n",
            "Epoch 3: train loss 1.6064632203843858, train accuracy 0.4222222222222222\n",
            "Epoch 4: train loss 1.6459670861562092, train accuracy 0.4088888888888889\n",
            "Epoch 4: train loss 1.564657191435496, train accuracy 0.4066666666666667\n",
            "Epoch 4: train loss 1.594138456715478, train accuracy 0.44\n",
            "Epoch 4: train loss 1.5667732159296672, train accuracy 0.44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:14:29,563 | server.py:229 | fit_round 12 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 12 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.5760521094004314, train accuracy 0.4577777777777778\n",
            "Epoch 5: train loss 1.5452667938338385, train accuracy 0.43777777777777777\n",
            "Epoch 5: train loss 1.594611300362481, train accuracy 0.4222222222222222\n",
            "Epoch 5: train loss 1.5805259943008423, train accuracy 0.42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:14:34,335 | server.py:116 | fit progress: (12, 1.5642313978075981, {'accuracy': 0.4288}, 282.709963921)\n",
            "INFO:flower:fit progress: (12, 1.5642313978075981, {'accuracy': 0.4288}, 282.709963921)\n",
            "INFO flower 2023-05-25 22:14:34,339 | server.py:163 | evaluate_round 12: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 12: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:14:34,346 | server.py:215 | fit_round 13: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 13: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.5642313978075981 / accuracy 0.4288\n",
            "[Client 59, round 13] fit, config: {'server_round': 13, 'local_epochs': 5}\n",
            "[Client 5, round 13] fit, config: {'server_round': 13, 'local_epochs': 5}\n",
            "[Client 1, round 13] fit, config: {'server_round': 13, 'local_epochs': 5}\n",
            "[Client 17, round 13] fit, config: {'server_round': 13, 'local_epochs': 5}[Client 58, round 13] fit, config: {'server_round': 13, 'local_epochs': 5}\n",
            "\n",
            "[Client 24, round 13] fit, config: {'server_round': 13, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.5911532640457153, train accuracy 0.40444444444444444\n",
            "Epoch 1: train loss 1.7426348328590393, train accuracy 0.35777777777777775\n",
            "Epoch 1: train loss 1.719906296994951, train accuracy 0.38222222222222224\n",
            "Epoch 1: train loss 1.7094771332210965, train accuracy 0.37555555555555553\n",
            "Epoch 1: train loss 1.7693172295888264, train accuracy 0.36\n",
            "Epoch 1: train loss 1.6974871754646301, train accuracy 0.36444444444444446\n",
            "Epoch 2: train loss 1.5444716546270583, train accuracy 0.42\n",
            "Epoch 2: train loss 1.6378795968161688, train accuracy 0.38666666666666666\n",
            "Epoch 2: train loss 1.6141765713691711, train accuracy 0.4222222222222222\n",
            "Epoch 2: train loss 1.600218567583296, train accuracy 0.4\n",
            "Epoch 2: train loss 1.658512082364824, train accuracy 0.38\n",
            "Epoch 2: train loss 1.6811591850386725, train accuracy 0.41555555555555557\n",
            "Epoch 3: train loss 1.6584836509492662, train accuracy 0.3933333333333333\n",
            "Epoch 3: train loss 1.6292200220955744, train accuracy 0.4444444444444444\n",
            "Epoch 3: train loss 1.554568350315094, train accuracy 0.45555555555555555\n",
            "Epoch 3: train loss 1.56544342968199, train accuracy 0.4022222222222222\n",
            "Epoch 3: train loss 1.5421904656622145, train accuracy 0.4222222222222222\n",
            "Epoch 3: train loss 1.6222841342290242, train accuracy 0.41555555555555557\n",
            "Epoch 4: train loss 1.469191802872552, train accuracy 0.43777777777777777\n",
            "Epoch 4: train loss 1.5603355367978413, train accuracy 0.4222222222222222\n",
            "Epoch 4: train loss 1.5941958758566115, train accuracy 0.4222222222222222\n",
            "Epoch 4: train loss 1.6438246965408325, train accuracy 0.3844444444444444\n",
            "Epoch 4: train loss 1.5922582281960382, train accuracy 0.4177777777777778\n",
            "Epoch 4: train loss 1.644605490896437, train accuracy 0.4022222222222222\n",
            "Epoch 5: train loss 1.6235288712713454, train accuracy 0.4066666666666667\n",
            "[Client 2, round 13] fit, config: {'server_round': 13, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.5544664528634813, train accuracy 0.42\n",
            "[Client 32, round 13] fit, config: {'server_round': 13, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.6044066084755793, train accuracy 0.4222222222222222\n",
            "Epoch 5: train loss 1.4827589260207281, train accuracy 0.44666666666666666[Client 45, round 13] fit, config: {'server_round': 13, 'local_epochs': 5}\n",
            "\n",
            "[Client 87, round 13] fit, config: {'server_round': 13, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.5852868954340618, train accuracy 0.45111111111111113\n",
            "Epoch 5: train loss 1.5653339160813227, train accuracy 0.4266666666666667\n",
            "Epoch 1: train loss 1.6918530199262831, train accuracy 0.38666666666666666\n",
            "Epoch 1: train loss 1.7607262200779386, train accuracy 0.35555555555555557\n",
            "Epoch 1: train loss 1.682774027188619, train accuracy 0.37777777777777777\n",
            "Epoch 1: train loss 1.7826988961961534, train accuracy 0.35555555555555557\n",
            "Epoch 2: train loss 1.63549225197898, train accuracy 0.37777777777777777\n",
            "Epoch 2: train loss 1.683502369456821, train accuracy 0.39111111111111113\n",
            "Epoch 2: train loss 1.6376473903656006, train accuracy 0.4022222222222222\n",
            "Epoch 2: train loss 1.735509329371982, train accuracy 0.3688888888888889\n",
            "Epoch 3: train loss 1.5769791073269315, train accuracy 0.41555555555555557\n",
            "Epoch 3: train loss 1.6409271823035345, train accuracy 0.3844444444444444\n",
            "Epoch 3: train loss 1.610031293498145, train accuracy 0.4\n",
            "Epoch 3: train loss 1.685626056459215, train accuracy 0.3977777777777778\n",
            "Epoch 4: train loss 1.5188907716009352, train accuracy 0.4688888888888889\n",
            "Epoch 4: train loss 1.6027071608437433, train accuracy 0.4311111111111111\n",
            "Epoch 4: train loss 1.559293058183458, train accuracy 0.4311111111111111\n",
            "Epoch 4: train loss 1.6549647781583998, train accuracy 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:14:53,504 | server.py:229 | fit_round 13 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 13 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.5548883610301547, train accuracy 0.4266666666666667\n",
            "Epoch 5: train loss 1.5230549308988783, train accuracy 0.43555555555555553\n",
            "Epoch 5: train loss 1.5789656307962205, train accuracy 0.41333333333333333\n",
            "Epoch 5: train loss 1.62755505906211, train accuracy 0.37333333333333335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:14:57,530 | server.py:116 | fit progress: (13, 1.5418420234322547, {'accuracy': 0.4391}, 305.90509298399996)\n",
            "INFO:flower:fit progress: (13, 1.5418420234322547, {'accuracy': 0.4391}, 305.90509298399996)\n",
            "INFO flower 2023-05-25 22:14:57,532 | server.py:163 | evaluate_round 13: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 13: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:14:57,542 | server.py:215 | fit_round 14: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 14: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.5418420234322547 / accuracy 0.4391\n",
            "[Client 34, round 14] fit, config: {'server_round': 14, 'local_epochs': 5}\n",
            "[Client 81, round 14] fit, config: {'server_round': 14, 'local_epochs': 5}\n",
            "[Client 55, round 14] fit, config: {'server_round': 14, 'local_epochs': 5}\n",
            "[Client 0, round 14] fit, config: {'server_round': 14, 'local_epochs': 5}\n",
            "[Client 53, round 14] fit, config: {'server_round': 14, 'local_epochs': 5}\n",
            "[Client 13, round 14] fit, config: {'server_round': 14, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.654527809884813, train accuracy 0.38666666666666666\n",
            "Epoch 1: train loss 1.6319032576349046, train accuracy 0.37333333333333335\n",
            "Epoch 1: train loss 1.6864947610431247, train accuracy 0.37333333333333335\n",
            "Epoch 1: train loss 1.6941330234209697, train accuracy 0.38\n",
            "Epoch 1: train loss 1.6282584468523662, train accuracy 0.35555555555555557\n",
            "Epoch 1: train loss 1.7229411005973816, train accuracy 0.36\n",
            "Epoch 2: train loss 1.5562942889001634, train accuracy 0.41555555555555557\n",
            "Epoch 2: train loss 1.5293832222620647, train accuracy 0.4266666666666667\n",
            "Epoch 2: train loss 1.66603598329756, train accuracy 0.4Epoch 2: train loss 1.6622440814971924, train accuracy 0.4022222222222222\n",
            "\n",
            "Epoch 2: train loss 1.6331646641095479, train accuracy 0.3844444444444444\n",
            "Epoch 2: train loss 1.5833120677206252, train accuracy 0.4088888888888889\n",
            "Epoch 3: train loss 1.5424644417232938, train accuracy 0.41555555555555557\n",
            "Epoch 3: train loss 1.6420447892612882, train accuracy 0.4066666666666667\n",
            "Epoch 3: train loss 1.5238703621758356, train accuracy 0.41333333333333333\n",
            "Epoch 3: train loss 1.5801622403992548, train accuracy 0.40444444444444444\n",
            "Epoch 3: train loss 1.591981503698561, train accuracy 0.4088888888888889\n",
            "Epoch 3: train loss 1.5240261223581102, train accuracy 0.4711111111111111\n",
            "Epoch 4: train loss 1.5932032995753818, train accuracy 0.3844444444444444\n",
            "Epoch 4: train loss 1.5147573484314814, train accuracy 0.43333333333333335\n",
            "Epoch 4: train loss 1.600419282913208, train accuracy 0.4111111111111111\n",
            "Epoch 4: train loss 1.5930092467202082, train accuracy 0.4288888888888889\n",
            "Epoch 4: train loss 1.476546823978424, train accuracy 0.41333333333333333\n",
            "Epoch 4: train loss 1.5273742477099101, train accuracy 0.4088888888888889\n",
            "Epoch 5: train loss 1.5626822511355083, train accuracy 0.44666666666666666\n",
            "[Client 79, round 14] fit, config: {'server_round': 14, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.5332141915957134, train accuracy 0.4444444444444444\n",
            "[Client 8, round 14] fit, config: {'server_round': 14, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.5532898637983534, train accuracy 0.4088888888888889\n",
            "[Client 65, round 14] fit, config: {'server_round': 14, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4331272972954645, train accuracy 0.44222222222222224\n",
            "[Client 45, round 14] fit, config: {'server_round': 14, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.532763679822286, train accuracy 0.42444444444444446\n",
            "Epoch 5: train loss 1.522933257950677, train accuracy 0.43555555555555553\n",
            "Epoch 1: train loss 1.694237185849084, train accuracy 0.39111111111111113\n",
            "Epoch 1: train loss 1.795479072464837, train accuracy 0.34\n",
            "Epoch 1: train loss 1.6799229780832927, train accuracy 0.37555555555555553\n",
            "Epoch 1: train loss 1.7200551562839084, train accuracy 0.36666666666666664\n",
            "Epoch 2: train loss 1.6282378170225356, train accuracy 0.41555555555555557\n",
            "Epoch 2: train loss 1.6851122577985127, train accuracy 0.3844444444444444\n",
            "Epoch 2: train loss 1.5975118279457092, train accuracy 0.41555555555555557\n",
            "Epoch 2: train loss 1.6096422606044345, train accuracy 0.4066666666666667\n",
            "Epoch 3: train loss 1.525068912241194, train accuracy 0.4488888888888889\n",
            "Epoch 3: train loss 1.654530902703603, train accuracy 0.41555555555555557\n",
            "Epoch 3: train loss 1.6238786180814107, train accuracy 0.4111111111111111\n",
            "Epoch 3: train loss 1.599437905682458, train accuracy 0.4111111111111111\n",
            "Epoch 4: train loss 1.508374313513438, train accuracy 0.4222222222222222\n",
            "Epoch 4: train loss 1.6211920181910198, train accuracy 0.4111111111111111\n",
            "Epoch 4: train loss 1.6286644339561462, train accuracy 0.40444444444444444\n",
            "Epoch 4: train loss 1.568999429543813, train accuracy 0.4488888888888889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:15:18,400 | server.py:229 | fit_round 14 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 14 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.5314638747109308, train accuracy 0.45555555555555555\n",
            "Epoch 5: train loss 1.604784243636661, train accuracy 0.4288888888888889\n",
            "Epoch 5: train loss 1.5093077222506206, train accuracy 0.42\n",
            "Epoch 5: train loss 1.6153526703516643, train accuracy 0.40444444444444444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:15:23,610 | server.py:116 | fit progress: (14, 1.5269755792617798, {'accuracy': 0.4436}, 331.98483005299994)\n",
            "INFO:flower:fit progress: (14, 1.5269755792617798, {'accuracy': 0.4436}, 331.98483005299994)\n",
            "INFO flower 2023-05-25 22:15:23,614 | server.py:163 | evaluate_round 14: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 14: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:15:23,617 | server.py:215 | fit_round 15: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 15: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.5269755792617798 / accuracy 0.4436\n",
            "[Client 90, round 15] fit, config: {'server_round': 15, 'local_epochs': 5}\n",
            "[Client 11, round 15] fit, config: {'server_round': 15, 'local_epochs': 5}\n",
            "[Client 10, round 15] fit, config: {'server_round': 15, 'local_epochs': 5}\n",
            "[Client 55, round 15] fit, config: {'server_round': 15, 'local_epochs': 5}\n",
            "[Client 68, round 15] fit, config: {'server_round': 15, 'local_epochs': 5}\n",
            "[Client 1, round 15] fit, config: {'server_round': 15, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.6466760966512892, train accuracy 0.38666666666666666\n",
            "Epoch 1: train loss 1.6945106519593134, train accuracy 0.3622222222222222\n",
            "Epoch 1: train loss 1.725978136062622, train accuracy 0.3977777777777778\n",
            "Epoch 1: train loss 1.775304787688785, train accuracy 0.3511111111111111\n",
            "Epoch 1: train loss 1.6857695447074041, train accuracy 0.36\n",
            "Epoch 1: train loss 1.7227129936218262, train accuracy 0.3622222222222222\n",
            "Epoch 2: train loss 1.5831953949398465, train accuracy 0.3977777777777778\n",
            "Epoch 2: train loss 1.7355846961339314, train accuracy 0.37555555555555553\n",
            "Epoch 2: train loss 1.5450920197698805, train accuracy 0.4222222222222222\n",
            "Epoch 2: train loss 1.6806172264946833, train accuracy 0.40444444444444444\n",
            "Epoch 2: train loss 1.6069394018914964, train accuracy 0.3711111111111111\n",
            "Epoch 2: train loss 1.6297850476370916, train accuracy 0.42444444444444446\n",
            "Epoch 3: train loss 1.5495148499806721, train accuracy 0.4288888888888889\n",
            "Epoch 3: train loss 1.5763048595852323, train accuracy 0.37777777777777777\n",
            "Epoch 3: train loss 1.689409679836697, train accuracy 0.39111111111111113\n",
            "Epoch 3: train loss 1.5649250944455464, train accuracy 0.4577777777777778\n",
            "Epoch 3: train loss 1.5794392625490825, train accuracy 0.4177777777777778\n",
            "Epoch 3: train loss 1.5737361974186368, train accuracy 0.44\n",
            "Epoch 4: train loss 1.5870928764343262, train accuracy 0.41333333333333333\n",
            "Epoch 4: train loss 1.638276947869195, train accuracy 0.3888888888888889\n",
            "Epoch 4: train loss 1.5271804531415303, train accuracy 0.4777777777777778\n",
            "Epoch 4: train loss 1.5228634013070002, train accuracy 0.41555555555555557\n",
            "Epoch 4: train loss 1.5348603592978582, train accuracy 0.43777777777777777\n",
            "Epoch 4: train loss 1.5483573873837788, train accuracy 0.45555555555555555\n",
            "Epoch 5: train loss 1.5863652494218614, train accuracy 0.4266666666666667\n",
            "[Client 48, round 15] fit, config: {'server_round': 15, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.5331526398658752, train accuracy 0.3977777777777778\n",
            "Epoch 5: train loss 1.5015144679281447, train accuracy 0.41555555555555557\n",
            "[Client 9, round 15] fit, config: {'server_round': 15, 'local_epochs': 5}\n",
            "[Client 69, round 15] fit, config: {'server_round': 15, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.637870921028985, train accuracy 0.4\n",
            "Epoch 5: train loss 1.538132561577691, train accuracy 0.43333333333333335\n",
            "[Client 88, round 15] fit, config: {'server_round': 15, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.5395373702049255, train accuracy 0.4488888888888889\n",
            "Epoch 1: train loss 1.6618478298187256, train accuracy 0.36\n",
            "Epoch 1: train loss 1.7301110956403944, train accuracy 0.3622222222222222\n",
            "Epoch 1: train loss 1.6997510062323675, train accuracy 0.37555555555555553Epoch 1: train loss 1.6049345930417378, train accuracy 0.4022222222222222\n",
            "\n",
            "Epoch 2: train loss 1.5578698449664645, train accuracy 0.40444444444444444\n",
            "Epoch 2: train loss 1.6238940755526226, train accuracy 0.41333333333333333\n",
            "Epoch 2: train loss 1.683510012096829, train accuracy 0.38666666666666666\n",
            "Epoch 2: train loss 1.5318628682030573, train accuracy 0.44666666666666666\n",
            "Epoch 3: train loss 1.5476759009891086, train accuracy 0.3933333333333333\n",
            "Epoch 3: train loss 1.595304098394182, train accuracy 0.40444444444444444\n",
            "Epoch 3: train loss 1.6422349214553833, train accuracy 0.3888888888888889\n",
            "Epoch 3: train loss 1.5112687481774225, train accuracy 0.4222222222222222\n",
            "Epoch 4: train loss 1.4943752023908827, train accuracy 0.4111111111111111\n",
            "Epoch 4: train loss 1.5122908155123393, train accuracy 0.45555555555555555\n",
            "Epoch 4: train loss 1.6241937610838149, train accuracy 0.4088888888888889\n",
            "Epoch 4: train loss 1.5574231412675645, train accuracy 0.4444444444444444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:15:43,336 | server.py:229 | fit_round 15 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 15 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.493550909890069, train accuracy 0.4288888888888889\n",
            "Epoch 5: train loss 1.5317591494984097, train accuracy 0.43555555555555553\n",
            "Epoch 5: train loss 1.5573461916711595, train accuracy 0.4288888888888889\n",
            "Epoch 5: train loss 1.5357808868090312, train accuracy 0.43333333333333335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:15:48,302 | server.py:116 | fit progress: (15, 1.5104037708044051, {'accuracy': 0.4557}, 356.67664816999996)\n",
            "INFO:flower:fit progress: (15, 1.5104037708044051, {'accuracy': 0.4557}, 356.67664816999996)\n",
            "INFO flower 2023-05-25 22:15:48,306 | server.py:163 | evaluate_round 15: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 15: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:15:48,311 | server.py:215 | fit_round 16: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 16: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.5104037708044051 / accuracy 0.4557\n",
            "[Client 81, round 16] fit, config: {'server_round': 16, 'local_epochs': 5}\n",
            "[Client 51, round 16] fit, config: {'server_round': 16, 'local_epochs': 5}\n",
            "[Client 41, round 16] fit, config: {'server_round': 16, 'local_epochs': 5}[Client 3, round 16] fit, config: {'server_round': 16, 'local_epochs': 5}\n",
            "\n",
            "[Client 33, round 16] fit, config: {'server_round': 16, 'local_epochs': 5}\n",
            "[Client 60, round 16] fit, config: {'server_round': 16, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.587822159131368, train accuracy 0.42444444444444446\n",
            "Epoch 1: train loss 1.7051379283269246, train accuracy 0.36444444444444446\n",
            "Epoch 1: train loss 1.6812505655818515, train accuracy 0.39111111111111113\n",
            "Epoch 1: train loss 1.7064109577072992, train accuracy 0.38222222222222224\n",
            "Epoch 1: train loss 1.6921059025658503, train accuracy 0.38\n",
            "Epoch 1: train loss 1.603406462404463, train accuracy 0.38666666666666666\n",
            "Epoch 2: train loss 1.5247482392523024, train accuracy 0.4533333333333333\n",
            "Epoch 2: train loss 1.5819849504364862, train accuracy 0.43333333333333335\n",
            "Epoch 2: train loss 1.6005659566985235, train accuracy 0.4288888888888889\n",
            "Epoch 2: train loss 1.4790088335673015, train accuracy 0.44222222222222224\n",
            "Epoch 2: train loss 1.6343226962619357, train accuracy 0.37777777777777777\n",
            "Epoch 2: train loss 1.6752290460798476, train accuracy 0.39555555555555555\n",
            "Epoch 3: train loss 1.5614360902044508, train accuracy 0.4222222222222222\n",
            "Epoch 3: train loss 1.530856966972351, train accuracy 0.45111111111111113\n",
            "Epoch 3: train loss 1.4381417565875583, train accuracy 0.4822222222222222\n",
            "Epoch 3: train loss 1.5975140399403043, train accuracy 0.44222222222222224\n",
            "Epoch 3: train loss 1.4910163150893316, train accuracy 0.4688888888888889\n",
            "Epoch 3: train loss 1.6005545987023249, train accuracy 0.39555555555555555\n",
            "Epoch 4: train loss 1.5329047110345628, train accuracy 0.41555555555555557\n",
            "Epoch 4: train loss 1.5132081707318623, train accuracy 0.43555555555555553\n",
            "Epoch 4: train loss 1.4159219794803195, train accuracy 0.46444444444444444\n",
            "Epoch 4: train loss 1.5376196569866605, train accuracy 0.43777777777777777\n",
            "Epoch 4: train loss 1.3736528952916462, train accuracy 0.5044444444444445\n",
            "Epoch 4: train loss 1.5934680501619976, train accuracy 0.4311111111111111\n",
            "Epoch 5: train loss 1.5255915191438463, train accuracy 0.4288888888888889\n",
            "[Client 4, round 16] fit, config: {'server_round': 16, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4790695640775893, train accuracy 0.44666666666666666\n",
            "[Client 96, round 16] fit, config: {'server_round': 16, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4799293412102594, train accuracy 0.4911111111111111\n",
            "[Client 71, round 16] fit, config: {'server_round': 16, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.3895130157470703, train accuracy 0.48\n",
            "[Client 42, round 16] fit, config: {'server_round': 16, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.3906087478001912, train accuracy 0.47333333333333333\n",
            "Epoch 5: train loss 1.5721397466129727, train accuracy 0.43777777777777777\n",
            "Epoch 1: train loss 1.6498799853854709, train accuracy 0.38222222222222224\n",
            "Epoch 1: train loss 1.6684039102660284, train accuracy 0.4111111111111111\n",
            "Epoch 1: train loss 1.6622965931892395, train accuracy 0.41555555555555557\n",
            "Epoch 1: train loss 1.6626848975817363, train accuracy 0.40444444444444444\n",
            "Epoch 2: train loss 1.563364413049486, train accuracy 0.41555555555555557\n",
            "Epoch 2: train loss 1.5416545271873474, train accuracy 0.4711111111111111\n",
            "Epoch 2: train loss 1.5691309372584026, train accuracy 0.4288888888888889\n",
            "Epoch 2: train loss 1.6554674572414823, train accuracy 0.37333333333333335\n",
            "Epoch 3: train loss 1.541651513841417, train accuracy 0.4111111111111111\n",
            "Epoch 3: train loss 1.5525032414330378, train accuracy 0.44666666666666666\n",
            "Epoch 3: train loss 1.5150219400723774, train accuracy 0.4488888888888889\n",
            "Epoch 3: train loss 1.5625088943375482, train accuracy 0.42\n",
            "Epoch 4: train loss 1.5751967430114746, train accuracy 0.41333333333333333\n",
            "Epoch 4: train loss 1.530202395386166, train accuracy 0.43777777777777777\n",
            "Epoch 4: train loss 1.544200513097975, train accuracy 0.46\n",
            "Epoch 4: train loss 1.4902890854411655, train accuracy 0.4622222222222222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:16:07,711 | server.py:229 | fit_round 16 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 16 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.5154888431231182, train accuracy 0.4577777777777778\n",
            "Epoch 5: train loss 1.518661896387736, train accuracy 0.4666666666666667\n",
            "Epoch 5: train loss 1.54494927989112, train accuracy 0.44\n",
            "Epoch 5: train loss 1.4827532039748297, train accuracy 0.44222222222222224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:16:11,484 | server.py:116 | fit progress: (16, 1.5006945283710957, {'accuracy': 0.4497}, 379.858524909)\n",
            "INFO:flower:fit progress: (16, 1.5006945283710957, {'accuracy': 0.4497}, 379.858524909)\n",
            "INFO flower 2023-05-25 22:16:11,489 | server.py:163 | evaluate_round 16: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 16: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:16:11,491 | server.py:215 | fit_round 17: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 17: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.5006945283710957 / accuracy 0.4497\n",
            "[Client 53, round 17] fit, config: {'server_round': 17, 'local_epochs': 5}\n",
            "[Client 44, round 17] fit, config: {'server_round': 17, 'local_epochs': 5}\n",
            "[Client 3, round 17] fit, config: {'server_round': 17, 'local_epochs': 5}\n",
            "[Client 20, round 17] fit, config: {'server_round': 17, 'local_epochs': 5}\n",
            "[Client 81, round 17] fit, config: {'server_round': 17, 'local_epochs': 5}\n",
            "[Client 8, round 17] fit, config: {'server_round': 17, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.6399652030732896, train accuracy 0.4022222222222222\n",
            "Epoch 1: train loss 1.6875756714079115, train accuracy 0.3977777777777778\n",
            "Epoch 1: train loss 1.6624932554033067, train accuracy 0.4\n",
            "Epoch 1: train loss 1.509513841734992, train accuracy 0.4688888888888889\n",
            "Epoch 1: train loss 1.644462486108144, train accuracy 0.3711111111111111\n",
            "Epoch 1: train loss 1.6085371242629156, train accuracy 0.4088888888888889\n",
            "Epoch 2: train loss 1.604998721016778, train accuracy 0.43777777777777777\n",
            "Epoch 2: train loss 1.5847970379723444, train accuracy 0.41333333333333333\n",
            "Epoch 2: train loss 1.4498330023553636, train accuracy 0.4822222222222222Epoch 2: train loss 1.5662809014320374, train accuracy 0.3977777777777778\n",
            "\n",
            "Epoch 2: train loss 1.5389421184857686, train accuracy 0.3977777777777778\n",
            "Epoch 2: train loss 1.551357752747006, train accuracy 0.4177777777777778\n",
            "Epoch 3: train loss 1.5942838191986084, train accuracy 0.4177777777777778\n",
            "Epoch 3: train loss 1.589553005165524, train accuracy 0.42444444444444446\n",
            "Epoch 3: train loss 1.3913085990481906, train accuracy 0.5177777777777778\n",
            "Epoch 3: train loss 1.5376975933710735, train accuracy 0.4311111111111111\n",
            "Epoch 3: train loss 1.562512735525767, train accuracy 0.4222222222222222\n",
            "Epoch 3: train loss 1.5267114175690546, train accuracy 0.4066666666666667\n",
            "Epoch 4: train loss 1.59138290087382, train accuracy 0.4088888888888889\n",
            "Epoch 4: train loss 1.558746702141232, train accuracy 0.45555555555555555\n",
            "Epoch 4: train loss 1.344802028603024, train accuracy 0.5022222222222222\n",
            "Epoch 4: train loss 1.557465672492981, train accuracy 0.42\n",
            "Epoch 4: train loss 1.4699227677451239, train accuracy 0.4822222222222222\n",
            "Epoch 4: train loss 1.478378759490119, train accuracy 0.4266666666666667\n",
            "Epoch 5: train loss 1.5239775710635715, train accuracy 0.44222222222222224\n",
            "[Client 91, round 17] fit, config: {'server_round': 17, 'local_epochs': 5}Epoch 5: train loss 1.5449331204096477, train accuracy 0.4288888888888889\n",
            "\n",
            "[Client 86, round 17] fit, config: {'server_round': 17, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.501865824063619, train accuracy 0.4488888888888889\n",
            "[Client 18, round 17] fit, config: {'server_round': 17, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4630052248636882, train accuracy 0.4688888888888889\n",
            "[Client 47, round 17] fit, config: {'server_round': 17, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.3595596651236217, train accuracy 0.5133333333333333\n",
            "Epoch 5: train loss 1.51781431833903, train accuracy 0.42444444444444446\n",
            "Epoch 1: train loss 1.6709546380572848, train accuracy 0.4111111111111111\n",
            "Epoch 1: train loss 1.7032924824290805, train accuracy 0.39111111111111113\n",
            "Epoch 1: train loss 1.5851484537124634, train accuracy 0.4022222222222222\n",
            "Epoch 1: train loss 1.5955175757408142, train accuracy 0.4\n",
            "Epoch 2: train loss 1.664263082875146, train accuracy 0.3888888888888889\n",
            "Epoch 2: train loss 1.544785565800137, train accuracy 0.43777777777777777\n",
            "Epoch 2: train loss 1.538460546069675, train accuracy 0.4488888888888889\n",
            "Epoch 2: train loss 1.4959006773100958, train accuracy 0.46444444444444444\n",
            "Epoch 3: train loss 1.5607637763023376, train accuracy 0.45555555555555555\n",
            "Epoch 3: train loss 1.51038349337048, train accuracy 0.43555555555555553\n",
            "Epoch 3: train loss 1.4819752640194364, train accuracy 0.4577777777777778\n",
            "Epoch 3: train loss 1.467723309993744, train accuracy 0.4622222222222222\n",
            "Epoch 4: train loss 1.615707563029395, train accuracy 0.4177777777777778\n",
            "Epoch 4: train loss 1.5421088735262554, train accuracy 0.4311111111111111\n",
            "Epoch 4: train loss 1.4568938745392694, train accuracy 0.49333333333333335\n",
            "Epoch 4: train loss 1.4829965829849243, train accuracy 0.43333333333333335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:16:29,144 | server.py:229 | fit_round 17 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 17 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.5148765113618639, train accuracy 0.4711111111111111\n",
            "Epoch 5: train loss 1.5001459982660081, train accuracy 0.45555555555555555\n",
            "Epoch 5: train loss 1.4514331420262654, train accuracy 0.4911111111111111\n",
            "Epoch 5: train loss 1.451158391104804, train accuracy 0.46\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:16:34,275 | server.py:116 | fit progress: (17, 1.4792648033797742, {'accuracy': 0.4661}, 402.649639478)\n",
            "INFO:flower:fit progress: (17, 1.4792648033797742, {'accuracy': 0.4661}, 402.649639478)\n",
            "INFO flower 2023-05-25 22:16:34,281 | server.py:163 | evaluate_round 17: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 17: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:16:34,285 | server.py:215 | fit_round 18: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 18: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.4792648033797742 / accuracy 0.4661\n",
            "[Client 85, round 18] fit, config: {'server_round': 18, 'local_epochs': 5}\n",
            "[Client 30, round 18] fit, config: {'server_round': 18, 'local_epochs': 5}[Client 10, round 18] fit, config: {'server_round': 18, 'local_epochs': 5}\n",
            "\n",
            "[Client 95, round 18] fit, config: {'server_round': 18, 'local_epochs': 5}\n",
            "[Client 80, round 18] fit, config: {'server_round': 18, 'local_epochs': 5}\n",
            "[Client 7, round 18] fit, config: {'server_round': 18, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.6866581638654072, train accuracy 0.39555555555555555\n",
            "Epoch 1: train loss 1.592482282055749, train accuracy 0.4111111111111111\n",
            "Epoch 1: train loss 1.6946136289172702, train accuracy 0.4\n",
            "Epoch 1: train loss 1.6643790072864957, train accuracy 0.4288888888888889\n",
            "Epoch 1: train loss 1.603189918729994, train accuracy 0.39555555555555555\n",
            "Epoch 1: train loss 1.6468074785338507, train accuracy 0.37777777777777777\n",
            "Epoch 2: train loss 1.6052889559004042, train accuracy 0.4088888888888889\n",
            "Epoch 2: train loss 1.5434619983037312, train accuracy 0.43333333333333335\n",
            "Epoch 2: train loss 1.5640057855182223, train accuracy 0.4533333333333333\n",
            "Epoch 2: train loss 1.5341873566309612, train accuracy 0.43777777777777777\n",
            "Epoch 2: train loss 1.5415788557794359, train accuracy 0.45555555555555555\n",
            "Epoch 2: train loss 1.5940819382667542, train accuracy 0.3977777777777778\n",
            "Epoch 3: train loss 1.5777371989356146, train accuracy 0.4266666666666667\n",
            "Epoch 3: train loss 1.5105765395694308, train accuracy 0.4866666666666667\n",
            "Epoch 3: train loss 1.5710702406035528, train accuracy 0.4177777777777778\n",
            "Epoch 3: train loss 1.5414633552233379, train accuracy 0.47555555555555556\n",
            "Epoch 3: train loss 1.5207374559508429, train accuracy 0.4533333333333333\n",
            "Epoch 3: train loss 1.5345186392466228, train accuracy 0.4488888888888889\n",
            "Epoch 4: train loss 1.482515447669559, train accuracy 0.45555555555555555\n",
            "Epoch 4: train loss 1.5501924223370023, train accuracy 0.44\n",
            "Epoch 4: train loss 1.5428309639294941, train accuracy 0.4288888888888889\n",
            "Epoch 4: train loss 1.4628095626831055, train accuracy 0.4911111111111111\n",
            "Epoch 4: train loss 1.49193541208903, train accuracy 0.45111111111111113\n",
            "Epoch 4: train loss 1.4779153135087755, train accuracy 0.47333333333333333\n",
            "Epoch 5: train loss 1.5093687507841322, train accuracy 0.45555555555555555\n",
            "[Client 97, round 18] fit, config: {'server_round': 18, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4731743269496493, train accuracy 0.47555555555555556\n",
            "[Client 66, round 18] fit, config: {'server_round': 18, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.5440186262130737, train accuracy 0.43777777777777777\n",
            "[Client 49, round 18] fit, config: {'server_round': 18, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4519789550039504, train accuracy 0.4577777777777778\n",
            "Epoch 5: train loss 1.50895674361123, train accuracy 0.46444444444444444\n",
            "[Client 68, round 18] fit, config: {'server_round': 18, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.5567610594961379, train accuracy 0.4622222222222222\n",
            "Epoch 1: train loss 1.613039367728763, train accuracy 0.43777777777777777\n",
            "Epoch 1: train loss 1.6989767418967352, train accuracy 0.4\n",
            "Epoch 1: train loss 1.6261703305774264, train accuracy 0.39111111111111113\n",
            "Epoch 1: train loss 1.7124896181954279, train accuracy 0.40444444444444444\n",
            "Epoch 2: train loss 1.55062421825197, train accuracy 0.43777777777777777\n",
            "Epoch 2: train loss 1.6182378199365404, train accuracy 0.3977777777777778\n",
            "Epoch 2: train loss 1.6060690879821777, train accuracy 0.4311111111111111\n",
            "Epoch 2: train loss 1.4869338075319927, train accuracy 0.4622222222222222\n",
            "Epoch 3: train loss 1.546647502316369, train accuracy 0.4222222222222222\n",
            "Epoch 3: train loss 1.5522172186109755, train accuracy 0.4488888888888889\n",
            "Epoch 3: train loss 1.4562103748321533, train accuracy 0.47333333333333333\n",
            "Epoch 3: train loss 1.569074617491828, train accuracy 0.4688888888888889\n",
            "Epoch 4: train loss 1.5300774971644084, train accuracy 0.44\n",
            "Epoch 4: train loss 1.4935633540153503, train accuracy 0.4688888888888889\n",
            "Epoch 4: train loss 1.4686871767044067, train accuracy 0.45111111111111113\n",
            "Epoch 4: train loss 1.5505839387575786, train accuracy 0.44666666666666666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:16:51,655 | server.py:229 | fit_round 18 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 18 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.4987947808371649, train accuracy 0.44\n",
            "Epoch 5: train loss 1.522654241985745, train accuracy 0.43777777777777777\n",
            "Epoch 5: train loss 1.4092989299032423, train accuracy 0.4488888888888889\n",
            "Epoch 5: train loss 1.4951949450704787, train accuracy 0.45555555555555555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:16:55,574 | server.py:116 | fit progress: (18, 1.4703371922671795, {'accuracy': 0.4692}, 423.94862592)\n",
            "INFO:flower:fit progress: (18, 1.4703371922671795, {'accuracy': 0.4692}, 423.94862592)\n",
            "INFO flower 2023-05-25 22:16:55,577 | server.py:163 | evaluate_round 18: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 18: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:16:55,583 | server.py:215 | fit_round 19: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 19: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.4703371922671795 / accuracy 0.4692\n",
            "[Client 18, round 19] fit, config: {'server_round': 19, 'local_epochs': 5}[Client 39, round 19] fit, config: {'server_round': 19, 'local_epochs': 5}\n",
            "[Client 83, round 19] fit, config: {'server_round': 19, 'local_epochs': 5}\n",
            "\n",
            "[Client 37, round 19] fit, config: {'server_round': 19, 'local_epochs': 5}\n",
            "[Client 98, round 19] fit, config: {'server_round': 19, 'local_epochs': 5}\n",
            "[Client 99, round 19] fit, config: {'server_round': 19, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.5790140430132549, train accuracy 0.4177777777777778\n",
            "Epoch 1: train loss 1.679541329542796, train accuracy 0.37777777777777777\n",
            "Epoch 1: train loss 1.6447949078347948, train accuracy 0.3622222222222222\n",
            "Epoch 1: train loss 1.550895048512353, train accuracy 0.43333333333333335\n",
            "Epoch 1: train loss 1.5492629541291132, train accuracy 0.43777777777777777\n",
            "Epoch 1: train loss 1.6565693550639682, train accuracy 0.3888888888888889\n",
            "Epoch 2: train loss 1.4270852605501811, train accuracy 0.45111111111111113\n",
            "Epoch 2: train loss 1.5392004913753934, train accuracy 0.4488888888888889\n",
            "Epoch 2: train loss 1.4484040670924716, train accuracy 0.4866666666666667\n",
            "Epoch 2: train loss 1.5517207781473796, train accuracy 0.4444444444444444Epoch 2: train loss 1.6339957382943895, train accuracy 0.4266666666666667\n",
            "\n",
            "Epoch 2: train loss 1.60780178838306, train accuracy 0.4177777777777778\n",
            "Epoch 3: train loss 1.4251100023587544, train accuracy 0.4911111111111111\n",
            "Epoch 3: train loss 1.511629217200809, train accuracy 0.46\n",
            "Epoch 3: train loss 1.5047898888587952, train accuracy 0.4622222222222222\n",
            "Epoch 3: train loss 1.5022100342644586, train accuracy 0.4711111111111111\n",
            "Epoch 3: train loss 1.439372890525394, train accuracy 0.47555555555555556\n",
            "Epoch 3: train loss 1.6163147886594136, train accuracy 0.4311111111111111\n",
            "Epoch 4: train loss 1.3829114105966356, train accuracy 0.47555555555555556\n",
            "Epoch 4: train loss 1.4332163400120206, train accuracy 0.4688888888888889\n",
            "Epoch 4: train loss 1.5166753994094, train accuracy 0.45111111111111113\n",
            "Epoch 4: train loss 1.4540884693463643, train accuracy 0.4666666666666667\n",
            "Epoch 4: train loss 1.4799292220009699, train accuracy 0.4822222222222222\n",
            "Epoch 4: train loss 1.541081170241038, train accuracy 0.4311111111111111\n",
            "Epoch 5: train loss 1.376809537410736, train accuracy 0.4888888888888889\n",
            "[Client 49, round 19] fit, config: {'server_round': 19, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4516064590877957, train accuracy 0.48\n",
            "[Client 47, round 19] fit, config: {'server_round': 19, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.3842696613735623, train accuracy 0.45555555555555555\n",
            "[Client 16, round 19] fit, config: {'server_round': 19, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4826567239231534, train accuracy 0.46\n",
            "Epoch 5: train loss 1.5303326447804768, train accuracy 0.43777777777777777\n",
            "[Client 68, round 19] fit, config: {'server_round': 19, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.5353849331537883, train accuracy 0.4488888888888889\n",
            "Epoch 1: train loss 1.5363959736294217, train accuracy 0.43555555555555553\n",
            "Epoch 1: train loss 1.6560404962963529, train accuracy 0.41333333333333333\n",
            "Epoch 1: train loss 1.5463031861517165, train accuracy 0.44222222222222224\n",
            "Epoch 1: train loss 1.6693714790874057, train accuracy 0.4688888888888889\n",
            "Epoch 2: train loss 1.4858136971791585, train accuracy 0.4866666666666667\n",
            "Epoch 2: train loss 1.579343272580041, train accuracy 0.4222222222222222\n",
            "Epoch 2: train loss 1.4486950238545735, train accuracy 0.46444444444444444\n",
            "Epoch 2: train loss 1.5639372203085158, train accuracy 0.4488888888888889\n",
            "Epoch 3: train loss 1.4518951641188726, train accuracy 0.49333333333333335\n",
            "Epoch 3: train loss 1.5777391990025837, train accuracy 0.42\n",
            "Epoch 3: train loss 1.4328995280795627, train accuracy 0.4488888888888889\n",
            "Epoch 3: train loss 1.5285285578833685, train accuracy 0.43777777777777777\n",
            "Epoch 4: train loss 1.5484715037875705, train accuracy 0.45111111111111113\n",
            "Epoch 4: train loss 1.446440623866187, train accuracy 0.47555555555555556\n",
            "Epoch 4: train loss 1.529200639989641, train accuracy 0.47333333333333333\n",
            "Epoch 4: train loss 1.4725215832392375, train accuracy 0.4577777777777778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:17:13,446 | server.py:229 | fit_round 19 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 19 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.4391148818863764, train accuracy 0.48\n",
            "Epoch 5: train loss 1.506298581759135, train accuracy 0.46444444444444444\n",
            "Epoch 5: train loss 1.4595531688796148, train accuracy 0.46Epoch 5: train loss 1.4727126293712192, train accuracy 0.46\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:17:18,515 | server.py:116 | fit progress: (19, 1.461723094433546, {'accuracy': 0.4681}, 446.88970751200003)\n",
            "INFO:flower:fit progress: (19, 1.461723094433546, {'accuracy': 0.4681}, 446.88970751200003)\n",
            "INFO flower 2023-05-25 22:17:18,518 | server.py:163 | evaluate_round 19: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 19: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:17:18,522 | server.py:215 | fit_round 20: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 20: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.461723094433546 / accuracy 0.4681\n",
            "[Client 43, round 20] fit, config: {'server_round': 20, 'local_epochs': 5}\n",
            "[Client 66, round 20] fit, config: {'server_round': 20, 'local_epochs': 5}\n",
            "[Client 15, round 20] fit, config: {'server_round': 20, 'local_epochs': 5}\n",
            "[Client 80, round 20] fit, config: {'server_round': 20, 'local_epochs': 5}\n",
            "[Client 75, round 20] fit, config: {'server_round': 20, 'local_epochs': 5}\n",
            "[Client 21, round 20] fit, config: {'server_round': 20, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.6072565582063463, train accuracy 0.3711111111111111\n",
            "Epoch 1: train loss 1.5586585402488708, train accuracy 0.41333333333333333\n",
            "Epoch 1: train loss 1.6658216251267328, train accuracy 0.3888888888888889\n",
            "Epoch 1: train loss 1.6225983036888971, train accuracy 0.4022222222222222\n",
            "Epoch 1: train loss 1.6069336533546448, train accuracy 0.4022222222222222\n",
            "Epoch 1: train loss 1.6570707625812955, train accuracy 0.42444444444444446\n",
            "Epoch 2: train loss 1.526173300213284, train accuracy 0.43777777777777777\n",
            "Epoch 2: train loss 1.5552494724591572, train accuracy 0.41555555555555557\n",
            "Epoch 2: train loss 1.4831611646546259, train accuracy 0.4488888888888889\n",
            "Epoch 2: train loss 1.5990997950236003, train accuracy 0.42444444444444446\n",
            "Epoch 2: train loss 1.5713346468077765, train accuracy 0.41555555555555557\n",
            "Epoch 2: train loss 1.5155750513076782, train accuracy 0.46444444444444444\n",
            "Epoch 3: train loss 1.5200611882739596, train accuracy 0.4222222222222222\n",
            "Epoch 3: train loss 1.5351846019426982, train accuracy 0.4533333333333333\n",
            "Epoch 3: train loss 1.536694433954027, train accuracy 0.4688888888888889\n",
            "Epoch 3: train loss 1.4605571693844266, train accuracy 0.46\n",
            "Epoch 3: train loss 1.5222189161512587, train accuracy 0.45555555555555555\n",
            "Epoch 3: train loss 1.505751285288069, train accuracy 0.43555555555555553\n",
            "Epoch 4: train loss 1.4721286296844482, train accuracy 0.44222222222222224\n",
            "Epoch 4: train loss 1.521743608845605, train accuracy 0.4444444444444444\n",
            "Epoch 4: train loss 1.415920661555396, train accuracy 0.4822222222222222\n",
            "Epoch 4: train loss 1.462079836262597, train accuracy 0.4622222222222222\n",
            "Epoch 4: train loss 1.5517997609244452, train accuracy 0.42444444444444446Epoch 4: train loss 1.4690555466545954, train accuracy 0.4533333333333333\n",
            "\n",
            "Epoch 5: train loss 1.4828130470381842, train accuracy 0.4488888888888889\n",
            "[Client 49, round 20] fit, config: {'server_round': 20, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4883734583854675, train accuracy 0.46444444444444444\n",
            "[Client 55, round 20] fit, config: {'server_round': 20, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4884254998630948, train accuracy 0.4711111111111111\n",
            "[Client 7, round 20] fit, config: {'server_round': 20, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4388073682785034, train accuracy 0.4666666666666667\n",
            "[Client 94, round 20] fit, config: {'server_round': 20, 'local_epochs': 5}Epoch 5: train loss 1.4405930704540677, train accuracy 0.47555555555555556\n",
            "\n",
            "Epoch 5: train loss 1.502864744928148, train accuracy 0.4488888888888889\n",
            "Epoch 1: train loss 1.5730111996332805, train accuracy 0.42444444444444446\n",
            "Epoch 1: train loss 1.6150579121377733, train accuracy 0.4022222222222222\n",
            "Epoch 1: train loss 1.6912931733661227, train accuracy 0.38\n",
            "Epoch 1: train loss 1.6100652085410223, train accuracy 0.4111111111111111\n",
            "Epoch 2: train loss 1.431042406294081, train accuracy 0.4488888888888889\n",
            "Epoch 2: train loss 1.5046614739629958, train accuracy 0.4311111111111111\n",
            "Epoch 2: train loss 1.553739329179128, train accuracy 0.44222222222222224\n",
            "Epoch 2: train loss 1.5862500667572021, train accuracy 0.3888888888888889\n",
            "Epoch 3: train loss 1.4221047361691792, train accuracy 0.48\n",
            "Epoch 3: train loss 1.4942801528506808, train accuracy 0.44222222222222224\n",
            "Epoch 3: train loss 1.4569578568140666, train accuracy 0.4533333333333333\n",
            "Epoch 3: train loss 1.5201530787679884, train accuracy 0.4311111111111111\n",
            "Epoch 4: train loss 1.3947061962551541, train accuracy 0.4888888888888889\n",
            "Epoch 4: train loss 1.4534352090623643, train accuracy 0.46\n",
            "Epoch 4: train loss 1.448304639922248, train accuracy 0.46\n",
            "Epoch 4: train loss 1.4631558656692505, train accuracy 0.4688888888888889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:17:35,961 | server.py:229 | fit_round 20 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 20 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.3786448041598003, train accuracy 0.5111111111111111\n",
            "Epoch 5: train loss 1.4561599757936265, train accuracy 0.4533333333333333\n",
            "Epoch 5: train loss 1.4464503526687622, train accuracy 0.4711111111111111\n",
            "Epoch 5: train loss 1.3989513317743938, train accuracy 0.49333333333333335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:17:39,664 | server.py:116 | fit progress: (20, 1.4547788849473, {'accuracy': 0.4725}, 468.03831246299995)\n",
            "INFO:flower:fit progress: (20, 1.4547788849473, {'accuracy': 0.4725}, 468.03831246299995)\n",
            "INFO flower 2023-05-25 22:17:39,670 | server.py:163 | evaluate_round 20: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 20: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:17:39,673 | server.py:215 | fit_round 21: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 21: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.4547788849473 / accuracy 0.4725\n",
            "[Client 17, round 21] fit, config: {'server_round': 21, 'local_epochs': 5}\n",
            "[Client 58, round 21] fit, config: {'server_round': 21, 'local_epochs': 5}[Client 85, round 21] fit, config: {'server_round': 21, 'local_epochs': 5}\n",
            "\n",
            "[Client 44, round 21] fit, config: {'server_round': 21, 'local_epochs': 5}\n",
            "[Client 2, round 21] fit, config: {'server_round': 21, 'local_epochs': 5}\n",
            "[Client 57, round 21] fit, config: {'server_round': 21, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.5982904964023166, train accuracy 0.4266666666666667\n",
            "Epoch 1: train loss 1.6129760675960116, train accuracy 0.4111111111111111\n",
            "Epoch 1: train loss 1.5697976218329535, train accuracy 0.4\n",
            "Epoch 1: train loss 1.6147958437601726, train accuracy 0.4222222222222222\n",
            "Epoch 1: train loss 1.5897196994887457, train accuracy 0.4066666666666667\n",
            "Epoch 1: train loss 1.612628075811598, train accuracy 0.3888888888888889\n",
            "Epoch 2: train loss 1.4790905250443354, train accuracy 0.4666666666666667Epoch 2: train loss 1.5567004879315693, train accuracy 0.43555555555555553\n",
            "Epoch 2: train loss 1.5316355956925287, train accuracy 0.43555555555555553\n",
            "\n",
            "Epoch 2: train loss 1.555656956301795, train accuracy 0.46444444444444444\n",
            "Epoch 2: train loss 1.5355458656946819, train accuracy 0.4222222222222222\n",
            "Epoch 2: train loss 1.5450396802690294, train accuracy 0.43777777777777777\n",
            "Epoch 3: train loss 1.4602264033423529, train accuracy 0.49333333333333335\n",
            "Epoch 3: train loss 1.4559355510605707, train accuracy 0.4888888888888889\n",
            "Epoch 3: train loss 1.4848621951209173, train accuracy 0.43333333333333335\n",
            "Epoch 3: train loss 1.5029053025775485, train accuracy 0.4577777777777778\n",
            "Epoch 3: train loss 1.4621302882830303, train accuracy 0.4777777777777778\n",
            "Epoch 3: train loss 1.4751020736164517, train accuracy 0.4688888888888889\n",
            "Epoch 4: train loss 1.4543019400702581, train accuracy 0.5022222222222222\n",
            "Epoch 4: train loss 1.483716282579634, train accuracy 0.4666666666666667\n",
            "Epoch 4: train loss 1.4619450834062364, train accuracy 0.4311111111111111\n",
            "Epoch 4: train loss 1.4425837927394443, train accuracy 0.4688888888888889\n",
            "Epoch 4: train loss 1.44820417298211, train accuracy 0.4688888888888889\n",
            "Epoch 4: train loss 1.466915680302514, train accuracy 0.49333333333333335\n",
            "Epoch 5: train loss 1.4918587340248957, train accuracy 0.42444444444444446\n",
            "[Client 94, round 21] fit, config: {'server_round': 21, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4360212451881833, train accuracy 0.44666666666666666\n",
            "[Client 92, round 21] fit, config: {'server_round': 21, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4532814621925354, train accuracy 0.43777777777777777\n",
            "[Client 91, round 21] fit, config: {'server_round': 21, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4308960172865126, train accuracy 0.5111111111111111\n",
            "[Client 38, round 21] fit, config: {'server_round': 21, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4604810277620952, train accuracy 0.47333333333333333\n",
            "Epoch 5: train loss 1.4719220532311335, train accuracy 0.4533333333333333\n",
            "Epoch 1: train loss 1.5748867458767362, train accuracy 0.43555555555555553\n",
            "Epoch 1: train loss 1.5800909399986267, train accuracy 0.3977777777777778Epoch 1: train loss 1.5032393866115146, train accuracy 0.43555555555555553\n",
            "\n",
            "Epoch 1: train loss 1.6090027160114713, train accuracy 0.40444444444444444\n",
            "Epoch 2: train loss 1.5154259602228801, train accuracy 0.4311111111111111\n",
            "Epoch 2: train loss 1.5124876101811726, train accuracy 0.41555555555555557\n",
            "Epoch 2: train loss 1.4616153240203857, train accuracy 0.4866666666666667\n",
            "Epoch 2: train loss 1.5712700684865315, train accuracy 0.41333333333333333\n",
            "Epoch 3: train loss 1.471126721964942, train accuracy 0.46\n",
            "Epoch 3: train loss 1.48418837123447, train accuracy 0.4622222222222222\n",
            "Epoch 3: train loss 1.4587104850345187, train accuracy 0.5\n",
            "Epoch 3: train loss 1.4883314304881625, train accuracy 0.45555555555555555\n",
            "Epoch 4: train loss 1.4242458211051092, train accuracy 0.47555555555555556\n",
            "Epoch 4: train loss 1.469548073079851, train accuracy 0.44666666666666666\n",
            "Epoch 4: train loss 1.4103947480519612, train accuracy 0.47555555555555556\n",
            "Epoch 4: train loss 1.5051919089423285, train accuracy 0.4622222222222222\n",
            "Epoch 5: train loss 1.4160901175604925, train accuracy 0.5066666666666667\n",
            "Epoch 5: train loss 1.4574203689893086, train accuracy 0.44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:17:58,418 | server.py:229 | fit_round 21 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 21 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.4709859887758892, train accuracy 0.46444444444444444\n",
            "Epoch 5: train loss 1.3678667810228136, train accuracy 0.5022222222222222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:18:03,761 | server.py:116 | fit progress: (21, 1.4366457156836987, {'accuracy': 0.4805}, 492.136052506)\n",
            "INFO:flower:fit progress: (21, 1.4366457156836987, {'accuracy': 0.4805}, 492.136052506)\n",
            "INFO flower 2023-05-25 22:18:03,769 | server.py:163 | evaluate_round 21: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 21: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:18:03,775 | server.py:215 | fit_round 22: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 22: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.4366457156836987 / accuracy 0.4805\n",
            "[Client 54, round 22] fit, config: {'server_round': 22, 'local_epochs': 5}\n",
            "[Client 99, round 22] fit, config: {'server_round': 22, 'local_epochs': 5}\n",
            "[Client 3, round 22] fit, config: {'server_round': 22, 'local_epochs': 5}\n",
            "[Client 66, round 22] fit, config: {'server_round': 22, 'local_epochs': 5}\n",
            "[Client 20, round 22] fit, config: {'server_round': 22, 'local_epochs': 5}\n",
            "[Client 41, round 22] fit, config: {'server_round': 22, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.6183395120832655, train accuracy 0.43777777777777777\n",
            "Epoch 1: train loss 1.6005599697430928, train accuracy 0.42\n",
            "Epoch 1: train loss 1.4447625478108723, train accuracy 0.4888888888888889\n",
            "Epoch 1: train loss 1.6700644493103027, train accuracy 0.3711111111111111\n",
            "Epoch 1: train loss 1.6583940386772156, train accuracy 0.4022222222222222\n",
            "Epoch 1: train loss 1.6460458768738642, train accuracy 0.38666666666666666\n",
            "Epoch 2: train loss 1.667164319091373, train accuracy 0.37333333333333335\n",
            "Epoch 2: train loss 1.3906176288922627, train accuracy 0.4777777777777778\n",
            "Epoch 2: train loss 1.4865903125868902, train accuracy 0.4311111111111111\n",
            "Epoch 2: train loss 1.521049400170644, train accuracy 0.43333333333333335\n",
            "Epoch 2: train loss 1.5671167969703674, train accuracy 0.41555555555555557\n",
            "Epoch 2: train loss 1.5945900943544176, train accuracy 0.44222222222222224\n",
            "Epoch 3: train loss 1.5772171020507812, train accuracy 0.40444444444444444\n",
            "Epoch 3: train loss 1.3635347286860149, train accuracy 0.52\n",
            "Epoch 3: train loss 1.5228208369678922, train accuracy 0.41333333333333333\n",
            "Epoch 3: train loss 1.4851876960860357, train accuracy 0.44666666666666666\n",
            "Epoch 3: train loss 1.443106280432807, train accuracy 0.44666666666666666\n",
            "Epoch 3: train loss 1.516262001461453, train accuracy 0.4822222222222222\n",
            "Epoch 4: train loss 1.5729138652483623, train accuracy 0.40444444444444444\n",
            "Epoch 4: train loss 1.319905506239997, train accuracy 0.52\n",
            "Epoch 4: train loss 1.4279271827803717, train accuracy 0.4777777777777778Epoch 4: train loss 1.454258746571011, train accuracy 0.4488888888888889\n",
            "\n",
            "Epoch 4: train loss 1.504276904794905, train accuracy 0.4577777777777778\n",
            "Epoch 4: train loss 1.475150227546692, train accuracy 0.4688888888888889\n",
            "Epoch 5: train loss 1.5508425699339972, train accuracy 0.3933333333333333\n",
            "[Client 65, round 22] fit, config: {'server_round': 22, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.2601548830668132, train accuracy 0.5422222222222223\n",
            "[Client 71, round 22] fit, config: {'server_round': 22, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.3670281569163005, train accuracy 0.47555555555555556\n",
            "Epoch 5: train loss 1.4269850717650518, train accuracy 0.48444444444444446\n",
            "[Client 17, round 22] fit, config: {'server_round': 22, 'local_epochs': 5}[Client 43, round 22] fit, config: {'server_round': 22, 'local_epochs': 5}\n",
            "\n",
            "Epoch 5: train loss 1.4437626202901204, train accuracy 0.4622222222222222\n",
            "Epoch 5: train loss 1.421616103914049, train accuracy 0.4888888888888889\n",
            "Epoch 1: train loss 1.5852141314082675, train accuracy 0.3977777777777778\n",
            "Epoch 1: train loss 1.606950733396742, train accuracy 0.4088888888888889\n",
            "Epoch 1: train loss 1.5812372300359938, train accuracy 0.4022222222222222\n",
            "Epoch 1: train loss 1.6482320229212444, train accuracy 0.3888888888888889\n",
            "Epoch 2: train loss 1.488569849067264, train accuracy 0.45111111111111113\n",
            "Epoch 2: train loss 1.4779146247439914, train accuracy 0.45555555555555555\n",
            "Epoch 2: train loss 1.509108132786221, train accuracy 0.4622222222222222\n",
            "Epoch 2: train loss 1.576733410358429, train accuracy 0.43555555555555553\n",
            "Epoch 3: train loss 1.4679711792204115, train accuracy 0.4533333333333333\n",
            "Epoch 3: train loss 1.4714322719309065, train accuracy 0.4533333333333333\n",
            "Epoch 3: train loss 1.4596162570847406, train accuracy 0.4866666666666667\n",
            "Epoch 3: train loss 1.4805480308002896, train accuracy 0.4622222222222222\n",
            "Epoch 4: train loss 1.4326130549112956, train accuracy 0.46\n",
            "Epoch 4: train loss 1.4575573603312175, train accuracy 0.44222222222222224\n",
            "Epoch 4: train loss 1.4351545969645183, train accuracy 0.4711111111111111\n",
            "Epoch 4: train loss 1.4702908727857802, train accuracy 0.5088888888888888\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:18:22,459 | server.py:229 | fit_round 22 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 22 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.402936167187161, train accuracy 0.4866666666666667\n",
            "Epoch 5: train loss 1.4215104381243389, train accuracy 0.46444444444444444\n",
            "Epoch 5: train loss 1.500618232621087, train accuracy 0.45111111111111113\n",
            "Epoch 5: train loss 1.4651786949899461, train accuracy 0.4911111111111111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:18:27,100 | server.py:116 | fit progress: (22, 1.429206059873104, {'accuracy': 0.485}, 515.475091607)\n",
            "INFO:flower:fit progress: (22, 1.429206059873104, {'accuracy': 0.485}, 515.475091607)\n",
            "INFO flower 2023-05-25 22:18:27,104 | server.py:163 | evaluate_round 22: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 22: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:18:27,107 | server.py:215 | fit_round 23: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 23: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.429206059873104 / accuracy 0.485\n",
            "[Client 64, round 23] fit, config: {'server_round': 23, 'local_epochs': 5}\n",
            "[Client 13, round 23] fit, config: {'server_round': 23, 'local_epochs': 5}\n",
            "[Client 69, round 23] fit, config: {'server_round': 23, 'local_epochs': 5}\n",
            "[Client 92, round 23] fit, config: {'server_round': 23, 'local_epochs': 5}\n",
            "[Client 47, round 23] fit, config: {'server_round': 23, 'local_epochs': 5}\n",
            "[Client 28, round 23] fit, config: {'server_round': 23, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.6237158444192674, train accuracy 0.4066666666666667\n",
            "Epoch 1: train loss 1.6219974358876545, train accuracy 0.4066666666666667\n",
            "Epoch 1: train loss 1.553504400783115, train accuracy 0.4444444444444444\n",
            "Epoch 1: train loss 1.6769842637909784, train accuracy 0.38666666666666666\n",
            "Epoch 1: train loss 1.582754757669237, train accuracy 0.42Epoch 1: train loss 1.608618312411838, train accuracy 0.4066666666666667\n",
            "\n",
            "Epoch 2: train loss 1.5361980199813843, train accuracy 0.42444444444444446\n",
            "Epoch 2: train loss 1.5536583132214017, train accuracy 0.43555555555555553\n",
            "Epoch 2: train loss 1.522312084833781, train accuracy 0.42\n",
            "Epoch 2: train loss 1.4930409524175856, train accuracy 0.4177777777777778\n",
            "Epoch 2: train loss 1.593861632876926, train accuracy 0.4066666666666667\n",
            "Epoch 2: train loss 1.5306222041447957, train accuracy 0.42444444444444446\n",
            "Epoch 3: train loss 1.5194737646314833, train accuracy 0.42\n",
            "Epoch 3: train loss 1.4756417274475098, train accuracy 0.43555555555555553\n",
            "Epoch 3: train loss 1.4901087151633368, train accuracy 0.4622222222222222\n",
            "Epoch 3: train loss 1.4880937669012282, train accuracy 0.4955555555555556\n",
            "Epoch 3: train loss 1.5232088300916884, train accuracy 0.44666666666666666\n",
            "Epoch 3: train loss 1.4736680852042303, train accuracy 0.4866666666666667\n",
            "Epoch 4: train loss 1.4685227473576863, train accuracy 0.4688888888888889\n",
            "Epoch 4: train loss 1.4321907295121088, train accuracy 0.4688888888888889\n",
            "Epoch 4: train loss 1.466791696018643, train accuracy 0.4622222222222222\n",
            "Epoch 4: train loss 1.399155729346805, train accuracy 0.45111111111111113\n",
            "Epoch 4: train loss 1.4519176284472148, train accuracy 0.44666666666666666\n",
            "Epoch 4: train loss 1.4715123640166388, train accuracy 0.4577777777777778\n",
            "Epoch 5: train loss 1.4546073542700872, train accuracy 0.4622222222222222\n",
            "[Client 72, round 23] fit, config: {'server_round': 23, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4449447327189975, train accuracy 0.4533333333333333\n",
            "[Client 43, round 23] fit, config: {'server_round': 23, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4225737353165944, train accuracy 0.44666666666666666\n",
            "[Client 11, round 23] fit, config: {'server_round': 23, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4025960663954418, train accuracy 0.4666666666666667\n",
            "[Client 34, round 23] fit, config: {'server_round': 23, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.418418526649475, train accuracy 0.5066666666666667\n",
            "Epoch 5: train loss 1.3926780786779192, train accuracy 0.48\n",
            "Epoch 1: train loss 1.4846623208787706, train accuracy 0.47555555555555556\n",
            "Epoch 1: train loss 1.6399056381649442, train accuracy 0.4022222222222222\n",
            "Epoch 1: train loss 1.5443382461865742, train accuracy 0.41333333333333333\n",
            "Epoch 1: train loss 1.6526394883791606, train accuracy 0.4066666666666667\n",
            "Epoch 2: train loss 1.4996787309646606, train accuracy 0.4711111111111111\n",
            "Epoch 2: train loss 1.4133033156394958, train accuracy 0.5177777777777778\n",
            "Epoch 2: train loss 1.48515518506368, train accuracy 0.43333333333333335\n",
            "Epoch 2: train loss 1.4640961090723674, train accuracy 0.4666666666666667\n",
            "Epoch 3: train loss 1.5113854474491544, train accuracy 0.4488888888888889\n",
            "Epoch 3: train loss 1.4254664646254644, train accuracy 0.4666666666666667\n",
            "Epoch 3: train loss 1.4526258806387584, train accuracy 0.4577777777777778\n",
            "Epoch 3: train loss 1.4796673092577193, train accuracy 0.44222222222222224\n",
            "Epoch 4: train loss 1.4517777959505718, train accuracy 0.47555555555555556\n",
            "Epoch 4: train loss 1.3773667481210496, train accuracy 0.5222222222222223\n",
            "Epoch 4: train loss 1.3954858978589375, train accuracy 0.4777777777777778\n",
            "Epoch 4: train loss 1.4480714334381952, train accuracy 0.4577777777777778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:18:46,445 | server.py:229 | fit_round 23 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 23 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.480260193347931, train accuracy 0.4688888888888889\n",
            "Epoch 5: train loss 1.332974500126309, train accuracy 0.4955555555555556\n",
            "Epoch 5: train loss 1.3872541122966342, train accuracy 0.4888888888888889\n",
            "Epoch 5: train loss 1.4272107813093398, train accuracy 0.4955555555555556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:18:50,349 | server.py:116 | fit progress: (23, 1.4237524403631687, {'accuracy': 0.4899}, 538.723813993)\n",
            "INFO:flower:fit progress: (23, 1.4237524403631687, {'accuracy': 0.4899}, 538.723813993)\n",
            "INFO flower 2023-05-25 22:18:50,354 | server.py:163 | evaluate_round 23: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 23: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:18:50,358 | server.py:215 | fit_round 24: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 24: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.4237524403631687 / accuracy 0.4899\n",
            "[Client 64, round 24] fit, config: {'server_round': 24, 'local_epochs': 5}\n",
            "[Client 31, round 24] fit, config: {'server_round': 24, 'local_epochs': 5}\n",
            "[Client 26, round 24] fit, config: {'server_round': 24, 'local_epochs': 5}\n",
            "[Client 33, round 24] fit, config: {'server_round': 24, 'local_epochs': 5}\n",
            "[Client 41, round 24] fit, config: {'server_round': 24, 'local_epochs': 5}\n",
            "[Client 50, round 24] fit, config: {'server_round': 24, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.6264818045828078, train accuracy 0.3888888888888889\n",
            "Epoch 1: train loss 1.5961149334907532, train accuracy 0.44666666666666666\n",
            "Epoch 1: train loss 1.625994410779741, train accuracy 0.39555555555555555\n",
            "Epoch 1: train loss 1.613152351644304, train accuracy 0.3977777777777778\n",
            "Epoch 1: train loss 1.6485084626409743, train accuracy 0.4111111111111111\n",
            "Epoch 1: train loss 1.5497631364398532, train accuracy 0.4288888888888889\n",
            "Epoch 2: train loss 1.5131055580245123, train accuracy 0.4177777777777778\n",
            "Epoch 2: train loss 1.492424898677402, train accuracy 0.4288888888888889\n",
            "Epoch 2: train loss 1.5169411367840238, train accuracy 0.44666666666666666\n",
            "Epoch 2: train loss 1.5306407544347975, train accuracy 0.4488888888888889\n",
            "Epoch 2: train loss 1.5151564942465887, train accuracy 0.48\n",
            "Epoch 2: train loss 1.4591521951887343, train accuracy 0.44666666666666666\n",
            "Epoch 3: train loss 1.4645582437515259, train accuracy 0.4666666666666667\n",
            "Epoch 3: train loss 1.4678657452265422, train accuracy 0.4688888888888889\n",
            "Epoch 3: train loss 1.4671654767460294, train accuracy 0.43777777777777777\n",
            "Epoch 3: train loss 1.5061167412334018, train accuracy 0.44666666666666666Epoch 3: train loss 1.486455135875278, train accuracy 0.4688888888888889\n",
            "\n",
            "Epoch 3: train loss 1.4230130447281732, train accuracy 0.4822222222222222\n",
            "Epoch 4: train loss 1.4983338846100702, train accuracy 0.4533333333333333\n",
            "Epoch 4: train loss 1.4647301104333665, train accuracy 0.43333333333333335\n",
            "Epoch 4: train loss 1.4614556696679857, train accuracy 0.45111111111111113\n",
            "Epoch 4: train loss 1.4557608597808414, train accuracy 0.4711111111111111\n",
            "Epoch 4: train loss 1.4619944559203253, train accuracy 0.48444444444444446\n",
            "Epoch 4: train loss 1.3931722972128127, train accuracy 0.49777777777777776\n",
            "Epoch 5: train loss 1.4493541518847148, train accuracy 0.4533333333333333\n",
            "[Client 5, round 24] fit, config: {'server_round': 24, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.3967057930098639, train accuracy 0.4888888888888889\n",
            "[Client 10, round 24] fit, config: {'server_round': 24, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4349772996372647, train accuracy 0.49777777777777776\n",
            "[Client 25, round 24] fit, config: {'server_round': 24, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.431038134627872, train accuracy 0.4888888888888889\n",
            "[Client 97, round 24] fit, config: {'server_round': 24, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.352864192591773, train accuracy 0.5044444444444445\n",
            "Epoch 5: train loss 1.4388913181093004, train accuracy 0.5044444444444445\n",
            "Epoch 1: train loss 1.6470564471350775, train accuracy 0.3933333333333333\n",
            "Epoch 1: train loss 1.6397448248333402, train accuracy 0.42\n",
            "Epoch 1: train loss 1.6588257021374173, train accuracy 0.41333333333333333\n",
            "Epoch 1: train loss 1.6414891481399536, train accuracy 0.4088888888888889\n",
            "Epoch 2: train loss 1.4555664989683363, train accuracy 0.48\n",
            "Epoch 2: train loss 1.576527025964525, train accuracy 0.4488888888888889\n",
            "Epoch 2: train loss 1.553546494907803, train accuracy 0.42444444444444446\n",
            "Epoch 2: train loss 1.5322252710660298, train accuracy 0.42\n",
            "Epoch 3: train loss 1.4731429086791143, train accuracy 0.4533333333333333\n",
            "Epoch 3: train loss 1.4893837637371488, train accuracy 0.48\n",
            "Epoch 3: train loss 1.4786495036549039, train accuracy 0.45111111111111113\n",
            "Epoch 3: train loss 1.5340339607662625, train accuracy 0.41333333333333333\n",
            "Epoch 4: train loss 1.4666277567545574, train accuracy 0.47555555555555556\n",
            "Epoch 4: train loss 1.5037727289729648, train accuracy 0.46444444444444444\n",
            "Epoch 4: train loss 1.405331426196628, train accuracy 0.48444444444444446\n",
            "Epoch 4: train loss 1.5421614580684238, train accuracy 0.44666666666666666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:19:08,977 | server.py:229 | fit_round 24 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 24 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.4344174994362726, train accuracy 0.4777777777777778\n",
            "Epoch 5: train loss 1.4299147658877902, train accuracy 0.43777777777777777\n",
            "Epoch 5: train loss 1.4185289210743375, train accuracy 0.5088888888888888\n",
            "Epoch 5: train loss 1.5078556074036493, train accuracy 0.44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:19:14,322 | server.py:116 | fit progress: (24, 1.4109964521229268, {'accuracy': 0.4939}, 562.6969665709998)\n",
            "INFO:flower:fit progress: (24, 1.4109964521229268, {'accuracy': 0.4939}, 562.6969665709998)\n",
            "INFO flower 2023-05-25 22:19:14,330 | server.py:163 | evaluate_round 24: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 24: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:19:14,334 | server.py:215 | fit_round 25: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 25: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.4109964521229268 / accuracy 0.4939\n",
            "[Client 2, round 25] fit, config: {'server_round': 25, 'local_epochs': 5}\n",
            "[Client 24, round 25] fit, config: {'server_round': 25, 'local_epochs': 5}\n",
            "[Client 29, round 25] fit, config: {'server_round': 25, 'local_epochs': 5}[Client 72, round 25] fit, config: {'server_round': 25, 'local_epochs': 5}\n",
            "[Client 34, round 25] fit, config: {'server_round': 25, 'local_epochs': 5}\n",
            "\n",
            "[Client 10, round 25] fit, config: {'server_round': 25, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.6033735209041171, train accuracy 0.4177777777777778\n",
            "Epoch 1: train loss 1.4743116034401789, train accuracy 0.4822222222222222\n",
            "Epoch 1: train loss 1.5397348403930664, train accuracy 0.4088888888888889\n",
            "Epoch 1: train loss 1.549378467930688, train accuracy 0.44222222222222224\n",
            "Epoch 1: train loss 1.5950082341829936, train accuracy 0.46\n",
            "Epoch 1: train loss 1.5741341047816806, train accuracy 0.4288888888888889\n",
            "Epoch 2: train loss 1.4668776790301006, train accuracy 0.4777777777777778\n",
            "Epoch 2: train loss 1.5230974290106032, train accuracy 0.45111111111111113\n",
            "Epoch 2: train loss 1.4334337049060397, train accuracy 0.45111111111111113\n",
            "Epoch 2: train loss 1.5942905876371596, train accuracy 0.44222222222222224\n",
            "Epoch 2: train loss 1.512148121992747, train accuracy 0.4\n",
            "Epoch 2: train loss 1.4348625143369038, train accuracy 0.46444444444444444\n",
            "Epoch 3: train loss 1.3842428657743666, train accuracy 0.4866666666666667\n",
            "Epoch 3: train loss 1.4427790774239435, train accuracy 0.4711111111111111\n",
            "Epoch 3: train loss 1.4444445768992107, train accuracy 0.5088888888888888\n",
            "Epoch 3: train loss 1.4947761562135484, train accuracy 0.4288888888888889\n",
            "Epoch 3: train loss 1.4751706255806818, train accuracy 0.47555555555555556\n",
            "Epoch 3: train loss 1.4148264328638713, train accuracy 0.46\n",
            "Epoch 4: train loss 1.4113668865627713, train accuracy 0.5\n",
            "Epoch 4: train loss 1.4668663872612848, train accuracy 0.46444444444444444\n",
            "Epoch 4: train loss 1.3604633841249678, train accuracy 0.4888888888888889\n",
            "Epoch 4: train loss 1.4400813844468858, train accuracy 0.4444444444444444\n",
            "Epoch 4: train loss 1.465918951564365, train accuracy 0.4533333333333333\n",
            "Epoch 4: train loss 1.405329445997874, train accuracy 0.4822222222222222\n",
            "Epoch 5: train loss 1.3057756423950195, train accuracy 0.54\n",
            "[Client 76, round 25] fit, config: {'server_round': 25, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.410305056307051, train accuracy 0.4955555555555556\n",
            "[Client 40, round 25] fit, config: {'server_round': 25, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4338048299153645, train accuracy 0.48444444444444446\n",
            "[Client 43, round 25] fit, config: {'server_round': 25, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.3813152114550273, train accuracy 0.5088888888888888\n",
            "[Client 70, round 25] fit, config: {'server_round': 25, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4162166780895658, train accuracy 0.4866666666666667\n",
            "Epoch 5: train loss 1.3671724134021335, train accuracy 0.4866666666666667\n",
            "Epoch 1: train loss 1.4978340334362454, train accuracy 0.45555555555555555\n",
            "Epoch 1: train loss 1.5868517557779949, train accuracy 0.4177777777777778\n",
            "Epoch 1: train loss 1.4642899301317003, train accuracy 0.4777777777777778\n",
            "Epoch 1: train loss 1.584552268187205, train accuracy 0.4444444444444444\n",
            "Epoch 2: train loss 1.4092135230700176, train accuracy 0.4622222222222222\n",
            "Epoch 2: train loss 1.4740711715486314, train accuracy 0.46444444444444444\n",
            "Epoch 2: train loss 1.426322294606103, train accuracy 0.46\n",
            "Epoch 2: train loss 1.527852217356364, train accuracy 0.44\n",
            "Epoch 3: train loss 1.439113563961453, train accuracy 0.46444444444444444\n",
            "Epoch 3: train loss 1.4187964002291362, train accuracy 0.49333333333333335\n",
            "Epoch 3: train loss 1.3460986481772528, train accuracy 0.5177777777777778\n",
            "Epoch 3: train loss 1.4550090763303969, train accuracy 0.4911111111111111\n",
            "Epoch 4: train loss 1.4130237234963312, train accuracy 0.49333333333333335\n",
            "Epoch 4: train loss 1.4747619099087186, train accuracy 0.45111111111111113\n",
            "Epoch 4: train loss 1.341183516714308, train accuracy 0.5066666666666667\n",
            "Epoch 4: train loss 1.4160289698176913, train accuracy 0.5022222222222222\n",
            "Epoch 5: train loss 1.390594048632516, train accuracy 0.4622222222222222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:19:32,489 | server.py:229 | fit_round 25 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 25 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.3030513260099623, train accuracy 0.5355555555555556\n",
            "Epoch 5: train loss 1.401065253549152, train accuracy 0.5133333333333333\n",
            "Epoch 5: train loss 1.3608240617646112, train accuracy 0.5066666666666667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:19:36,335 | server.py:116 | fit progress: (25, 1.3972075460851192, {'accuracy': 0.5006}, 584.7097678939999)\n",
            "INFO:flower:fit progress: (25, 1.3972075460851192, {'accuracy': 0.5006}, 584.7097678939999)\n",
            "INFO flower 2023-05-25 22:19:36,344 | server.py:163 | evaluate_round 25: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 25: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:19:36,348 | server.py:215 | fit_round 26: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 26: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.3972075460851192 / accuracy 0.5006\n",
            "[Client 68, round 26] fit, config: {'server_round': 26, 'local_epochs': 5}\n",
            "[Client 17, round 26] fit, config: {'server_round': 26, 'local_epochs': 5}\n",
            "[Client 61, round 26] fit, config: {'server_round': 26, 'local_epochs': 5}\n",
            "[Client 93, round 26] fit, config: {'server_round': 26, 'local_epochs': 5}\n",
            "[Client 63, round 26] fit, config: {'server_round': 26, 'local_epochs': 5}\n",
            "[Client 50, round 26] fit, config: {'server_round': 26, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.609556986225976, train accuracy 0.43555555555555553\n",
            "Epoch 1: train loss 1.6053770846790738, train accuracy 0.4022222222222222\n",
            "Epoch 1: train loss 1.5495168036884732, train accuracy 0.4066666666666667\n",
            "Epoch 1: train loss 1.5424985157118902, train accuracy 0.45555555555555555\n",
            "Epoch 1: train loss 1.596477038330502, train accuracy 0.4\n",
            "Epoch 1: train loss 1.6112637718518574, train accuracy 0.3844444444444444\n",
            "Epoch 2: train loss 1.4802936712900798, train accuracy 0.4622222222222222\n",
            "Epoch 2: train loss 1.4883422586652968, train accuracy 0.46444444444444444\n",
            "Epoch 2: train loss 1.5120798614290025, train accuracy 0.44222222222222224\n",
            "Epoch 2: train loss 1.4586303035418193, train accuracy 0.4666666666666667Epoch 2: train loss 1.4930481447113886, train accuracy 0.45555555555555555\n",
            "\n",
            "Epoch 2: train loss 1.5351692636807759, train accuracy 0.43333333333333335\n",
            "Epoch 3: train loss 1.4311550458272297, train accuracy 0.48\n",
            "Epoch 3: train loss 1.4312633275985718, train accuracy 0.4955555555555556\n",
            "Epoch 3: train loss 1.4192838139004178, train accuracy 0.49333333333333335\n",
            "Epoch 3: train loss 1.4691281782256231, train accuracy 0.44222222222222224\n",
            "Epoch 3: train loss 1.5145090288586087, train accuracy 0.4266666666666667\n",
            "Epoch 3: train loss 1.4526825414763556, train accuracy 0.47333333333333333\n",
            "Epoch 4: train loss 1.4043934212790594, train accuracy 0.4866666666666667\n",
            "Epoch 4: train loss 1.40628096792433, train accuracy 0.48444444444444446Epoch 4: train loss 1.411776238017612, train accuracy 0.4711111111111111\n",
            "\n",
            "Epoch 4: train loss 1.4265020688374836, train accuracy 0.47333333333333333Epoch 4: train loss 1.3970284197065566, train accuracy 0.4955555555555556\n",
            "\n",
            "Epoch 4: train loss 1.4352338777648077, train accuracy 0.4711111111111111\n",
            "Epoch 5: train loss 1.398561093542311, train accuracy 0.46444444444444444\n",
            "[Client 99, round 26] fit, config: {'server_round': 26, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.3628292149967618, train accuracy 0.5155555555555555\n",
            "[Client 3, round 26] fit, config: {'server_round': 26, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.3646679984198675, train accuracy 0.4777777777777778\n",
            "Epoch 5: train loss 1.44957039753596, train accuracy 0.4688888888888889\n",
            "[Client 91, round 26] fit, config: {'server_round': 26, 'local_epochs': 5}\n",
            "[Client 32, round 26] fit, config: {'server_round': 26, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4567097226778667, train accuracy 0.43333333333333335\n",
            "Epoch 5: train loss 1.4486172795295715, train accuracy 0.4666666666666667\n",
            "Epoch 1: train loss 1.4982140395376418, train accuracy 0.4488888888888889\n",
            "Epoch 1: train loss 1.5608073870340984, train accuracy 0.4111111111111111\n",
            "Epoch 1: train loss 1.5646122097969055, train accuracy 0.43555555555555553\n",
            "Epoch 1: train loss 1.486628704600864, train accuracy 0.5044444444444445\n",
            "Epoch 2: train loss 1.3607831862237718, train accuracy 0.5266666666666666\n",
            "Epoch 2: train loss 1.4669069978925917, train accuracy 0.43555555555555553\n",
            "Epoch 2: train loss 1.4333464238378737, train accuracy 0.4666666666666667\n",
            "Epoch 2: train loss 1.3732421497503917, train accuracy 0.5222222222222223\n",
            "Epoch 3: train loss 1.3242343366146088, train accuracy 0.5066666666666667\n",
            "Epoch 3: train loss 1.4665162596437666, train accuracy 0.4622222222222222\n",
            "Epoch 3: train loss 1.4338160289658441, train accuracy 0.4866666666666667\n",
            "Epoch 3: train loss 1.29830973678165, train accuracy 0.52\n",
            "Epoch 4: train loss 1.4267944561110601, train accuracy 0.49333333333333335\n",
            "Epoch 4: train loss 1.4142481552229986, train accuracy 0.49777777777777776\n",
            "Epoch 4: train loss 1.4115742577446833, train accuracy 0.5\n",
            "Epoch 4: train loss 1.3017201622327168, train accuracy 0.5288888888888889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:19:54,311 | server.py:229 | fit_round 26 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 26 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.3736240797572665, train accuracy 0.47333333333333333\n",
            "Epoch 5: train loss 1.3242477509710524, train accuracy 0.5111111111111111\n",
            "Epoch 5: train loss 1.3644155727492437, train accuracy 0.5133333333333333\n",
            "Epoch 5: train loss 1.2843903137577906, train accuracy 0.5377777777777778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:19:59,122 | server.py:116 | fit progress: (26, 1.398137093782425, {'accuracy': 0.5021}, 607.4970973059999)\n",
            "INFO:flower:fit progress: (26, 1.398137093782425, {'accuracy': 0.5021}, 607.4970973059999)\n",
            "INFO flower 2023-05-25 22:19:59,129 | server.py:163 | evaluate_round 26: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 26: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:19:59,134 | server.py:215 | fit_round 27: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 27: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.398137093782425 / accuracy 0.5021\n",
            "[Client 73, round 27] fit, config: {'server_round': 27, 'local_epochs': 5}\n",
            "[Client 62, round 27] fit, config: {'server_round': 27, 'local_epochs': 5}\n",
            "[Client 43, round 27] fit, config: {'server_round': 27, 'local_epochs': 5}\n",
            "[Client 28, round 27] fit, config: {'server_round': 27, 'local_epochs': 5}\n",
            "[Client 50, round 27] fit, config: {'server_round': 27, 'local_epochs': 5}\n",
            "[Client 64, round 27] fit, config: {'server_round': 27, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.6041165192921956, train accuracy 0.4177777777777778\n",
            "Epoch 1: train loss 1.5736284123526678, train accuracy 0.44666666666666666\n",
            "Epoch 1: train loss 1.6042971147431269, train accuracy 0.3888888888888889\n",
            "Epoch 1: train loss 1.5872817900445726, train accuracy 0.44222222222222224\n",
            "Epoch 1: train loss 1.6058446566263835, train accuracy 0.4022222222222222\n",
            "Epoch 1: train loss 1.5522574053870306, train accuracy 0.4288888888888889\n",
            "Epoch 2: train loss 1.539578914642334, train accuracy 0.40444444444444444\n",
            "Epoch 2: train loss 1.4566580951213837, train accuracy 0.4955555555555556\n",
            "Epoch 2: train loss 1.5134709609879389, train accuracy 0.4444444444444444\n",
            "Epoch 2: train loss 1.4708367122544184, train accuracy 0.4666666666666667\n",
            "Epoch 2: train loss 1.4499658677313063, train accuracy 0.4911111111111111\n",
            "Epoch 2: train loss 1.4412483043140836, train accuracy 0.4444444444444444\n",
            "Epoch 3: train loss 1.4248244828648038, train accuracy 0.4955555555555556\n",
            "Epoch 3: train loss 1.4112179544236925, train accuracy 0.4688888888888889\n",
            "Epoch 3: train loss 1.521982146633996, train accuracy 0.45555555555555555\n",
            "Epoch 3: train loss 1.421399884753757, train accuracy 0.4911111111111111\n",
            "Epoch 3: train loss 1.4520386788580153, train accuracy 0.4822222222222222\n",
            "Epoch 3: train loss 1.3981316751903958, train accuracy 0.5111111111111111\n",
            "Epoch 4: train loss 1.4507248865233526, train accuracy 0.48444444444444446\n",
            "Epoch 4: train loss 1.4696380363570318, train accuracy 0.47333333333333333\n",
            "Epoch 4: train loss 1.4812880754470825, train accuracy 0.4622222222222222\n",
            "Epoch 4: train loss 1.3674827350510492, train accuracy 0.49777777777777776\n",
            "Epoch 4: train loss 1.43340089586046, train accuracy 0.4866666666666667\n",
            "Epoch 4: train loss 1.3551129500071208, train accuracy 0.47333333333333333\n",
            "Epoch 5: train loss 1.4675040046374004, train accuracy 0.4822222222222222\n",
            "[Client 16, round 27] fit, config: {'server_round': 27, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.473127391603258, train accuracy 0.4688888888888889\n",
            "[Client 78, round 27] fit, config: {'server_round': 27, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.3865661025047302, train accuracy 0.4777777777777778\n",
            "[Client 81, round 27] fit, config: {'server_round': 27, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4063102801640828, train accuracy 0.49333333333333335\n",
            "[Client 0, round 27] fit, config: {'server_round': 27, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4591881963941786, train accuracy 0.48\n",
            "Epoch 5: train loss 1.3808609909481473, train accuracy 0.49333333333333335\n",
            "Epoch 1: train loss 1.5177915957238939, train accuracy 0.4022222222222222\n",
            "Epoch 1: train loss 1.498543335331811, train accuracy 0.4488888888888889\n",
            "Epoch 1: train loss 1.5922058555814955, train accuracy 0.43777777777777777\n",
            "Epoch 1: train loss 1.5039419796731737, train accuracy 0.4577777777777778\n",
            "Epoch 2: train loss 1.425322367085351, train accuracy 0.4955555555555556\n",
            "Epoch 2: train loss 1.4211074709892273, train accuracy 0.4688888888888889\n",
            "Epoch 2: train loss 1.534989403353797, train accuracy 0.45111111111111113\n",
            "Epoch 2: train loss 1.389132108953264, train accuracy 0.47333333333333333\n",
            "Epoch 3: train loss 1.3771229518784418, train accuracy 0.5\n",
            "Epoch 3: train loss 1.3587155805693731, train accuracy 0.5\n",
            "Epoch 3: train loss 1.4356179700957403, train accuracy 0.4444444444444444\n",
            "Epoch 3: train loss 1.3993368082576327, train accuracy 0.4888888888888889\n",
            "Epoch 4: train loss 1.3152405818303425, train accuracy 0.5111111111111111\n",
            "Epoch 4: train loss 1.3511638243993123, train accuracy 0.5088888888888888\n",
            "Epoch 4: train loss 1.4384228388468425, train accuracy 0.4822222222222222\n",
            "Epoch 4: train loss 1.2980935441123114, train accuracy 0.54\n",
            "Epoch 5: train loss 1.3361824221081204, train accuracy 0.5066666666666667\n",
            "Epoch 5: train loss 1.360590507586797, train accuracy 0.48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:20:17,418 | server.py:229 | fit_round 27 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 27 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.4152313338385687, train accuracy 0.45555555555555555\n",
            "Epoch 5: train loss 1.2845713330639734, train accuracy 0.5133333333333333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:20:21,283 | server.py:116 | fit progress: (27, 1.3913226461410522, {'accuracy': 0.5006}, 629.657617841)\n",
            "INFO:flower:fit progress: (27, 1.3913226461410522, {'accuracy': 0.5006}, 629.657617841)\n",
            "INFO flower 2023-05-25 22:20:21,290 | server.py:163 | evaluate_round 27: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 27: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:20:21,295 | server.py:215 | fit_round 28: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 28: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.3913226461410522 / accuracy 0.5006\n",
            "[Client 76, round 28] fit, config: {'server_round': 28, 'local_epochs': 5}\n",
            "[Client 77, round 28] fit, config: {'server_round': 28, 'local_epochs': 5}\n",
            "[Client 63, round 28] fit, config: {'server_round': 28, 'local_epochs': 5}\n",
            "[Client 89, round 28] fit, config: {'server_round': 28, 'local_epochs': 5}\n",
            "[Client 43, round 28] fit, config: {'server_round': 28, 'local_epochs': 5}\n",
            "[Client 74, round 28] fit, config: {'server_round': 28, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.5331337319480047, train accuracy 0.46444444444444444\n",
            "Epoch 1: train loss 1.62400303946601, train accuracy 0.39555555555555555\n",
            "Epoch 1: train loss 1.522794935438368, train accuracy 0.4577777777777778\n",
            "Epoch 1: train loss 1.650351557466719, train accuracy 0.4088888888888889\n",
            "Epoch 1: train loss 1.4763484464751349, train accuracy 0.46444444444444444\n",
            "Epoch 1: train loss 1.496008230580224, train accuracy 0.43777777777777777\n",
            "Epoch 2: train loss 1.4911627570788066, train accuracy 0.47555555555555556\n",
            "Epoch 2: train loss 1.4802125493685405, train accuracy 0.46\n",
            "Epoch 2: train loss 1.561982062127855, train accuracy 0.4577777777777778\n",
            "Epoch 2: train loss 1.4584855039914448, train accuracy 0.4822222222222222\n",
            "Epoch 2: train loss 1.4287969337569342, train accuracy 0.45111111111111113\n",
            "Epoch 2: train loss 1.4304596450593736, train accuracy 0.5133333333333333\n",
            "Epoch 3: train loss 1.3870999879307218, train accuracy 0.4777777777777778\n",
            "Epoch 3: train loss 1.4483810067176819, train accuracy 0.49333333333333335\n",
            "Epoch 3: train loss 1.375874360402425, train accuracy 0.5155555555555555\n",
            "Epoch 3: train loss 1.381797605090671, train accuracy 0.5066666666666667\n",
            "Epoch 3: train loss 1.489234897825453, train accuracy 0.4444444444444444\n",
            "Epoch 3: train loss 1.475981546772851, train accuracy 0.48444444444444446\n",
            "Epoch 4: train loss 1.3640058702892728, train accuracy 0.5111111111111111\n",
            "Epoch 4: train loss 1.383805023299323, train accuracy 0.48444444444444446\n",
            "Epoch 4: train loss 1.3539985683229234, train accuracy 0.4866666666666667\n",
            "Epoch 4: train loss 1.3756700091891818, train accuracy 0.4777777777777778\n",
            "Epoch 4: train loss 1.4899428884188335, train accuracy 0.45111111111111113\n",
            "Epoch 4: train loss 1.4053815139664545, train accuracy 0.5066666666666667\n",
            "Epoch 5: train loss 1.3362157278590732, train accuracy 0.5111111111111111\n",
            "[Client 15, round 28] fit, config: {'server_round': 28, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.3459676504135132, train accuracy 0.5111111111111111\n",
            "[Client 88, round 28] fit, config: {'server_round': 28, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.3345866534445021, train accuracy 0.5\n",
            "[Client 6, round 28] fit, config: {'server_round': 28, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4422476092974346, train accuracy 0.4666666666666667\n",
            "[Client 46, round 28] fit, config: {'server_round': 28, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.4419034057193332, train accuracy 0.49777777777777776Epoch 5: train loss 1.3306688136524625, train accuracy 0.4955555555555556\n",
            "\n",
            "Epoch 1: train loss 1.5168022513389587, train accuracy 0.44\n",
            "Epoch 1: train loss 1.461384697092904, train accuracy 0.4888888888888889\n",
            "Epoch 1: train loss 1.5452378127310011, train accuracy 0.45555555555555555\n",
            "Epoch 1: train loss 1.6202736629380121, train accuracy 0.4222222222222222\n",
            "Epoch 2: train loss 1.428194522857666, train accuracy 0.47555555555555556\n",
            "Epoch 2: train loss 1.4594955808586545, train accuracy 0.4666666666666667\n",
            "Epoch 2: train loss 1.4810322456889682, train accuracy 0.4488888888888889\n",
            "Epoch 2: train loss 1.464675572183397, train accuracy 0.4666666666666667\n",
            "Epoch 3: train loss 1.407378335793813, train accuracy 0.4822222222222222\n",
            "Epoch 3: train loss 1.3912150065104167, train accuracy 0.4911111111111111\n",
            "Epoch 3: train loss 1.405890213118659, train accuracy 0.4777777777777778\n",
            "Epoch 3: train loss 1.4293279515372381, train accuracy 0.4666666666666667\n",
            "Epoch 4: train loss 1.421174989806281, train accuracy 0.4777777777777778\n",
            "Epoch 4: train loss 1.3928075631459553, train accuracy 0.5244444444444445\n",
            "Epoch 4: train loss 1.4016736878289118, train accuracy 0.4533333333333333\n",
            "Epoch 4: train loss 1.3737763961156209, train accuracy 0.5244444444444445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:20:40,631 | server.py:229 | fit_round 28 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 28 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.3150872555043962, train accuracy 0.5288888888888889\n",
            "Epoch 5: train loss 1.3563276131947835, train accuracy 0.5177777777777778\n",
            "Epoch 5: train loss 1.3133832613627117, train accuracy 0.5044444444444445\n",
            "Epoch 5: train loss 1.3740785982873704, train accuracy 0.4955555555555556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:20:44,520 | server.py:116 | fit progress: (28, 1.378044763505459, {'accuracy': 0.5102}, 652.8952631329998)\n",
            "INFO:flower:fit progress: (28, 1.378044763505459, {'accuracy': 0.5102}, 652.8952631329998)\n",
            "INFO flower 2023-05-25 22:20:44,524 | server.py:163 | evaluate_round 28: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 28: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:20:44,532 | server.py:215 | fit_round 29: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 29: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.378044763505459 / accuracy 0.5102\n",
            "[Client 58, round 29] fit, config: {'server_round': 29, 'local_epochs': 5}\n",
            "[Client 46, round 29] fit, config: {'server_round': 29, 'local_epochs': 5}\n",
            "[Client 85, round 29] fit, config: {'server_round': 29, 'local_epochs': 5}\n",
            "[Client 53, round 29] fit, config: {'server_round': 29, 'local_epochs': 5}\n",
            "[Client 45, round 29] fit, config: {'server_round': 29, 'local_epochs': 5}\n",
            "[Client 40, round 29] fit, config: {'server_round': 29, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.5519921117358737, train accuracy 0.3888888888888889\n",
            "Epoch 1: train loss 1.5511703160074022, train accuracy 0.4311111111111111\n",
            "Epoch 1: train loss 1.5667930112944708, train accuracy 0.4111111111111111\n",
            "Epoch 1: train loss 1.5888535976409912, train accuracy 0.4266666666666667\n",
            "Epoch 1: train loss 1.5242606335216098, train accuracy 0.43555555555555553\n",
            "Epoch 1: train loss 1.5587668750021193, train accuracy 0.46444444444444444\n",
            "Epoch 2: train loss 1.4226789739396837, train accuracy 0.5044444444444445\n",
            "Epoch 2: train loss 1.5128425161043804, train accuracy 0.45111111111111113\n",
            "Epoch 2: train loss 1.4380803836716547, train accuracy 0.4822222222222222\n",
            "Epoch 2: train loss 1.483372430006663, train accuracy 0.46444444444444444\n",
            "Epoch 2: train loss 1.4132815798123677, train accuracy 0.5\n",
            "Epoch 2: train loss 1.3980534275372822, train accuracy 0.4822222222222222\n",
            "Epoch 3: train loss 1.4201310674349468, train accuracy 0.5111111111111111\n",
            "Epoch 3: train loss 1.3625260326597426, train accuracy 0.5044444444444445\n",
            "Epoch 3: train loss 1.433931827545166, train accuracy 0.4533333333333333\n",
            "Epoch 3: train loss 1.4592851599057515, train accuracy 0.47333333333333333\n",
            "Epoch 3: train loss 1.423484742641449, train accuracy 0.4822222222222222\n",
            "Epoch 3: train loss 1.4259528517723083, train accuracy 0.44\n",
            "Epoch 4: train loss 1.380751719077428, train accuracy 0.5266666666666666\n",
            "Epoch 4: train loss 1.3887080682648554, train accuracy 0.4911111111111111\n",
            "Epoch 4: train loss 1.3751803437868755, train accuracy 0.5044444444444445\n",
            "Epoch 4: train loss 1.3639661404821608, train accuracy 0.5155555555555555\n",
            "Epoch 4: train loss 1.382946401834488, train accuracy 0.5088888888888888\n",
            "Epoch 4: train loss 1.389896485540602, train accuracy 0.4777777777777778\n",
            "Epoch 5: train loss 1.3377351098590426, train accuracy 0.5155555555555555\n",
            "[Client 27, round 29] fit, config: {'server_round': 29, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.39928709798389, train accuracy 0.5044444444444445\n",
            "Epoch 5: train loss 1.4283103479279413, train accuracy 0.48\n",
            "[Client 98, round 29] fit, config: {'server_round': 29, 'local_epochs': 5}\n",
            "[Client 57, round 29] fit, config: {'server_round': 29, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.3478715022404988, train accuracy 0.4866666666666667\n",
            "[Client 43, round 29] fit, config: {'server_round': 29, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.3412616782718234, train accuracy 0.5044444444444445\n",
            "Epoch 5: train loss 1.3601789871851604, train accuracy 0.5111111111111111\n",
            "Epoch 1: train loss 1.607389317618476, train accuracy 0.43333333333333335\n",
            "Epoch 1: train loss 1.643532805972629, train accuracy 0.4066666666666667\n",
            "Epoch 1: train loss 1.5811987188127306, train accuracy 0.4622222222222222\n",
            "Epoch 1: train loss 1.5381115542517767, train accuracy 0.4622222222222222\n",
            "Epoch 2: train loss 1.4012796017858717, train accuracy 0.5066666666666667\n",
            "Epoch 2: train loss 1.5097303456730313, train accuracy 0.46\n",
            "Epoch 2: train loss 1.5148516562249925, train accuracy 0.44222222222222224\n",
            "Epoch 2: train loss 1.430693335003323, train accuracy 0.4866666666666667\n",
            "Epoch 3: train loss 1.3824338846736484, train accuracy 0.5266666666666666\n",
            "Epoch 3: train loss 1.4567649695608351, train accuracy 0.4666666666666667\n",
            "Epoch 3: train loss 1.4971819983588324, train accuracy 0.4711111111111111\n",
            "Epoch 3: train loss 1.3863188823064168, train accuracy 0.5066666666666667\n",
            "Epoch 4: train loss 1.366302791568968, train accuracy 0.5244444444444445\n",
            "Epoch 4: train loss 1.386936366558075, train accuracy 0.4866666666666667\n",
            "Epoch 4: train loss 1.396448963218265, train accuracy 0.5177777777777778\n",
            "Epoch 4: train loss 1.4453136656019423, train accuracy 0.4866666666666667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:21:02,767 | server.py:229 | fit_round 29 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 29 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.4017237424850464, train accuracy 0.4911111111111111\n",
            "Epoch 5: train loss 1.3056507507960002, train accuracy 0.52\n",
            "Epoch 5: train loss 1.4537387324704065, train accuracy 0.46\n",
            "Epoch 5: train loss 1.3354820609092712, train accuracy 0.5111111111111111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:21:06,673 | server.py:116 | fit progress: (29, 1.3796519815921784, {'accuracy': 0.5062}, 675.0480118619998)\n",
            "INFO:flower:fit progress: (29, 1.3796519815921784, {'accuracy': 0.5062}, 675.0480118619998)\n",
            "INFO flower 2023-05-25 22:21:06,677 | server.py:163 | evaluate_round 29: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 29: no clients selected, cancel\n",
            "DEBUG flower 2023-05-25 22:21:06,680 | server.py:215 | fit_round 30: strategy sampled 10 clients (out of 100)\n",
            "DEBUG:flower:fit_round 30: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.3796519815921784 / accuracy 0.5062\n",
            "[Client 24, round 30] fit, config: {'server_round': 30, 'local_epochs': 5}\n",
            "[Client 96, round 30] fit, config: {'server_round': 30, 'local_epochs': 5}[Client 23, round 30] fit, config: {'server_round': 30, 'local_epochs': 5}\n",
            "\n",
            "[Client 48, round 30] fit, config: {'server_round': 30, 'local_epochs': 5}\n",
            "[Client 7, round 30] fit, config: {'server_round': 30, 'local_epochs': 5}\n",
            "[Client 53, round 30] fit, config: {'server_round': 30, 'local_epochs': 5}\n",
            "Epoch 1: train loss 1.4824728502167597, train accuracy 0.47555555555555556\n",
            "Epoch 1: train loss 1.6126487652460735, train accuracy 0.3844444444444444\n",
            "Epoch 1: train loss 1.5413655704922147, train accuracy 0.45111111111111113Epoch 1: train loss 1.4934786756833394, train accuracy 0.44666666666666666\n",
            "\n",
            "Epoch 1: train loss 1.5795131391949124, train accuracy 0.3888888888888889\n",
            "Epoch 1: train loss 1.5351674026913114, train accuracy 0.42444444444444446\n",
            "Epoch 2: train loss 1.4519639379448361, train accuracy 0.48\n",
            "Epoch 2: train loss 1.5132307675149705, train accuracy 0.4622222222222222\n",
            "Epoch 2: train loss 1.4094668361875746, train accuracy 0.47333333333333333\n",
            "Epoch 2: train loss 1.4741421673032973, train accuracy 0.44666666666666666\n",
            "Epoch 2: train loss 1.4479972389009264, train accuracy 0.4488888888888889\n",
            "Epoch 2: train loss 1.4875120653046503, train accuracy 0.46444444444444444\n",
            "Epoch 3: train loss 1.4131544563505385, train accuracy 0.49333333333333335\n",
            "Epoch 3: train loss 1.41077012485928, train accuracy 0.4444444444444444\n",
            "Epoch 3: train loss 1.4612582292821672, train accuracy 0.48\n",
            "Epoch 3: train loss 1.3763297994931538, train accuracy 0.46444444444444444\n",
            "Epoch 3: train loss 1.4016417397393122, train accuracy 0.48\n",
            "Epoch 3: train loss 1.3751651015546587, train accuracy 0.5111111111111111\n",
            "Epoch 4: train loss 1.3996272749371, train accuracy 0.4911111111111111\n",
            "Epoch 4: train loss 1.3961477544572618, train accuracy 0.4577777777777778\n",
            "Epoch 4: train loss 1.3265318671862285, train accuracy 0.49777777777777776\n",
            "Epoch 4: train loss 1.3777263694339328, train accuracy 0.5155555555555555\n",
            "Epoch 4: train loss 1.3726724253760443, train accuracy 0.5155555555555555\n",
            "Epoch 4: train loss 1.4510925809542339, train accuracy 0.4866666666666667\n",
            "Epoch 5: train loss 1.3272491825951471, train accuracy 0.5177777777777778\n",
            "[Client 64, round 30] fit, config: {'server_round': 30, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.3614737027221255, train accuracy 0.4888888888888889\n",
            "[Client 33, round 30] fit, config: {'server_round': 30, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.38394076956643, train accuracy 0.4911111111111111\n",
            "[Client 22, round 30] fit, config: {'server_round': 30, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.2916347251998053, train accuracy 0.5155555555555555\n",
            "[Client 71, round 30] fit, config: {'server_round': 30, 'local_epochs': 5}\n",
            "Epoch 5: train loss 1.3230443232589297, train accuracy 0.5444444444444444\n",
            "Epoch 5: train loss 1.4028540485435061, train accuracy 0.4888888888888889\n",
            "Epoch 1: train loss 1.5933918025758531, train accuracy 0.4022222222222222\n",
            "Epoch 1: train loss 1.5377526217036777, train accuracy 0.4533333333333333\n",
            "Epoch 1: train loss 1.4954423838191562, train accuracy 0.44222222222222224\n",
            "Epoch 1: train loss 1.6190759738286336, train accuracy 0.4066666666666667\n",
            "Epoch 2: train loss 1.4515429470274184, train accuracy 0.4577777777777778\n",
            "Epoch 2: train loss 1.440720472070906, train accuracy 0.47555555555555556\n",
            "Epoch 2: train loss 1.4401454461945429, train accuracy 0.49777777777777776\n",
            "Epoch 2: train loss 1.4645675553215876, train accuracy 0.49333333333333335\n",
            "Epoch 3: train loss 1.4625001417265997, train accuracy 0.4688888888888889\n",
            "Epoch 3: train loss 1.420387903849284, train accuracy 0.4911111111111111\n",
            "Epoch 3: train loss 1.456120981110467, train accuracy 0.4622222222222222\n",
            "Epoch 3: train loss 1.4913452863693237, train accuracy 0.47333333333333333\n",
            "Epoch 4: train loss 1.3789944979879591, train accuracy 0.5155555555555555\n",
            "Epoch 4: train loss 1.363499727514055, train accuracy 0.52\n",
            "Epoch 4: train loss 1.3972836666636996, train accuracy 0.4822222222222222\n",
            "Epoch 4: train loss 1.4154234793451097, train accuracy 0.4711111111111111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-05-25 22:21:25,360 | server.py:229 | fit_round 30 received 10 results and 0 failures\n",
            "DEBUG:flower:fit_round 30 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.3616801036728754, train accuracy 0.4955555555555556\n",
            "Epoch 5: train loss 1.3204087946150038, train accuracy 0.5244444444444445\n",
            "Epoch 5: train loss 1.3616632686720953, train accuracy 0.5288888888888889\n",
            "Epoch 5: train loss 1.4118530419137743, train accuracy 0.48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-05-25 22:21:29,140 | server.py:116 | fit progress: (30, 1.3692414423823356, {'accuracy': 0.5129}, 697.5148169049999)\n",
            "INFO:flower:fit progress: (30, 1.3692414423823356, {'accuracy': 0.5129}, 697.5148169049999)\n",
            "INFO flower 2023-05-25 22:21:29,143 | server.py:163 | evaluate_round 30: no clients selected, cancel\n",
            "INFO:flower:evaluate_round 30: no clients selected, cancel\n",
            "INFO flower 2023-05-25 22:21:29,146 | server.py:144 | FL finished in 697.5207943149999\n",
            "INFO:flower:FL finished in 697.5207943149999\n",
            "INFO flower 2023-05-25 22:21:29,150 | app.py:192 | app_fit: losses_distributed []\n",
            "INFO:flower:app_fit: losses_distributed []\n",
            "INFO flower 2023-05-25 22:21:29,158 | app.py:193 | app_fit: metrics_distributed {}\n",
            "INFO:flower:app_fit: metrics_distributed {}\n",
            "INFO flower 2023-05-25 22:21:29,160 | app.py:194 | app_fit: losses_centralized [(0, 2.3038880437612534), (1, 2.109095280468464), (2, 1.972492690384388), (3, 1.8904584163427354), (4, 1.8255807301402092), (5, 1.7847999560832977), (6, 1.742974908053875), (7, 1.712778445482254), (8, 1.6776006150245666), (9, 1.6379253214597702), (10, 1.6131660467386246), (11, 1.5919593322277068), (12, 1.5642313978075981), (13, 1.5418420234322547), (14, 1.5269755792617798), (15, 1.5104037708044051), (16, 1.5006945283710957), (17, 1.4792648033797742), (18, 1.4703371922671795), (19, 1.461723094433546), (20, 1.4547788849473), (21, 1.4366457156836987), (22, 1.429206059873104), (23, 1.4237524403631687), (24, 1.4109964521229268), (25, 1.3972075460851192), (26, 1.398137093782425), (27, 1.3913226461410522), (28, 1.378044763505459), (29, 1.3796519815921784), (30, 1.3692414423823356)]\n",
            "INFO:flower:app_fit: losses_centralized [(0, 2.3038880437612534), (1, 2.109095280468464), (2, 1.972492690384388), (3, 1.8904584163427354), (4, 1.8255807301402092), (5, 1.7847999560832977), (6, 1.742974908053875), (7, 1.712778445482254), (8, 1.6776006150245666), (9, 1.6379253214597702), (10, 1.6131660467386246), (11, 1.5919593322277068), (12, 1.5642313978075981), (13, 1.5418420234322547), (14, 1.5269755792617798), (15, 1.5104037708044051), (16, 1.5006945283710957), (17, 1.4792648033797742), (18, 1.4703371922671795), (19, 1.461723094433546), (20, 1.4547788849473), (21, 1.4366457156836987), (22, 1.429206059873104), (23, 1.4237524403631687), (24, 1.4109964521229268), (25, 1.3972075460851192), (26, 1.398137093782425), (27, 1.3913226461410522), (28, 1.378044763505459), (29, 1.3796519815921784), (30, 1.3692414423823356)]\n",
            "INFO flower 2023-05-25 22:21:29,165 | app.py:195 | app_fit: metrics_centralized {'accuracy': [(0, 0.1018), (1, 0.2227), (2, 0.2673), (3, 0.2992), (4, 0.3253), (5, 0.3409), (6, 0.3583), (7, 0.3774), (8, 0.3846), (9, 0.4), (10, 0.4068), (11, 0.4185), (12, 0.4288), (13, 0.4391), (14, 0.4436), (15, 0.4557), (16, 0.4497), (17, 0.4661), (18, 0.4692), (19, 0.4681), (20, 0.4725), (21, 0.4805), (22, 0.485), (23, 0.4899), (24, 0.4939), (25, 0.5006), (26, 0.5021), (27, 0.5006), (28, 0.5102), (29, 0.5062), (30, 0.5129)]}\n",
            "INFO:flower:app_fit: metrics_centralized {'accuracy': [(0, 0.1018), (1, 0.2227), (2, 0.2673), (3, 0.2992), (4, 0.3253), (5, 0.3409), (6, 0.3583), (7, 0.3774), (8, 0.3846), (9, 0.4), (10, 0.4068), (11, 0.4185), (12, 0.4288), (13, 0.4391), (14, 0.4436), (15, 0.4557), (16, 0.4497), (17, 0.4661), (18, 0.4692), (19, 0.4681), (20, 0.4725), (21, 0.4805), (22, 0.485), (23, 0.4899), (24, 0.4939), (25, 0.5006), (26, 0.5021), (27, 0.5006), (28, 0.5102), (29, 0.5062), (30, 0.5129)]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.3692414423823356 / accuracy 0.5129\n"
          ]
        }
      ],
      "source": [
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=FRACTION_FIT,\n",
        "    fraction_evaluate=FRACTION_EVAL,\n",
        "    min_fit_clients=int(NUM_CLIENTS * FRACTION_FIT),\n",
        "    min_evaluate_clients=int(NUM_CLIENTS * FRACTION_EVAL),\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=initial_parameters,  # Pass the initial parameters\n",
        "    on_fit_config_fn=fit_config,            # Pass the fit_config function\n",
        "    evaluate_fn=evaluate,                   # Pass the evaluation function\n",
        ")\n",
        "\n",
        "history = start_simulation(\n",
        "    strategy=strategy,\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=NUM_ROUNDS),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "iZLAeVlRk_gv",
        "outputId": "c3d524a1-8d43-4cc4-a81e-dada81afc847"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc1b6c56ad0>]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot([v for _, v in history.losses_centralized])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "uwmF_IKBQLg6",
        "outputId": "fe03301e-ea3d-46d4-c69a-e09480b8b161"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc1a669f880>]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot([v for _, v in history.metrics_centralized[\"accuracy\"]])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "f4e66fa4acf8f75cb7e5bf746b87cb26119baafbc935380f682e62cbdd8df510"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
