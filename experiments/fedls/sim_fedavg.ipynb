{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz71fPGrpRiQ"
      },
      "source": [
        "# **Federated Learning with (PeerReview-)Flower and FedAvg**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4KiTMTpiort"
      },
      "source": [
        "### Installing dependencies\n",
        "\n",
        "First, we install the necessary packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PAxbNFt6in6"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/passerim/peer-reviewed-flower.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abtAKdBl6in6"
      },
      "source": [
        "Now that we have all dependencies installed, we can import everything we need for this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os; os.chdir(\"../..\"); import prflwr; os.chdir(\"experiments/fedls\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eTrCL2FmC5U5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import flwr as fl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from prflwr.simulation import start_simulation\n",
        "from prflwr.utils import non_iid_partitions\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TllM4BjqxRrG"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Set useful constants, experiments settings and random seed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RV_Mu96KhHBu"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxsPYpBPhOvN",
        "outputId": "02477350-6564-4f9b-e9b2-d676c5c0c0d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 30 rounds\n",
            "Training on cpu\n"
          ]
        }
      ],
      "source": [
        "# Setting random seed for reproducibility\n",
        "SEED = 123\n",
        "set_seed(SEED)\n",
        "\n",
        "# Experimental settings\n",
        "DATASET = \"CIFAR10\"  # admissible values: \"CIFAR10\" or \"CIFAR100\"\n",
        "NUM_ROUNDS = 30\n",
        "NUM_CLIENTS = 100\n",
        "LOCAL_EPOCHS = 5\n",
        "BATCH_SIZE = 50\n",
        "FRACTION_FIT = 0.1\n",
        "FRACTION_EVAL = 0  # Model performance will be evaluated in a centralized way\n",
        "print(f\"Training for {NUM_ROUNDS} rounds\")\n",
        "\n",
        "# Device to use for training and evaluation\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "print(f\"Training on {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVcgAAiaihnx"
      },
      "source": [
        "## Data loading\n",
        "\n",
        "Let's now load the CIFAR-10 (or CIFAR-100) training and test set, partition them into `NUM_CLIENTS` smaller datasets (each split into training and validation set), and wrap everything in their own `DataLoader`. Test data will be used to evaluate model's performance in a centralized way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4Em7BPNTXeX",
        "outputId": "8c158396-8531-43e8-98b6-a0f78e54bfbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "def load_datasets(\n",
        "    num_clients: int,\n",
        "    dataset: str = \"CIFAR10\",\n",
        "    src: str = \"./data\",\n",
        "    iid: bool = True,\n",
        "    concentration: float = 1,\n",
        "    use_augmentation: bool = True,\n",
        ") -> Tuple[List[DataLoader], List[DataLoader], DataLoader]:\n",
        "    if dataset not in [\"CIFAR10\", \"CIFAR100\"]:\n",
        "        raise ValueError(\n",
        "            \"Unknown dataset! Admissible values are: 'CIFAR10' or 'CIFAR100'.\"\n",
        "        )\n",
        "\n",
        "    # Download and transform CIFAR dataset (train and test)\n",
        "    augmentation = (\n",
        "        [\n",
        "            transforms.RandomCrop(24),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "        ]\n",
        "        if use_augmentation\n",
        "        else []\n",
        "    )\n",
        "    transform = [\n",
        "        transforms.CenterCrop(24),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ]\n",
        "    trainset = getattr(torchvision.datasets, dataset)(\n",
        "        src,\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([*augmentation, *transform]),\n",
        "    )\n",
        "    testset = getattr(torchvision.datasets, dataset)(\n",
        "        src,\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([*transform]),\n",
        "    )\n",
        "\n",
        "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
        "    if not iid:\n",
        "        targets = np.array(trainset.targets)\n",
        "        idxs = np.array(range(len(targets)))\n",
        "        dataset = [idxs, targets]\n",
        "        train_partitions = non_iid_partitions(\n",
        "            dataset,\n",
        "            num_partitions=num_clients,\n",
        "            concentration=concentration,\n",
        "        )\n",
        "        subsets = list(map(lambda p: Subset(trainset, p), train_partitions))\n",
        "    else:\n",
        "        partition_size = len(trainset) // num_clients\n",
        "        lengths = [partition_size] * num_clients\n",
        "        subsets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in subsets:\n",
        "        len_val = len(ds) // 10  #  use 10% of client's data as validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS, src=\"../../data/cifar10\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBp7kB4G0sPB"
      },
      "source": [
        "## Model training/evaluation\n",
        "\n",
        "Let's continue with the usual model definition (including `set_parameters` and `get_parameters`), training and test functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2X3cVBXMpP6w"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes: int) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 8, 5, 1, 1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(8, 16, 5, 1, 1)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def train(net, trainloader, epochs=1, lr=0.01):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for batch, (images, labels) in enumerate(trainloader):\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss.item()\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= (batch + 1)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch, (images, labels) in enumerate(testloader):\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= (batch + 1)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZlzx1tbdnGz"
      },
      "source": [
        "Let's check model's correctness, then print some info about the datasets and splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQmFLwyrcZ4U",
        "outputId": "8375ef11-5fbd-410e-c404-57d6740cd75e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model parameters: 45626\n",
            "Client's trainset size: 450\n",
            "Client's validation set size: 50\n",
            "Server's testset size: 10000\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of the model\n",
        "NUM_CLASSES = len(np.unique(testloader.dataset.targets))\n",
        "net = Net(NUM_CLASSES).to(DEVICE)\n",
        "with torch.no_grad():\n",
        "    assert net(torch.randn((3, 24, 24), device=DEVICE)).shape == torch.Size(\n",
        "        [1, NUM_CLASSES]\n",
        "    )\n",
        "\n",
        "# Print some stats about the model and the data\n",
        "print(\"Model parameters:\", sum(p.numel() for p in net.parameters() if p.requires_grad))\n",
        "print(\"Client's trainset size:\", len(trainloaders[0].dataset))\n",
        "print(\"Client's validation set size:\", len(valloaders[0].dataset))\n",
        "print(\"Server's testset size:\", len(testloader.dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yW_cnCapDN9"
      },
      "source": [
        "## Flower client\n",
        "\n",
        "To implement the Flower client, we create a subclass of `flwr.client.NumPyClient` and implement the three methods `get_parameters`, `fit`, and `evaluate`. Here, we also pass the `cid` to the client and use it log additional details."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1lCf3oljdClM"
      },
      "source": [
        "### Sending/receiving arbitrary values to/from clients\n",
        "\n",
        "In some situations, we want to dinamically configure client side training and evaluation from the server-side, for example by setting the learning rate or the local epochs. Flower provides a way to send configuration values from the server to the clients using a dictionary. Clients receive values from the server through the `config` parameter and can read values from this dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZH3f2rt7h-Ih"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        # Read values from config\n",
        "        server_round = config[\"server_round\"]\n",
        "        local_epochs = config[\"local_epochs\"]\n",
        "        learning_rate = config[\"learning_rate\"]\n",
        "        # Use values provided by the config\n",
        "        print(f\"[Client {self.cid}, round {server_round}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, local_epochs, learning_rate)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    net = Net(NUM_CLASSES).to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F8eKOYYsix3W"
      },
      "source": [
        "We can send the config dictionary from the server to the clients providing a function to the strategy that gets called every round of federated learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wlqLKGdJgVRg"
      },
      "outputs": [],
      "source": [
        "def fit_config(server_round: int):\n",
        "    # os.system(\"rm -r /tmp/ray\")\n",
        "    config = {\n",
        "        \"server_round\": server_round,  # The current round of federated learning\n",
        "        \"local_epochs\":  LOCAL_EPOCHS,\n",
        "        \"learning_rate\": 0.25 * (0.99 ** (server_round - 1)),\n",
        "    }\n",
        "    return config"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "axzXSMtlfhXU"
      },
      "source": [
        "## Customizing the FedAvg strategy\n",
        "\n",
        "The strategy encapsulates the federated learning algorithm, in this notebook we will use the standard version of FedAvg. We will also customize the parameters initilization of the global model and the centralized model evaluation."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "p6FHRf8HrbzV"
      },
      "source": [
        "### Server-side parameter **initialization**\n",
        "\n",
        "Flower, by default, initializes the global model by asking one random client for the initial parameters, however when more control on the initialization is needed passing `initial_parameters` to the `FedAvg` strategy prevents Flower from asking one of the clients for the initial parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "50Y2yxJOjw4z"
      },
      "outputs": [],
      "source": [
        "initial_parameters = fl.common.ndarrays_to_parameters(get_parameters(Net(NUM_CLASSES)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wt3_SmQKnpRO"
      },
      "source": [
        "### Server-side parameter **evaluation**\n",
        "\n",
        "With Flower, we can evaluate the aggregated model on the server-side or on the client-side. Centralized evaluation is conceptually simpler: if there is a server-side dataset that can be used for evaluation purposes, then we can evaluate the newly aggregated model after each round of training without having to send the model to clients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MDovnUvsn7if"
      },
      "outputs": [],
      "source": [
        "# The `evaluate` function will be by Flower called after every round\n",
        "def evaluate(\n",
        "    server_round: int, parameters: fl.common.NDArrays, config: Dict[str, fl.common.Scalar]\n",
        ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "    net = Net(NUM_CLASSES).to(DEVICE)\n",
        "    set_parameters(net, parameters)  # Update model with the latest parameters\n",
        "    loss, accuracy = test(net, testloader)\n",
        "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
        "    return loss, {\"accuracy\": accuracy}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "POBApsmwuCx2"
      },
      "source": [
        "## Running federated learning\n",
        "\n",
        "Let's run a federated learning experiment with a large number of clients. We have 100 partitions, each holding 450 training and 50 validation examples. We configure the clients to perform 5 local training epochs. The federated learning simulation is started by the function `start_simulation`, in this case we will use the sequential simulation implemented in PeerReview-Flower. The `start_simulation` function accepts a number of arguments:\n",
        "* `client_fn` is used to create `FlowerClient` instances,\n",
        "* the number of clients to simulate is specified by `num_clients`,\n",
        "* the number of rounds `num_rounds` is encapsulated in a `flwr.server.ServerConfig`,\n",
        "* `strategy` is used to specify the custom strategy we configured above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVTrw7OsttE7",
        "outputId": "0e3f799a-d895-4346-b7d5-7bbc09e49d22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:01:57,923 | app.py:95 | Starting Flower simulation, config: ServerConfig(num_rounds=30, round_timeout=None)\n",
            "INFO flower 2023-01-02 13:01:58,059 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2023-01-02 13:01:58,060 | server.py:266 | Using initial parameters provided by strategy\n",
            "INFO flower 2023-01-02 13:01:58,061 | server.py:88 | Evaluating initial parameters\n",
            "INFO flower 2023-01-02 13:02:00,795 | server.py:91 | initial parameters (loss, other metrics): 2.30655566573143, {'accuracy': 0.1}\n",
            "INFO flower 2023-01-02 13:02:00,796 | server.py:101 | FL starting\n",
            "DEBUG flower 2023-01-02 13:02:00,797 | server.py:215 | fit_round 1: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 2.30655566573143 / accuracy 0.1\n",
            "[Client 48, round 1] fit, config: {'server_round': 1, 'local_epochs': 5, 'learning_rate': 0.25}\n",
            "[Client 47, round 1] fit, config: {'server_round': 1, 'local_epochs': 5, 'learning_rate': 0.25}\n",
            "[Client 8, round 1] fit, config: {'server_round': 1, 'local_epochs': 5, 'learning_rate': 0.25}\n",
            "[Client 37, round 1] fit, config: {'server_round': 1, 'local_epochs': 5, 'learning_rate': 0.25}\n",
            "[Client 15, round 1] fit, config: {'server_round': 1, 'local_epochs': 5, 'learning_rate': 0.25}\n",
            "[Client 33, round 1] fit, config: {'server_round': 1, 'local_epochs': 5, 'learning_rate': 0.25}\n",
            "[Client 64, round 1] fit, config: {'server_round': 1, 'local_epochs': 5, 'learning_rate': 0.25}\n",
            "[Client 77, round 1] fit, config: {'server_round': 1, 'local_epochs': 5, 'learning_rate': 0.25}\n",
            "[Client 41, round 1] fit, config: {'server_round': 1, 'local_epochs': 5, 'learning_rate': 0.25}\n",
            "[Client 7, round 1] fit, config: {'server_round': 1, 'local_epochs': 5, 'learning_rate': 0.25}\n",
            "Epoch 1: train loss 2.3115269343058267, accuracy 0.09111111111111111\n",
            "Epoch 1: train loss 2.3012457423739963, accuracy 0.11555555555555555\n",
            "Epoch 1: train loss 2.307942416932848, accuracy 0.08222222222222222\n",
            "Epoch 1: train loss 2.2983626789516873, accuracy 0.10888888888888888\n",
            "Epoch 1: train loss 2.305410861968994, accuracy 0.09555555555555556\n",
            "Epoch 1: train loss 2.309536933898926, accuracy 0.08444444444444445\n",
            "Epoch 1: train loss 2.304082234700521, accuracy 0.09555555555555556\n",
            "Epoch 1: train loss 2.3061263826158314, accuracy 0.1111111111111111\n",
            "Epoch 1: train loss 2.3099293973710804, accuracy 0.08444444444444445\n",
            "Epoch 1: train loss 2.310855415132311, accuracy 0.07555555555555556\n",
            "Epoch 2: train loss 2.3019507196214466, accuracy 0.10888888888888888\n",
            "Epoch 2: train loss 2.29146311018202, accuracy 0.14222222222222222\n",
            "Epoch 2: train loss 2.3019707997639975, accuracy 0.10444444444444445\n",
            "Epoch 2: train loss 2.2946685949961343, accuracy 0.1\n",
            "Epoch 2: train loss 2.3002374437120228, accuracy 0.1111111111111111\n",
            "Epoch 2: train loss 2.2965102990468345, accuracy 0.1\n",
            "Epoch 2: train loss 2.2963443862067328, accuracy 0.11777777777777777\n",
            "Epoch 2: train loss 2.3029509915245905, accuracy 0.08888888888888889\n",
            "Epoch 2: train loss 2.2984788947635226, accuracy 0.09777777777777778\n",
            "Epoch 2: train loss 2.2935801876915827, accuracy 0.11777777777777777\n",
            "Epoch 3: train loss 2.2921343909369574, accuracy 0.1511111111111111\n",
            "Epoch 3: train loss 2.2805013391706677, accuracy 0.14222222222222222\n",
            "Epoch 3: train loss 2.2924676736195884, accuracy 0.14222222222222222\n",
            "Epoch 3: train loss 2.292513476477729, accuracy 0.12222222222222222\n",
            "Epoch 3: train loss 2.2904126114315457, accuracy 0.13555555555555557\n",
            "Epoch 3: train loss 2.2778404818640814, accuracy 0.15333333333333332\n",
            "Epoch 3: train loss 2.275615109337701, accuracy 0.14222222222222222\n",
            "Epoch 3: train loss 2.281746122572157, accuracy 0.14888888888888888\n",
            "Epoch 3: train loss 2.2881285084618463, accuracy 0.13777777777777778\n",
            "Epoch 3: train loss 2.2769716845618353, accuracy 0.15333333333333332\n",
            "Epoch 4: train loss 2.2703569995032415, accuracy 0.14888888888888888\n",
            "Epoch 4: train loss 2.2627135382758246, accuracy 0.14222222222222222\n",
            "Epoch 4: train loss 2.2698896725972495, accuracy 0.14444444444444443\n",
            "Epoch 4: train loss 2.2684672938452826, accuracy 0.14\n",
            "Epoch 4: train loss 2.26969141430325, accuracy 0.1288888888888889\n",
            "Epoch 4: train loss 2.2535337342156305, accuracy 0.18\n",
            "Epoch 4: train loss 2.2717038260565863, accuracy 0.1688888888888889\n",
            "Epoch 4: train loss 2.248326884375678, accuracy 0.18222222222222223\n",
            "Epoch 4: train loss 2.237882057825724, accuracy 0.15333333333333332\n",
            "Epoch 4: train loss 2.234777185651991, accuracy 0.15777777777777777\n",
            "Epoch 5: train loss 2.2336475054423013, accuracy 0.15777777777777777\n",
            "Epoch 5: train loss 2.232504818174574, accuracy 0.13555555555555557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:02:13,705 | server.py:229 | fit_round 1 received 10 results and 0 failures\n",
            "WARNING flower 2023-01-02 13:02:13,738 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 2.230281194051107, accuracy 0.17777777777777778\n",
            "Epoch 5: train loss 2.2224558459387884, accuracy 0.16666666666666666\n",
            "Epoch 5: train loss 2.2325150436825223, accuracy 0.14\n",
            "Epoch 5: train loss 2.235481341679891, accuracy 0.16666666666666666\n",
            "Epoch 5: train loss 2.2077820830874972, accuracy 0.19777777777777777\n",
            "Epoch 5: train loss 2.193068186442057, accuracy 0.20222222222222222\n",
            "Epoch 5: train loss 2.2245153850979276, accuracy 0.1622222222222222\n",
            "Epoch 5: train loss 2.208337518903944, accuracy 0.18888888888888888\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:02:16,912 | server.py:116 | fit progress: (1, 2.1898021697998047, {'accuracy': 0.1751}, 16.11516770900016)\n",
            "INFO flower 2023-01-02 13:02:16,912 | server.py:163 | evaluate_round 1: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:02:16,913 | server.py:215 | fit_round 2: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 2.1898021697998047 / accuracy 0.1751\n",
            "[Client 48, round 2] fit, config: {'server_round': 2, 'local_epochs': 5, 'learning_rate': 0.2475}\n",
            "[Client 6, round 2] fit, config: {'server_round': 2, 'local_epochs': 5, 'learning_rate': 0.2475}\n",
            "[Client 75, round 2] fit, config: {'server_round': 2, 'local_epochs': 5, 'learning_rate': 0.2475}\n",
            "[Client 49, round 2] fit, config: {'server_round': 2, 'local_epochs': 5, 'learning_rate': 0.2475}\n",
            "[Client 38, round 2] fit, config: {'server_round': 2, 'local_epochs': 5, 'learning_rate': 0.2475}\n",
            "[Client 13, round 2] fit, config: {'server_round': 2, 'local_epochs': 5, 'learning_rate': 0.2475}\n",
            "[Client 59, round 2] fit, config: {'server_round': 2, 'local_epochs': 5, 'learning_rate': 0.2475}\n",
            "[Client 73, round 2] fit, config: {'server_round': 2, 'local_epochs': 5, 'learning_rate': 0.2475}\n",
            "[Client 97, round 2] fit, config: {'server_round': 2, 'local_epochs': 5, 'learning_rate': 0.2475}\n",
            "[Client 90, round 2] fit, config: {'server_round': 2, 'local_epochs': 5, 'learning_rate': 0.2475}\n",
            "Epoch 1: train loss 2.190424336327447, accuracy 0.18222222222222223\n",
            "Epoch 1: train loss 2.2143564224243164, accuracy 0.19555555555555557\n",
            "Epoch 1: train loss 2.2200039757622614, accuracy 0.17777777777777778\n",
            "Epoch 1: train loss 2.253919071621365, accuracy 0.14222222222222222\n",
            "Epoch 1: train loss 2.1892390516069202, accuracy 0.18666666666666668\n",
            "Epoch 1: train loss 2.2067992422315807, accuracy 0.16\n",
            "Epoch 1: train loss 2.163850466410319, accuracy 0.17333333333333334\n",
            "Epoch 1: train loss 2.2098470528920493, accuracy 0.2088888888888889\n",
            "Epoch 1: train loss 2.2050595813327365, accuracy 0.18888888888888888\n",
            "Epoch 1: train loss 2.1703409353892007, accuracy 0.17777777777777778\n",
            "Epoch 2: train loss 2.171032508214315, accuracy 0.15555555555555556\n",
            "Epoch 2: train loss 2.1800316439734564, accuracy 0.18222222222222223\n",
            "Epoch 2: train loss 2.1380899217393665, accuracy 0.22\n",
            "Epoch 2: train loss 2.1894355879889593, accuracy 0.18888888888888888\n",
            "Epoch 2: train loss 2.1569537586636014, accuracy 0.2311111111111111\n",
            "Epoch 2: train loss 2.173056231604682, accuracy 0.22\n",
            "Epoch 2: train loss 2.17515402370029, accuracy 0.1711111111111111\n",
            "Epoch 2: train loss 2.163291056950887, accuracy 0.1688888888888889\n",
            "Epoch 2: train loss 2.1936625904507108, accuracy 0.17555555555555555\n",
            "Epoch 2: train loss 2.2215347819858127, accuracy 0.14666666666666667\n",
            "Epoch 3: train loss 2.104283889134725, accuracy 0.19333333333333333\n",
            "Epoch 3: train loss 2.161157581541273, accuracy 0.18666666666666668\n",
            "Epoch 3: train loss 2.1312431494394937, accuracy 0.16444444444444445\n",
            "Epoch 3: train loss 2.229965739780002, accuracy 0.1511111111111111\n",
            "Epoch 3: train loss 2.1430293718973794, accuracy 0.1711111111111111\n",
            "Epoch 3: train loss 2.151935577392578, accuracy 0.18444444444444444\n",
            "Epoch 3: train loss 2.148581796222263, accuracy 0.21333333333333335\n",
            "Epoch 3: train loss 2.1463176012039185, accuracy 0.19555555555555557\n",
            "Epoch 3: train loss 2.2239158815807767, accuracy 0.1688888888888889\n",
            "Epoch 3: train loss 2.1437381903330484, accuracy 0.18888888888888888\n",
            "Epoch 4: train loss 2.124392588933309, accuracy 0.19333333333333333\n",
            "Epoch 4: train loss 2.233312474356757, accuracy 0.15555555555555556\n",
            "Epoch 4: train loss 2.1181544727749295, accuracy 0.17777777777777778\n",
            "Epoch 4: train loss 2.1790639294518366, accuracy 0.17333333333333334\n",
            "Epoch 4: train loss 2.134549617767334, accuracy 0.22666666666666666\n",
            "Epoch 4: train loss 2.1717107031080456, accuracy 0.18888888888888888\n",
            "Epoch 4: train loss 2.1451340516408286, accuracy 0.21777777777777776\n",
            "Epoch 4: train loss 2.148000372780694, accuracy 0.15555555555555556\n",
            "Epoch 4: train loss 2.1553994284735785, accuracy 0.2\n",
            "Epoch 4: train loss 2.1408912208345203, accuracy 0.18444444444444444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:02:33,642 | server.py:229 | fit_round 2 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 2.0777696238623724, accuracy 0.2111111111111111\n",
            "Epoch 5: train loss 2.2037636174096003, accuracy 0.19555555555555557\n",
            "Epoch 5: train loss 2.08044351471795, accuracy 0.21777777777777776\n",
            "Epoch 5: train loss 2.1314909987979465, accuracy 0.20222222222222222\n",
            "Epoch 5: train loss 2.1081909603542752, accuracy 0.22\n",
            "Epoch 5: train loss 2.149714575873481, accuracy 0.1688888888888889\n",
            "Epoch 5: train loss 2.077318549156189, accuracy 0.21333333333333335\n",
            "Epoch 5: train loss 2.1232753064897327, accuracy 0.2088888888888889\n",
            "Epoch 5: train loss 2.1228226158354015, accuracy 0.21777777777777776\n",
            "Epoch 5: train loss 2.122673087649875, accuracy 0.18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:02:37,318 | server.py:116 | fit progress: (2, 2.0629611456394197, {'accuracy': 0.2207}, 36.52160762300082)\n",
            "INFO flower 2023-01-02 13:02:37,319 | server.py:163 | evaluate_round 2: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:02:37,319 | server.py:215 | fit_round 3: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 2.0629611456394197 / accuracy 0.2207\n",
            "[Client 41, round 3] fit, config: {'server_round': 3, 'local_epochs': 5, 'learning_rate': 0.245025}\n",
            "[Client 31, round 3] fit, config: {'server_round': 3, 'local_epochs': 5, 'learning_rate': 0.245025}\n",
            "[Client 82, round 3] fit, config: {'server_round': 3, 'local_epochs': 5, 'learning_rate': 0.245025}\n",
            "[Client 57, round 3] fit, config: {'server_round': 3, 'local_epochs': 5, 'learning_rate': 0.245025}\n",
            "[Client 56, round 3] fit, config: {'server_round': 3, 'local_epochs': 5, 'learning_rate': 0.245025}\n",
            "[Client 34, round 3] fit, config: {'server_round': 3, 'local_epochs': 5, 'learning_rate': 0.245025}\n",
            "[Client 72, round 3] fit, config: {'server_round': 3, 'local_epochs': 5, 'learning_rate': 0.245025}\n",
            "[Client 73, round 3] fit, config: {'server_round': 3, 'local_epochs': 5, 'learning_rate': 0.245025}\n",
            "[Client 44, round 3] fit, config: {'server_round': 3, 'local_epochs': 5, 'learning_rate': 0.245025}\n",
            "[Client 88, round 3] fit, config: {'server_round': 3, 'local_epochs': 5, 'learning_rate': 0.245025}\n",
            "Epoch 1: train loss 2.095528417163425, accuracy 0.21555555555555556\n",
            "Epoch 1: train loss 2.1115474038653903, accuracy 0.21333333333333335\n",
            "Epoch 1: train loss 2.124313566419813, accuracy 0.17777777777777778\n",
            "Epoch 1: train loss 2.1313316292232938, accuracy 0.17333333333333334\n",
            "Epoch 1: train loss 2.1492426925235324, accuracy 0.19555555555555557\n",
            "Epoch 1: train loss 2.096501257684496, accuracy 0.21333333333333335\n",
            "Epoch 1: train loss 2.1344983312818737, accuracy 0.2088888888888889\n",
            "Epoch 1: train loss 2.15283555454678, accuracy 0.16666666666666666\n",
            "Epoch 1: train loss 2.0964973502688937, accuracy 0.2\n",
            "Epoch 1: train loss 2.0696272320217557, accuracy 0.21777777777777776\n",
            "Epoch 2: train loss 2.066620018747118, accuracy 0.21777777777777776\n",
            "Epoch 2: train loss 2.1386782460742526, accuracy 0.20666666666666667\n",
            "Epoch 2: train loss 2.115112966961331, accuracy 0.18666666666666668\n",
            "Epoch 2: train loss 2.1352654298146567, accuracy 0.1622222222222222\n",
            "Epoch 2: train loss 2.0941792594061956, accuracy 0.21777777777777776\n",
            "Epoch 2: train loss 2.1437892648908825, accuracy 0.22666666666666666\n",
            "Epoch 2: train loss 2.1511205037434897, accuracy 0.19555555555555557\n",
            "Epoch 2: train loss 2.07568457391527, accuracy 0.23555555555555555\n",
            "Epoch 2: train loss 2.055954178174337, accuracy 0.22666666666666666\n",
            "Epoch 2: train loss 2.1241814295450845, accuracy 0.15777777777777777\n",
            "Epoch 3: train loss 2.0830582910113864, accuracy 0.17777777777777778\n",
            "Epoch 3: train loss 2.080098761452569, accuracy 0.21555555555555556\n",
            "Epoch 3: train loss 2.0753473970625134, accuracy 0.2288888888888889\n",
            "Epoch 3: train loss 2.035034603542752, accuracy 0.2288888888888889\n",
            "Epoch 3: train loss 2.0744960970348783, accuracy 0.18444444444444444\n",
            "Epoch 3: train loss 2.06316610177358, accuracy 0.2311111111111111\n",
            "Epoch 3: train loss 2.0710748698976307, accuracy 0.18222222222222223\n",
            "Epoch 3: train loss 2.0862846904330783, accuracy 0.19777777777777777\n",
            "Epoch 3: train loss 2.109035028351678, accuracy 0.19555555555555557\n",
            "Epoch 3: train loss 2.0965938568115234, accuracy 0.20666666666666667\n",
            "Epoch 4: train loss 2.098069535361396, accuracy 0.20666666666666667\n",
            "Epoch 4: train loss 2.054814020792643, accuracy 0.2111111111111111\n",
            "Epoch 4: train loss 2.0472027593188815, accuracy 0.24444444444444444\n",
            "Epoch 4: train loss 2.1184490389294095, accuracy 0.19555555555555557\n",
            "Epoch 4: train loss 2.0857507387797036, accuracy 0.22\n",
            "Epoch 4: train loss 2.075595498085022, accuracy 0.20222222222222222\n",
            "Epoch 4: train loss 2.063824415206909, accuracy 0.16666666666666666\n",
            "Epoch 4: train loss 2.121970706515842, accuracy 0.16444444444444445\n",
            "Epoch 4: train loss 2.1191591024398804, accuracy 0.18888888888888888\n",
            "Epoch 4: train loss 2.041254176033868, accuracy 0.19555555555555557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:02:51,406 | server.py:229 | fit_round 3 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 2.0681487321853638, accuracy 0.19777777777777777\n",
            "Epoch 5: train loss 2.081366393301222, accuracy 0.21333333333333335\n",
            "Epoch 5: train loss 2.0606825086805554, accuracy 0.20444444444444446\n",
            "Epoch 5: train loss 2.0146531661351523, accuracy 0.21555555555555556\n",
            "Epoch 5: train loss 2.039378219180637, accuracy 0.21777777777777776\n",
            "Epoch 5: train loss 2.1045691437191434, accuracy 0.23555555555555555\n",
            "Epoch 5: train loss 2.089146296183268, accuracy 0.21555555555555556\n",
            "Epoch 5: train loss 2.058923509385851, accuracy 0.2111111111111111\n",
            "Epoch 5: train loss 2.115175631311205, accuracy 0.16\n",
            "Epoch 5: train loss 2.0434206459257336, accuracy 0.1711111111111111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:02:54,573 | server.py:116 | fit progress: (3, 2.0181534522771836, {'accuracy': 0.2438}, 53.77632574299969)\n",
            "INFO flower 2023-01-02 13:02:54,573 | server.py:163 | evaluate_round 3: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:02:54,574 | server.py:215 | fit_round 4: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 2.0181534522771836 / accuracy 0.2438\n",
            "[Client 58, round 4] fit, config: {'server_round': 4, 'local_epochs': 5, 'learning_rate': 0.24257475}\n",
            "[Client 73, round 4] fit, config: {'server_round': 4, 'local_epochs': 5, 'learning_rate': 0.24257475}\n",
            "[Client 64, round 4] fit, config: {'server_round': 4, 'local_epochs': 5, 'learning_rate': 0.24257475}\n",
            "[Client 35, round 4] fit, config: {'server_round': 4, 'local_epochs': 5, 'learning_rate': 0.24257475}\n",
            "[Client 43, round 4] fit, config: {'server_round': 4, 'local_epochs': 5, 'learning_rate': 0.24257475}\n",
            "[Client 6, round 4] fit, config: {'server_round': 4, 'local_epochs': 5, 'learning_rate': 0.24257475}\n",
            "[Client 23, round 4] fit, config: {'server_round': 4, 'local_epochs': 5, 'learning_rate': 0.24257475}\n",
            "[Client 15, round 4] fit, config: {'server_round': 4, 'local_epochs': 5, 'learning_rate': 0.24257475}\n",
            "[Client 2, round 4] fit, config: {'server_round': 4, 'local_epochs': 5, 'learning_rate': 0.24257475}\n",
            "[Client 54, round 4] fit, config: {'server_round': 4, 'local_epochs': 5, 'learning_rate': 0.24257475}\n",
            "Epoch 1: train loss 2.088652941915724, accuracy 0.19333333333333333\n",
            "Epoch 1: train loss 2.1054020987616644, accuracy 0.19111111111111112\n",
            "Epoch 1: train loss 2.082160923216078, accuracy 0.24\n",
            "Epoch 1: train loss 2.0526512066523233, accuracy 0.24444444444444444\n",
            "Epoch 1: train loss 2.0762385659747653, accuracy 0.19111111111111112\n",
            "Epoch 1: train loss 2.059865713119507, accuracy 0.20666666666666667\n",
            "Epoch 1: train loss 2.0953982141282825, accuracy 0.2288888888888889\n",
            "Epoch 1: train loss 2.048901187049018, accuracy 0.19777777777777777\n",
            "Epoch 1: train loss 2.103838430510627, accuracy 0.1622222222222222\n",
            "Epoch 1: train loss 2.0585725175009832, accuracy 0.22\n",
            "Epoch 2: train loss 2.084256225162082, accuracy 0.2088888888888889\n",
            "Epoch 2: train loss 2.1139713393317328, accuracy 0.18444444444444444\n",
            "Epoch 2: train loss 2.040208180745443, accuracy 0.2\n",
            "Epoch 2: train loss 2.0594160424338446, accuracy 0.23777777777777778\n",
            "Epoch 2: train loss 2.1274189021852283, accuracy 0.2\n",
            "Epoch 2: train loss 2.050756123330858, accuracy 0.22444444444444445\n",
            "Epoch 2: train loss 2.046019540892707, accuracy 0.19777777777777777\n",
            "Epoch 2: train loss 2.0498038265440197, accuracy 0.19555555555555557\n",
            "Epoch 2: train loss 2.051369825998942, accuracy 0.24222222222222223\n",
            "Epoch 2: train loss 2.0600575473573475, accuracy 0.2288888888888889\n",
            "Epoch 3: train loss 2.074698951509264, accuracy 0.24444444444444444\n",
            "Epoch 3: train loss 2.149156755871243, accuracy 0.18\n",
            "Epoch 3: train loss 2.058399518330892, accuracy 0.20666666666666667\n",
            "Epoch 3: train loss 2.075170225567288, accuracy 0.20666666666666667\n",
            "Epoch 3: train loss 2.085309465726217, accuracy 0.2088888888888889\n",
            "Epoch 3: train loss 2.0783863597446017, accuracy 0.21777777777777776\n",
            "Epoch 3: train loss 2.0543585220972695, accuracy 0.24888888888888888\n",
            "Epoch 3: train loss 2.0210533804363675, accuracy 0.19333333333333333\n",
            "Epoch 3: train loss 1.99642546971639, accuracy 0.25333333333333335\n",
            "Epoch 3: train loss 2.054080777698093, accuracy 0.24\n",
            "Epoch 4: train loss 2.0466115474700928, accuracy 0.2111111111111111\n",
            "Epoch 4: train loss 2.0464493566089206, accuracy 0.23333333333333334\n",
            "Epoch 4: train loss 2.0398861037360296, accuracy 0.17555555555555555\n",
            "Epoch 4: train loss 2.066399229897393, accuracy 0.18222222222222223\n",
            "Epoch 4: train loss 2.0652560128106012, accuracy 0.23555555555555555\n",
            "Epoch 4: train loss 2.0064395798577204, accuracy 0.25333333333333335\n",
            "Epoch 4: train loss 2.0666059388054743, accuracy 0.23777777777777778\n",
            "Epoch 4: train loss 2.058802949057685, accuracy 0.2222222222222222\n",
            "Epoch 4: train loss 2.017999675538805, accuracy 0.21777777777777776\n",
            "Epoch 4: train loss 2.0723073614968195, accuracy 0.24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:03:10,283 | server.py:229 | fit_round 4 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 2.0715315341949463, accuracy 0.22444444444444445\n",
            "Epoch 5: train loss 2.12237458758884, accuracy 0.20222222222222222\n",
            "Epoch 5: train loss 2.004804836379157, accuracy 0.2288888888888889\n",
            "Epoch 5: train loss 2.014757831891378, accuracy 0.2644444444444444\n",
            "Epoch 5: train loss 2.023771736356947, accuracy 0.18888888888888888\n",
            "Epoch 5: train loss 2.0666589736938477, accuracy 0.23333333333333334\n",
            "Epoch 5: train loss 2.1133388545778065, accuracy 0.21777777777777776\n",
            "Epoch 5: train loss 2.098215924368964, accuracy 0.2088888888888889\n",
            "Epoch 5: train loss 2.0473176373375788, accuracy 0.22\n",
            "Epoch 5: train loss 2.0337676207224527, accuracy 0.25333333333333335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:03:13,068 | server.py:116 | fit progress: (4, 1.9932282614707946, {'accuracy': 0.2604}, 72.27153215199905)\n",
            "INFO flower 2023-01-02 13:03:13,069 | server.py:163 | evaluate_round 4: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:03:13,069 | server.py:215 | fit_round 5: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.9932282614707946 / accuracy 0.2604\n",
            "[Client 84, round 5] fit, config: {'server_round': 5, 'local_epochs': 5, 'learning_rate': 0.2401490025}\n",
            "[Client 63, round 5] fit, config: {'server_round': 5, 'local_epochs': 5, 'learning_rate': 0.2401490025}\n",
            "[Client 93, round 5] fit, config: {'server_round': 5, 'local_epochs': 5, 'learning_rate': 0.2401490025}\n",
            "[Client 16, round 5] fit, config: {'server_round': 5, 'local_epochs': 5, 'learning_rate': 0.2401490025}\n",
            "[Client 68, round 5] fit, config: {'server_round': 5, 'local_epochs': 5, 'learning_rate': 0.2401490025}\n",
            "[Client 5, round 5] fit, config: {'server_round': 5, 'local_epochs': 5, 'learning_rate': 0.2401490025}\n",
            "[Client 61, round 5] fit, config: {'server_round': 5, 'local_epochs': 5, 'learning_rate': 0.2401490025}\n",
            "[Client 60, round 5] fit, config: {'server_round': 5, 'local_epochs': 5, 'learning_rate': 0.2401490025}\n",
            "[Client 69, round 5] fit, config: {'server_round': 5, 'local_epochs': 5, 'learning_rate': 0.2401490025}\n",
            "[Client 18, round 5] fit, config: {'server_round': 5, 'local_epochs': 5, 'learning_rate': 0.2401490025}\n",
            "Epoch 1: train loss 2.0407344500223794, accuracy 0.23555555555555555\n",
            "Epoch 1: train loss 2.039971868197123, accuracy 0.23777777777777778\n",
            "Epoch 1: train loss 2.0206447309917874, accuracy 0.2111111111111111\n",
            "Epoch 1: train loss 2.085658404562208, accuracy 0.18666666666666668\n",
            "Epoch 1: train loss 1.975101523929172, accuracy 0.2777777777777778\n",
            "Epoch 1: train loss 2.0714863936106362, accuracy 0.2\n",
            "Epoch 1: train loss 2.0156523254182606, accuracy 0.25555555555555554\n",
            "Epoch 1: train loss 2.04651051097446, accuracy 0.21777777777777776\n",
            "Epoch 1: train loss 2.008011129167345, accuracy 0.22444444444444445\n",
            "Epoch 1: train loss 2.0403707954618664, accuracy 0.22666666666666666\n",
            "Epoch 2: train loss 2.088063213560316, accuracy 0.23333333333333334\n",
            "Epoch 2: train loss 2.0689200427797108, accuracy 0.2222222222222222\n",
            "Epoch 2: train loss 2.0606985886891684, accuracy 0.2222222222222222\n",
            "Epoch 2: train loss 2.0855055385165744, accuracy 0.22666666666666666\n",
            "Epoch 2: train loss 2.053793125682407, accuracy 0.2222222222222222\n",
            "Epoch 2: train loss 2.0347141292360096, accuracy 0.24666666666666667\n",
            "Epoch 2: train loss 2.030062609248691, accuracy 0.25333333333333335\n",
            "Epoch 2: train loss 2.0332320398754544, accuracy 0.2088888888888889\n",
            "Epoch 2: train loss 2.1271500057644315, accuracy 0.20444444444444446\n",
            "Epoch 2: train loss 1.996321267551846, accuracy 0.23555555555555555\n",
            "Epoch 3: train loss 2.116675919956631, accuracy 0.2311111111111111\n",
            "Epoch 3: train loss 2.033233390914069, accuracy 0.25555555555555554\n",
            "Epoch 3: train loss 2.043097178141276, accuracy 0.2311111111111111\n",
            "Epoch 3: train loss 1.9925018813874986, accuracy 0.2577777777777778\n",
            "Epoch 3: train loss 1.9898589981926813, accuracy 0.2511111111111111\n",
            "Epoch 3: train loss 2.06607358985477, accuracy 0.24444444444444444\n",
            "Epoch 3: train loss 1.9594245221879747, accuracy 0.24444444444444444\n",
            "Epoch 3: train loss 2.0416061083475747, accuracy 0.2311111111111111\n",
            "Epoch 3: train loss 1.996608747376336, accuracy 0.23555555555555555\n",
            "Epoch 3: train loss 1.9878952503204346, accuracy 0.21777777777777776\n",
            "Epoch 4: train loss 2.022899945576986, accuracy 0.23333333333333334\n",
            "Epoch 4: train loss 1.9620745579401653, accuracy 0.2688888888888889\n",
            "Epoch 4: train loss 2.049805177582635, accuracy 0.23777777777777778\n",
            "Epoch 4: train loss 2.0011651118596396, accuracy 0.2311111111111111\n",
            "Epoch 4: train loss 2.038983013894823, accuracy 0.22\n",
            "Epoch 4: train loss 2.0377005603578358, accuracy 0.2222222222222222\n",
            "Epoch 4: train loss 2.0345606406529746, accuracy 0.26222222222222225\n",
            "Epoch 4: train loss 1.993766228357951, accuracy 0.22\n",
            "Epoch 4: train loss 1.96483227941725, accuracy 0.24888888888888888\n",
            "Epoch 4: train loss 2.013372434510125, accuracy 0.24888888888888888\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:03:27,844 | server.py:229 | fit_round 5 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.982599178949992, accuracy 0.26222222222222225\n",
            "Epoch 5: train loss 2.0563159916136, accuracy 0.2222222222222222\n",
            "Epoch 5: train loss 1.9809147251976862, accuracy 0.2688888888888889\n",
            "Epoch 5: train loss 2.0480017529593573, accuracy 0.2644444444444444\n",
            "Epoch 5: train loss 1.991031249364217, accuracy 0.23333333333333334\n",
            "Epoch 5: train loss 1.9657673041025798, accuracy 0.2777777777777778\n",
            "Epoch 5: train loss 2.0305594073401556, accuracy 0.24444444444444444\n",
            "Epoch 5: train loss 2.07362343205346, accuracy 0.23777777777777778\n",
            "Epoch 5: train loss 1.956374168395996, accuracy 0.25555555555555554\n",
            "Epoch 5: train loss 1.9914069440629747, accuracy 0.22444444444444445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:03:30,894 | server.py:116 | fit progress: (5, 1.9428342407941819, {'accuracy': 0.2868}, 90.0976676650007)\n",
            "INFO flower 2023-01-02 13:03:30,895 | server.py:163 | evaluate_round 5: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:03:30,896 | server.py:215 | fit_round 6: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.9428342407941819 / accuracy 0.2868\n",
            "[Client 41, round 6] fit, config: {'server_round': 6, 'local_epochs': 5, 'learning_rate': 0.23774751247499998}\n",
            "[Client 47, round 6] fit, config: {'server_round': 6, 'local_epochs': 5, 'learning_rate': 0.23774751247499998}\n",
            "[Client 76, round 6] fit, config: {'server_round': 6, 'local_epochs': 5, 'learning_rate': 0.23774751247499998}\n",
            "[Client 4, round 6] fit, config: {'server_round': 6, 'local_epochs': 5, 'learning_rate': 0.23774751247499998}\n",
            "[Client 59, round 6] fit, config: {'server_round': 6, 'local_epochs': 5, 'learning_rate': 0.23774751247499998}\n",
            "[Client 28, round 6] fit, config: {'server_round': 6, 'local_epochs': 5, 'learning_rate': 0.23774751247499998}\n",
            "[Client 64, round 6] fit, config: {'server_round': 6, 'local_epochs': 5, 'learning_rate': 0.23774751247499998}\n",
            "[Client 99, round 6] fit, config: {'server_round': 6, 'local_epochs': 5, 'learning_rate': 0.23774751247499998}\n",
            "[Client 36, round 6] fit, config: {'server_round': 6, 'local_epochs': 5, 'learning_rate': 0.23774751247499998}\n",
            "[Client 90, round 6] fit, config: {'server_round': 6, 'local_epochs': 5, 'learning_rate': 0.23774751247499998}\n",
            "Epoch 1: train loss 1.9703188472323947, accuracy 0.24666666666666667\n",
            "Epoch 1: train loss 1.9446011914147272, accuracy 0.26222222222222225\n",
            "Epoch 1: train loss 2.048596077495151, accuracy 0.24\n",
            "Epoch 1: train loss 2.0126914580663047, accuracy 0.2777777777777778\n",
            "Epoch 1: train loss 2.069693499141269, accuracy 0.21777777777777776\n",
            "Epoch 1: train loss 1.9816926055484347, accuracy 0.23555555555555555\n",
            "Epoch 1: train loss 1.9276649289660983, accuracy 0.2733333333333333\n",
            "Epoch 1: train loss 1.9933228890101116, accuracy 0.22666666666666666\n",
            "Epoch 1: train loss 2.0027909676233926, accuracy 0.23555555555555555\n",
            "Epoch 1: train loss 1.9993999401728313, accuracy 0.24888888888888888\n",
            "Epoch 2: train loss 1.9971389108233981, accuracy 0.2311111111111111\n",
            "Epoch 2: train loss 1.9463669856389363, accuracy 0.24666666666666667\n",
            "Epoch 2: train loss 2.0577253103256226, accuracy 0.25555555555555554\n",
            "Epoch 2: train loss 1.9890641768773396, accuracy 0.2222222222222222\n",
            "Epoch 2: train loss 1.9509932332568698, accuracy 0.28\n",
            "Epoch 2: train loss 2.0577646758821277, accuracy 0.21333333333333335\n",
            "Epoch 2: train loss 1.9889540407392714, accuracy 0.2311111111111111\n",
            "Epoch 2: train loss 1.957197242312961, accuracy 0.26666666666666666\n",
            "Epoch 2: train loss 2.0179789066314697, accuracy 0.22\n",
            "Epoch 2: train loss 1.9730881187650893, accuracy 0.2311111111111111\n",
            "Epoch 3: train loss 2.040448268254598, accuracy 0.24222222222222223\n",
            "Epoch 3: train loss 2.065490232573615, accuracy 0.21555555555555556\n",
            "Epoch 3: train loss 1.951160642835829, accuracy 0.25555555555555554\n",
            "Epoch 3: train loss 1.900460097524855, accuracy 0.26666666666666666\n",
            "Epoch 3: train loss 1.9898191293080647, accuracy 0.25555555555555554\n",
            "Epoch 3: train loss 2.066802832815382, accuracy 0.28\n",
            "Epoch 3: train loss 1.986486964755588, accuracy 0.24888888888888888\n",
            "Epoch 3: train loss 1.9689661264419556, accuracy 0.2288888888888889\n",
            "Epoch 3: train loss 2.000103897518582, accuracy 0.24666666666666667\n",
            "Epoch 3: train loss 1.9901049666934543, accuracy 0.29333333333333333\n",
            "Epoch 4: train loss 2.0303897990120783, accuracy 0.2688888888888889\n",
            "Epoch 4: train loss 1.9963581032223172, accuracy 0.24222222222222223\n",
            "Epoch 4: train loss 1.9782848358154297, accuracy 0.27111111111111114\n",
            "Epoch 4: train loss 1.9130802022086248, accuracy 0.28\n",
            "Epoch 4: train loss 1.9708546267615423, accuracy 0.24888888888888888\n",
            "Epoch 4: train loss 1.9761761956744723, accuracy 0.22\n",
            "Epoch 4: train loss 1.987411379814148, accuracy 0.24666666666666667\n",
            "Epoch 4: train loss 1.9986606703864203, accuracy 0.2288888888888889\n",
            "Epoch 4: train loss 2.0077511734432645, accuracy 0.2644444444444444\n",
            "Epoch 4: train loss 1.9402726888656616, accuracy 0.26222222222222225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:03:47,104 | server.py:229 | fit_round 6 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.984714561038547, accuracy 0.23333333333333334\n",
            "Epoch 5: train loss 1.933481878704495, accuracy 0.2688888888888889\n",
            "Epoch 5: train loss 2.061586936314901, accuracy 0.2644444444444444\n",
            "Epoch 5: train loss 1.890190389421251, accuracy 0.2866666666666667\n",
            "Epoch 5: train loss 2.041822499699063, accuracy 0.20222222222222222\n",
            "Epoch 5: train loss 1.9326417181226943, accuracy 0.2733333333333333\n",
            "Epoch 5: train loss 1.939159870147705, accuracy 0.28444444444444444\n",
            "Epoch 5: train loss 2.0012551281187267, accuracy 0.23777777777777778\n",
            "Epoch 5: train loss 2.044666714138455, accuracy 0.22444444444444445\n",
            "Epoch 5: train loss 2.0294708410898843, accuracy 0.24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:03:50,347 | server.py:116 | fit progress: (6, 1.9086399233341218, {'accuracy': 0.3141}, 109.55071388000033)\n",
            "INFO flower 2023-01-02 13:03:50,348 | server.py:163 | evaluate_round 6: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:03:50,349 | server.py:215 | fit_round 7: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.9086399233341218 / accuracy 0.3141\n",
            "[Client 74, round 7] fit, config: {'server_round': 7, 'local_epochs': 5, 'learning_rate': 0.23537003735025}\n",
            "[Client 1, round 7] fit, config: {'server_round': 7, 'local_epochs': 5, 'learning_rate': 0.23537003735025}\n",
            "[Client 41, round 7] fit, config: {'server_round': 7, 'local_epochs': 5, 'learning_rate': 0.23537003735025}\n",
            "[Client 93, round 7] fit, config: {'server_round': 7, 'local_epochs': 5, 'learning_rate': 0.23537003735025}\n",
            "[Client 29, round 7] fit, config: {'server_round': 7, 'local_epochs': 5, 'learning_rate': 0.23537003735025}\n",
            "[Client 49, round 7] fit, config: {'server_round': 7, 'local_epochs': 5, 'learning_rate': 0.23537003735025}\n",
            "[Client 88, round 7] fit, config: {'server_round': 7, 'local_epochs': 5, 'learning_rate': 0.23537003735025}\n",
            "[Client 8, round 7] fit, config: {'server_round': 7, 'local_epochs': 5, 'learning_rate': 0.23537003735025}\n",
            "[Client 32, round 7] fit, config: {'server_round': 7, 'local_epochs': 5, 'learning_rate': 0.23537003735025}\n",
            "[Client 36, round 7] fit, config: {'server_round': 7, 'local_epochs': 5, 'learning_rate': 0.23537003735025}\n",
            "Epoch 1: train loss 1.970033327738444, accuracy 0.2311111111111111\n",
            "Epoch 1: train loss 1.9097917079925537, accuracy 0.3\n",
            "Epoch 1: train loss 1.9667934709125094, accuracy 0.26222222222222225\n",
            "Epoch 1: train loss 1.8812562889522977, accuracy 0.29555555555555557\n",
            "Epoch 1: train loss 1.9892772171232436, accuracy 0.2644444444444444\n",
            "Epoch 1: train loss 1.97096672323015, accuracy 0.2866666666666667\n",
            "Epoch 1: train loss 1.9733335442013211, accuracy 0.25555555555555554\n",
            "Epoch 1: train loss 1.9157402515411377, accuracy 0.2866666666666667\n",
            "Epoch 1: train loss 1.8992656999164157, accuracy 0.31777777777777777\n",
            "Epoch 1: train loss 2.016123572985331, accuracy 0.24666666666666667\n",
            "Epoch 2: train loss 2.1311828162935047, accuracy 0.26\n",
            "Epoch 2: train loss 2.0458631780412464, accuracy 0.21777777777777776\n",
            "Epoch 2: train loss 1.8847533729341295, accuracy 0.27555555555555555\n",
            "Epoch 2: train loss 1.9632173246807523, accuracy 0.28\n",
            "Epoch 2: train loss 1.9363723463482327, accuracy 0.27555555555555555\n",
            "Epoch 2: train loss 1.9380101760228474, accuracy 0.2688888888888889\n",
            "Epoch 2: train loss 2.0350034369362726, accuracy 0.2288888888888889\n",
            "Epoch 2: train loss 1.9676158958011203, accuracy 0.2911111111111111\n",
            "Epoch 2: train loss 1.9438176552454631, accuracy 0.2688888888888889\n",
            "Epoch 2: train loss 1.9316975408130221, accuracy 0.26222222222222225\n",
            "Epoch 3: train loss 2.0758760372797647, accuracy 0.20444444444444446\n",
            "Epoch 3: train loss 1.9868282079696655, accuracy 0.2822222222222222\n",
            "Epoch 3: train loss 1.9589066637886896, accuracy 0.25555555555555554\n",
            "Epoch 3: train loss 1.898778345849779, accuracy 0.27555555555555555\n",
            "Epoch 3: train loss 2.008598115709093, accuracy 0.28\n",
            "Epoch 3: train loss 1.950094872050815, accuracy 0.2822222222222222\n",
            "Epoch 3: train loss 1.9333890279134114, accuracy 0.28444444444444444\n",
            "Epoch 3: train loss 1.9020770920647516, accuracy 0.30444444444444446\n",
            "Epoch 3: train loss 1.9305470519595676, accuracy 0.28888888888888886\n",
            "Epoch 3: train loss 1.9098080529106989, accuracy 0.2688888888888889\n",
            "Epoch 4: train loss 2.0243411196602716, accuracy 0.2\n",
            "Epoch 4: train loss 1.8675674729877048, accuracy 0.31777777777777777\n",
            "Epoch 4: train loss 1.9847136471006606, accuracy 0.24666666666666667\n",
            "Epoch 4: train loss 1.9680860704845853, accuracy 0.2777777777777778\n",
            "Epoch 4: train loss 1.851707895596822, accuracy 0.29333333333333333\n",
            "Epoch 4: train loss 2.0170141723420887, accuracy 0.23777777777777778\n",
            "Epoch 4: train loss 1.8550535043080647, accuracy 0.31333333333333335\n",
            "Epoch 4: train loss 1.9840908977720473, accuracy 0.24444444444444444\n",
            "Epoch 4: train loss 1.8821921083662245, accuracy 0.30444444444444446\n",
            "Epoch 4: train loss 2.044844243261549, accuracy 0.25555555555555554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:04:06,094 | server.py:229 | fit_round 7 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 2.004818916320801, accuracy 0.21555555555555556\n",
            "Epoch 5: train loss 1.9426931540171306, accuracy 0.2866666666666667\n",
            "Epoch 5: train loss 1.9788047340181139, accuracy 0.25333333333333335\n",
            "Epoch 5: train loss 1.9563140869140625, accuracy 0.27555555555555555\n",
            "Epoch 5: train loss 1.9043625195821126, accuracy 0.32\n",
            "Epoch 5: train loss 1.8261998626920912, accuracy 0.30444444444444446\n",
            "Epoch 5: train loss 1.8448880778418646, accuracy 0.29555555555555557\n",
            "Epoch 5: train loss 1.8901411957210965, accuracy 0.28888888888888886\n",
            "Epoch 5: train loss 1.9638357162475586, accuracy 0.24888888888888888\n",
            "Epoch 5: train loss 2.1218121449152627, accuracy 0.26666666666666666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:04:08,773 | server.py:116 | fit progress: (7, 1.937952494621277, {'accuracy': 0.2845}, 127.97628000000077)\n",
            "INFO flower 2023-01-02 13:04:08,774 | server.py:163 | evaluate_round 7: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:04:08,774 | server.py:215 | fit_round 8: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.937952494621277 / accuracy 0.2845\n",
            "[Client 21, round 8] fit, config: {'server_round': 8, 'local_epochs': 5, 'learning_rate': 0.23301633697674748}\n",
            "[Client 53, round 8] fit, config: {'server_round': 8, 'local_epochs': 5, 'learning_rate': 0.23301633697674748}\n",
            "[Client 45, round 8] fit, config: {'server_round': 8, 'local_epochs': 5, 'learning_rate': 0.23301633697674748}\n",
            "[Client 54, round 8] fit, config: {'server_round': 8, 'local_epochs': 5, 'learning_rate': 0.23301633697674748}\n",
            "[Client 5, round 8] fit, config: {'server_round': 8, 'local_epochs': 5, 'learning_rate': 0.23301633697674748}\n",
            "[Client 1, round 8] fit, config: {'server_round': 8, 'local_epochs': 5, 'learning_rate': 0.23301633697674748}\n",
            "[Client 77, round 8] fit, config: {'server_round': 8, 'local_epochs': 5, 'learning_rate': 0.23301633697674748}\n",
            "[Client 63, round 8] fit, config: {'server_round': 8, 'local_epochs': 5, 'learning_rate': 0.23301633697674748}\n",
            "[Client 86, round 8] fit, config: {'server_round': 8, 'local_epochs': 5, 'learning_rate': 0.23301633697674748}\n",
            "[Client 25, round 8] fit, config: {'server_round': 8, 'local_epochs': 5, 'learning_rate': 0.23301633697674748}\n",
            "Epoch 1: train loss 1.9482671817143757, accuracy 0.25555555555555554\n",
            "Epoch 1: train loss 1.9442777501212225, accuracy 0.28444444444444444\n",
            "Epoch 1: train loss 1.8791816631952922, accuracy 0.29333333333333333\n",
            "Epoch 1: train loss 1.9063524802525837, accuracy 0.25555555555555554\n",
            "Epoch 1: train loss 1.8780789110395644, accuracy 0.30666666666666664\n",
            "Epoch 1: train loss 1.9577475256390042, accuracy 0.2644444444444444\n",
            "Epoch 1: train loss 1.9099990791744657, accuracy 0.2911111111111111\n",
            "Epoch 1: train loss 1.981414556503296, accuracy 0.26222222222222225\n",
            "Epoch 1: train loss 1.891920314894782, accuracy 0.34\n",
            "Epoch 1: train loss 1.9655669662687514, accuracy 0.26666666666666666\n",
            "Epoch 2: train loss 1.9016224543253581, accuracy 0.29333333333333333\n",
            "Epoch 2: train loss 1.9251360760794745, accuracy 0.2688888888888889\n",
            "Epoch 2: train loss 1.9627634684244792, accuracy 0.2733333333333333\n",
            "Epoch 2: train loss 1.8999269538455539, accuracy 0.29777777777777775\n",
            "Epoch 2: train loss 1.9078753921720717, accuracy 0.3022222222222222\n",
            "Epoch 2: train loss 1.9489676422542996, accuracy 0.29333333333333333\n",
            "Epoch 2: train loss 1.9126882553100586, accuracy 0.2866666666666667\n",
            "Epoch 2: train loss 1.916538291507297, accuracy 0.28888888888888886\n",
            "Epoch 2: train loss 1.9229622152116563, accuracy 0.27111111111111114\n",
            "Epoch 2: train loss 1.9040346807903714, accuracy 0.2644444444444444\n",
            "Epoch 3: train loss 1.880862169795566, accuracy 0.3022222222222222\n",
            "Epoch 3: train loss 1.8808078368504841, accuracy 0.34\n",
            "Epoch 3: train loss 1.9130501217312283, accuracy 0.24888888888888888\n",
            "Epoch 3: train loss 1.8406226767434015, accuracy 0.36444444444444446\n",
            "Epoch 3: train loss 1.8500064214070637, accuracy 0.31777777777777777\n",
            "Epoch 3: train loss 1.9013940890630086, accuracy 0.3\n",
            "Epoch 3: train loss 1.9024771716859605, accuracy 0.2911111111111111\n",
            "Epoch 3: train loss 1.9047461615668402, accuracy 0.27555555555555555\n",
            "Epoch 3: train loss 1.863046367963155, accuracy 0.2866666666666667\n",
            "Epoch 3: train loss 1.84752090771993, accuracy 0.29555555555555557\n",
            "Epoch 4: train loss 1.8407755957709417, accuracy 0.33555555555555555\n",
            "Epoch 4: train loss 1.8338670995500352, accuracy 0.3244444444444444\n",
            "Epoch 4: train loss 1.8972368372811212, accuracy 0.3022222222222222\n",
            "Epoch 4: train loss 1.9416618744532268, accuracy 0.2911111111111111\n",
            "Epoch 4: train loss 1.9078098800447252, accuracy 0.2911111111111111\n",
            "Epoch 4: train loss 1.8882103231218126, accuracy 0.28444444444444444\n",
            "Epoch 4: train loss 1.9450929429796007, accuracy 0.2733333333333333\n",
            "Epoch 4: train loss 1.8514018323686388, accuracy 0.34444444444444444\n",
            "Epoch 4: train loss 1.9097719722323947, accuracy 0.2911111111111111\n",
            "Epoch 4: train loss 1.9488703807195027, accuracy 0.2644444444444444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:04:23,987 | server.py:229 | fit_round 8 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.8569852908452351, accuracy 0.29333333333333333\n",
            "Epoch 5: train loss 1.8679549164242215, accuracy 0.3244444444444444\n",
            "Epoch 5: train loss 1.9097132550345526, accuracy 0.27111111111111114\n",
            "Epoch 5: train loss 1.8092676401138306, accuracy 0.3377777777777778\n",
            "Epoch 5: train loss 1.854982402589586, accuracy 0.3288888888888889\n",
            "Epoch 5: train loss 1.875347720252143, accuracy 0.30444444444444446\n",
            "Epoch 5: train loss 1.8697546852959528, accuracy 0.3111111111111111\n",
            "Epoch 5: train loss 1.9215518765979342, accuracy 0.3\n",
            "Epoch 5: train loss 1.8350060648388333, accuracy 0.29777777777777775\n",
            "Epoch 5: train loss 1.9312836064232721, accuracy 0.26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:04:26,934 | server.py:116 | fit progress: (8, 1.7613398510217666, {'accuracy': 0.3668}, 146.13779058599903)\n",
            "INFO flower 2023-01-02 13:04:26,935 | server.py:163 | evaluate_round 8: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:04:26,936 | server.py:215 | fit_round 9: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.7613398510217666 / accuracy 0.3668\n",
            "[Client 34, round 9] fit, config: {'server_round': 9, 'local_epochs': 5, 'learning_rate': 0.23068617360698002}\n",
            "[Client 5, round 9] fit, config: {'server_round': 9, 'local_epochs': 5, 'learning_rate': 0.23068617360698002}\n",
            "[Client 67, round 9] fit, config: {'server_round': 9, 'local_epochs': 5, 'learning_rate': 0.23068617360698002}\n",
            "[Client 21, round 9] fit, config: {'server_round': 9, 'local_epochs': 5, 'learning_rate': 0.23068617360698002}\n",
            "[Client 97, round 9] fit, config: {'server_round': 9, 'local_epochs': 5, 'learning_rate': 0.23068617360698002}\n",
            "[Client 94, round 9] fit, config: {'server_round': 9, 'local_epochs': 5, 'learning_rate': 0.23068617360698002}\n",
            "[Client 24, round 9] fit, config: {'server_round': 9, 'local_epochs': 5, 'learning_rate': 0.23068617360698002}\n",
            "[Client 38, round 9] fit, config: {'server_round': 9, 'local_epochs': 5, 'learning_rate': 0.23068617360698002}\n",
            "[Client 63, round 9] fit, config: {'server_round': 9, 'local_epochs': 5, 'learning_rate': 0.23068617360698002}\n",
            "[Client 59, round 9] fit, config: {'server_round': 9, 'local_epochs': 5, 'learning_rate': 0.23068617360698002}\n",
            "Epoch 1: train loss 1.8914684057235718, accuracy 0.31555555555555553\n",
            "Epoch 1: train loss 1.8885131809446547, accuracy 0.3111111111111111\n",
            "Epoch 1: train loss 1.9193061192830403, accuracy 0.2777777777777778\n",
            "Epoch 1: train loss 1.8556036551793416, accuracy 0.3022222222222222\n",
            "Epoch 1: train loss 1.8666382498211331, accuracy 0.2866666666666667\n",
            "Epoch 1: train loss 1.9061901172002156, accuracy 0.31333333333333335\n",
            "Epoch 1: train loss 1.9068401522106595, accuracy 0.32222222222222224\n",
            "Epoch 1: train loss 1.8093090852101643, accuracy 0.3022222222222222\n",
            "Epoch 1: train loss 1.847883900006612, accuracy 0.3088888888888889\n",
            "Epoch 1: train loss 1.9110920561684503, accuracy 0.28444444444444444\n",
            "Epoch 2: train loss 1.8765961329142253, accuracy 0.3\n",
            "Epoch 2: train loss 1.9175972673628066, accuracy 0.29777777777777775\n",
            "Epoch 2: train loss 1.9151855972078111, accuracy 0.30666666666666664\n",
            "Epoch 2: train loss 1.854250775443183, accuracy 0.32666666666666666\n",
            "Epoch 2: train loss 1.9080813593334622, accuracy 0.3\n",
            "Epoch 2: train loss 1.8239383432600234, accuracy 0.3288888888888889\n",
            "Epoch 2: train loss 1.8845770756403606, accuracy 0.3\n",
            "Epoch 2: train loss 1.8603063689337835, accuracy 0.31555555555555553\n",
            "Epoch 2: train loss 1.8570457696914673, accuracy 0.31555555555555553\n",
            "Epoch 2: train loss 1.9220157729254828, accuracy 0.31555555555555553\n",
            "Epoch 3: train loss 1.8376867373784382, accuracy 0.31333333333333335\n",
            "Epoch 3: train loss 1.9230717288123236, accuracy 0.2911111111111111\n",
            "Epoch 3: train loss 1.7816786898507013, accuracy 0.33111111111111113\n",
            "Epoch 3: train loss 1.8157056305143568, accuracy 0.33555555555555555\n",
            "Epoch 3: train loss 1.8749799860848322, accuracy 0.3\n",
            "Epoch 3: train loss 1.920183195008172, accuracy 0.31333333333333335\n",
            "Epoch 3: train loss 1.8024985922707453, accuracy 0.3511111111111111\n",
            "Epoch 3: train loss 1.873367773161994, accuracy 0.31333333333333335\n",
            "Epoch 3: train loss 1.860947158601549, accuracy 0.2688888888888889\n",
            "Epoch 3: train loss 1.832709444893731, accuracy 0.3088888888888889\n",
            "Epoch 4: train loss 1.7561815579732258, accuracy 0.3422222222222222\n",
            "Epoch 4: train loss 1.8373201025856867, accuracy 0.29777777777777775\n",
            "Epoch 4: train loss 1.8008053965038724, accuracy 0.3111111111111111\n",
            "Epoch 4: train loss 1.8431847757763333, accuracy 0.3377777777777778\n",
            "Epoch 4: train loss 1.7941842211617365, accuracy 0.3622222222222222\n",
            "Epoch 4: train loss 1.9535776774088542, accuracy 0.2777777777777778\n",
            "Epoch 4: train loss 1.7919777234395344, accuracy 0.32\n",
            "Epoch 4: train loss 1.8944914870791965, accuracy 0.3111111111111111\n",
            "Epoch 4: train loss 1.9107354084650676, accuracy 0.3022222222222222\n",
            "Epoch 4: train loss 1.8554732004801433, accuracy 0.28444444444444444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:04:42,602 | server.py:229 | fit_round 9 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.8369522492090862, accuracy 0.28888888888888886\n",
            "Epoch 5: train loss 1.7675188382466633, accuracy 0.3511111111111111\n",
            "Epoch 5: train loss 1.8006599479251437, accuracy 0.33555555555555555\n",
            "Epoch 5: train loss 1.7830366028679743, accuracy 0.31333333333333335\n",
            "Epoch 5: train loss 1.8737682501475017, accuracy 0.2822222222222222\n",
            "Epoch 5: train loss 1.8799626959694757, accuracy 0.3088888888888889\n",
            "Epoch 5: train loss 1.8372332519955106, accuracy 0.3088888888888889\n",
            "Epoch 5: train loss 1.8328964842690363, accuracy 0.30666666666666664\n",
            "Epoch 5: train loss 1.868816958533393, accuracy 0.27555555555555555\n",
            "Epoch 5: train loss 1.859777569770813, accuracy 0.3333333333333333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:04:45,333 | server.py:116 | fit progress: (9, 1.7244032686948776, {'accuracy': 0.3858}, 164.53593137700045)\n",
            "INFO flower 2023-01-02 13:04:45,333 | server.py:163 | evaluate_round 9: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:04:45,333 | server.py:215 | fit_round 10: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.7244032686948776 / accuracy 0.3858\n",
            "[Client 36, round 10] fit, config: {'server_round': 10, 'local_epochs': 5, 'learning_rate': 0.2283793118709102}\n",
            "[Client 28, round 10] fit, config: {'server_round': 10, 'local_epochs': 5, 'learning_rate': 0.2283793118709102}\n",
            "[Client 67, round 10] fit, config: {'server_round': 10, 'local_epochs': 5, 'learning_rate': 0.2283793118709102}\n",
            "[Client 11, round 10] fit, config: {'server_round': 10, 'local_epochs': 5, 'learning_rate': 0.2283793118709102}\n",
            "[Client 13, round 10] fit, config: {'server_round': 10, 'local_epochs': 5, 'learning_rate': 0.2283793118709102}\n",
            "[Client 56, round 10] fit, config: {'server_round': 10, 'local_epochs': 5, 'learning_rate': 0.2283793118709102}\n",
            "[Client 69, round 10] fit, config: {'server_round': 10, 'local_epochs': 5, 'learning_rate': 0.2283793118709102}\n",
            "[Client 78, round 10] fit, config: {'server_round': 10, 'local_epochs': 5, 'learning_rate': 0.2283793118709102}\n",
            "[Client 71, round 10] fit, config: {'server_round': 10, 'local_epochs': 5, 'learning_rate': 0.2283793118709102}\n",
            "[Client 35, round 10] fit, config: {'server_round': 10, 'local_epochs': 5, 'learning_rate': 0.2283793118709102}\n",
            "Epoch 1: train loss 1.9132222334543865, accuracy 0.32222222222222224\n",
            "Epoch 1: train loss 1.8843688037660387, accuracy 0.28888888888888886\n",
            "Epoch 1: train loss 1.8163421418931749, accuracy 0.3\n",
            "Epoch 1: train loss 1.8357764614952936, accuracy 0.31555555555555553\n",
            "Epoch 1: train loss 1.8116157982084486, accuracy 0.33555555555555555\n",
            "Epoch 1: train loss 1.8820842769410875, accuracy 0.3\n",
            "Epoch 1: train loss 1.799154904153612, accuracy 0.3488888888888889\n",
            "Epoch 1: train loss 1.8015410370296903, accuracy 0.3333333333333333\n",
            "Epoch 1: train loss 1.8608728514777289, accuracy 0.32222222222222224\n",
            "Epoch 1: train loss 1.7324171198738947, accuracy 0.31333333333333335\n",
            "Epoch 2: train loss 1.8202947510613336, accuracy 0.3022222222222222\n",
            "Epoch 2: train loss 1.896705945332845, accuracy 0.3244444444444444\n",
            "Epoch 2: train loss 1.8282764885160658, accuracy 0.3022222222222222\n",
            "Epoch 2: train loss 1.857876592212253, accuracy 0.29777777777777775\n",
            "Epoch 2: train loss 1.8211952315436468, accuracy 0.3488888888888889\n",
            "Epoch 2: train loss 1.8883622619840834, accuracy 0.30666666666666664\n",
            "Epoch 2: train loss 1.7879647413889568, accuracy 0.34444444444444444\n",
            "Epoch 2: train loss 1.7582423157162137, accuracy 0.38222222222222224\n",
            "Epoch 2: train loss 1.873728182580736, accuracy 0.29777777777777775\n",
            "Epoch 2: train loss 1.7966756688223944, accuracy 0.3022222222222222\n",
            "Epoch 3: train loss 1.8098795016606648, accuracy 0.3088888888888889\n",
            "Epoch 3: train loss 1.7273722622129652, accuracy 0.3488888888888889\n",
            "Epoch 3: train loss 1.8683449162377253, accuracy 0.32\n",
            "Epoch 3: train loss 1.845797273847792, accuracy 0.3333333333333333\n",
            "Epoch 3: train loss 1.7963403065999348, accuracy 0.3333333333333333\n",
            "Epoch 3: train loss 1.7878781689537897, accuracy 0.3466666666666667\n",
            "Epoch 3: train loss 1.7090900871488783, accuracy 0.4088888888888889\n",
            "Epoch 3: train loss 1.8285709354612563, accuracy 0.3622222222222222\n",
            "Epoch 3: train loss 1.8517106241650052, accuracy 0.3022222222222222\n",
            "Epoch 3: train loss 1.729713625378079, accuracy 0.3333333333333333\n",
            "Epoch 4: train loss 1.8387895954979792, accuracy 0.33111111111111113\n",
            "Epoch 4: train loss 1.8056739171346028, accuracy 0.3377777777777778\n",
            "Epoch 4: train loss 1.8159895075692072, accuracy 0.34\n",
            "Epoch 4: train loss 1.8429023557239108, accuracy 0.31333333333333335\n",
            "Epoch 4: train loss 1.8478696081373427, accuracy 0.3\n",
            "Epoch 4: train loss 1.7524251408047147, accuracy 0.33555555555555555\n",
            "Epoch 4: train loss 1.8240613142649333, accuracy 0.3288888888888889\n",
            "Epoch 4: train loss 1.8370498286353216, accuracy 0.3333333333333333\n",
            "Epoch 4: train loss 1.7721132569842868, accuracy 0.34444444444444444\n",
            "Epoch 4: train loss 1.8406395117441814, accuracy 0.34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:05:01,253 | server.py:229 | fit_round 10 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.7920867337120905, accuracy 0.3288888888888889\n",
            "Epoch 5: train loss 1.7783124844233196, accuracy 0.3\n",
            "Epoch 5: train loss 1.8307017352845933, accuracy 0.31333333333333335\n",
            "Epoch 5: train loss 1.9792773458692763, accuracy 0.3022222222222222\n",
            "Epoch 5: train loss 1.8775777551862929, accuracy 0.32\n",
            "Epoch 5: train loss 1.830125583542718, accuracy 0.32\n",
            "Epoch 5: train loss 1.9410122897889879, accuracy 0.3333333333333333\n",
            "Epoch 5: train loss 1.7596766551335652, accuracy 0.36\n",
            "Epoch 5: train loss 1.7241020335091486, accuracy 0.32666666666666666\n",
            "Epoch 5: train loss 1.8323746124903362, accuracy 0.30444444444444446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:05:05,231 | server.py:116 | fit progress: (10, 1.7422066110372543, {'accuracy': 0.3839}, 184.4346613859998)\n",
            "INFO flower 2023-01-02 13:05:05,232 | server.py:163 | evaluate_round 10: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:05:05,233 | server.py:215 | fit_round 11: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.7422066110372543 / accuracy 0.3839\n",
            "[Client 24, round 11] fit, config: {'server_round': 11, 'local_epochs': 5, 'learning_rate': 0.2260955187522011}\n",
            "[Client 66, round 11] fit, config: {'server_round': 11, 'local_epochs': 5, 'learning_rate': 0.2260955187522011}\n",
            "[Client 8, round 11] fit, config: {'server_round': 11, 'local_epochs': 5, 'learning_rate': 0.2260955187522011}\n",
            "[Client 81, round 11] fit, config: {'server_round': 11, 'local_epochs': 5, 'learning_rate': 0.2260955187522011}\n",
            "[Client 50, round 11] fit, config: {'server_round': 11, 'local_epochs': 5, 'learning_rate': 0.2260955187522011}\n",
            "[Client 57, round 11] fit, config: {'server_round': 11, 'local_epochs': 5, 'learning_rate': 0.2260955187522011}\n",
            "[Client 52, round 11] fit, config: {'server_round': 11, 'local_epochs': 5, 'learning_rate': 0.2260955187522011}\n",
            "[Client 14, round 11] fit, config: {'server_round': 11, 'local_epochs': 5, 'learning_rate': 0.2260955187522011}\n",
            "[Client 7, round 11] fit, config: {'server_round': 11, 'local_epochs': 5, 'learning_rate': 0.2260955187522011}\n",
            "[Client 72, round 11] fit, config: {'server_round': 11, 'local_epochs': 5, 'learning_rate': 0.2260955187522011}\n",
            "Epoch 1: train loss 1.7834224303563435, accuracy 0.3244444444444444\n",
            "Epoch 1: train loss 1.7887101040946112, accuracy 0.3688888888888889\n",
            "Epoch 1: train loss 1.8354507949617174, accuracy 0.3422222222222222\n",
            "Epoch 1: train loss 1.788189238972134, accuracy 0.32\n",
            "Epoch 1: train loss 1.771428147951762, accuracy 0.3622222222222222\n",
            "Epoch 1: train loss 1.8123487366570368, accuracy 0.31777777777777777\n",
            "Epoch 1: train loss 1.8437940279642742, accuracy 0.3466666666666667\n",
            "Epoch 1: train loss 1.7754725615183513, accuracy 0.34\n",
            "Epoch 1: train loss 1.8546395036909316, accuracy 0.29777777777777775\n",
            "Epoch 1: train loss 1.806617922253079, accuracy 0.32222222222222224\n",
            "Epoch 2: train loss 1.8848819202846951, accuracy 0.29555555555555557\n",
            "Epoch 2: train loss 1.7627172735002306, accuracy 0.35777777777777775\n",
            "Epoch 2: train loss 1.8652382691701253, accuracy 0.3422222222222222\n",
            "Epoch 2: train loss 1.7601397302415636, accuracy 0.3688888888888889\n",
            "Epoch 2: train loss 1.7859067387051053, accuracy 0.32666666666666666\n",
            "Epoch 2: train loss 1.8723738855785794, accuracy 0.31333333333333335\n",
            "Epoch 2: train loss 1.7711963653564453, accuracy 0.32\n",
            "Epoch 2: train loss 1.8636041349834866, accuracy 0.31333333333333335\n",
            "Epoch 2: train loss 1.784824185901218, accuracy 0.3288888888888889\n",
            "Epoch 2: train loss 1.8192079464594524, accuracy 0.3466666666666667\n",
            "Epoch 3: train loss 1.796813474761115, accuracy 0.34\n",
            "Epoch 3: train loss 1.6715001000298395, accuracy 0.3844444444444444\n",
            "Epoch 3: train loss 1.7188695536719427, accuracy 0.3711111111111111\n",
            "Epoch 3: train loss 1.851987706290351, accuracy 0.3\n",
            "Epoch 3: train loss 1.8135339551501803, accuracy 0.3\n",
            "Epoch 3: train loss 1.796368334028456, accuracy 0.3466666666666667\n",
            "Epoch 3: train loss 1.8146960867775812, accuracy 0.31777777777777777\n",
            "Epoch 3: train loss 1.9122277630700006, accuracy 0.29333333333333333\n",
            "Epoch 3: train loss 1.802098102039761, accuracy 0.3422222222222222\n",
            "Epoch 3: train loss 1.8226801819271512, accuracy 0.3422222222222222\n",
            "Epoch 4: train loss 1.7345738808314006, accuracy 0.3688888888888889\n",
            "Epoch 4: train loss 1.8235590193006728, accuracy 0.3111111111111111\n",
            "Epoch 4: train loss 1.8237279256184895, accuracy 0.3333333333333333\n",
            "Epoch 4: train loss 1.7784539196226332, accuracy 0.3244444444444444\n",
            "Epoch 4: train loss 1.760280476676093, accuracy 0.30444444444444446\n",
            "Epoch 4: train loss 1.8228902551862929, accuracy 0.31777777777777777\n",
            "Epoch 4: train loss 1.9108201795154147, accuracy 0.31333333333333335\n",
            "Epoch 4: train loss 1.860260354148017, accuracy 0.34\n",
            "Epoch 4: train loss 1.8606140348646376, accuracy 0.36\n",
            "Epoch 4: train loss 1.8004663123024836, accuracy 0.3288888888888889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:05:21,057 | server.py:229 | fit_round 11 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.7812872992621527, accuracy 0.35333333333333333\n",
            "Epoch 5: train loss 1.9711047278510199, accuracy 0.28444444444444444\n",
            "Epoch 5: train loss 1.8705029487609863, accuracy 0.33111111111111113\n",
            "Epoch 5: train loss 1.6601985957887437, accuracy 0.37777777777777777\n",
            "Epoch 5: train loss 1.8709504869249132, accuracy 0.3288888888888889\n",
            "Epoch 5: train loss 1.8233567343817816, accuracy 0.32\n",
            "Epoch 5: train loss 1.7714420557022095, accuracy 0.3488888888888889\n",
            "Epoch 5: train loss 1.7506601413091023, accuracy 0.36666666666666664\n",
            "Epoch 5: train loss 1.7464434040917292, accuracy 0.3488888888888889\n",
            "Epoch 5: train loss 1.8381249772177801, accuracy 0.28888888888888886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:05:23,840 | server.py:116 | fit progress: (11, 1.696931614279747, {'accuracy': 0.3896}, 203.04335266899943)\n",
            "INFO flower 2023-01-02 13:05:23,841 | server.py:163 | evaluate_round 11: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:05:23,842 | server.py:215 | fit_round 12: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.696931614279747 / accuracy 0.3896\n",
            "[Client 55, round 12] fit, config: {'server_round': 12, 'local_epochs': 5, 'learning_rate': 0.2238345635646791}\n",
            "[Client 97, round 12] fit, config: {'server_round': 12, 'local_epochs': 5, 'learning_rate': 0.2238345635646791}\n",
            "[Client 83, round 12] fit, config: {'server_round': 12, 'local_epochs': 5, 'learning_rate': 0.2238345635646791}\n",
            "[Client 66, round 12] fit, config: {'server_round': 12, 'local_epochs': 5, 'learning_rate': 0.2238345635646791}\n",
            "[Client 45, round 12] fit, config: {'server_round': 12, 'local_epochs': 5, 'learning_rate': 0.2238345635646791}\n",
            "[Client 63, round 12] fit, config: {'server_round': 12, 'local_epochs': 5, 'learning_rate': 0.2238345635646791}\n",
            "[Client 17, round 12] fit, config: {'server_round': 12, 'local_epochs': 5, 'learning_rate': 0.2238345635646791}\n",
            "[Client 19, round 12] fit, config: {'server_round': 12, 'local_epochs': 5, 'learning_rate': 0.2238345635646791}\n",
            "[Client 24, round 12] fit, config: {'server_round': 12, 'local_epochs': 5, 'learning_rate': 0.2238345635646791}\n",
            "[Client 27, round 12] fit, config: {'server_round': 12, 'local_epochs': 5, 'learning_rate': 0.2238345635646791}\n",
            "Epoch 1: train loss 1.8222335974375408, accuracy 0.3022222222222222\n",
            "Epoch 1: train loss 1.7961544858084784, accuracy 0.28\n",
            "Epoch 1: train loss 1.8181142674552069, accuracy 0.31333333333333335\n",
            "Epoch 1: train loss 1.7908525069554646, accuracy 0.31777777777777777\n",
            "Epoch 1: train loss 1.69056416882409, accuracy 0.38\n",
            "Epoch 1: train loss 1.723967605166965, accuracy 0.36\n",
            "Epoch 1: train loss 1.782454596625434, accuracy 0.34\n",
            "Epoch 1: train loss 1.8128792974683974, accuracy 0.3244444444444444\n",
            "Epoch 1: train loss 1.8081374830669827, accuracy 0.3466666666666667\n",
            "Epoch 1: train loss 1.8558031055662367, accuracy 0.3088888888888889\n",
            "Epoch 2: train loss 1.7509575817320082, accuracy 0.31555555555555553\n",
            "Epoch 2: train loss 1.6900115013122559, accuracy 0.3466666666666667\n",
            "Epoch 2: train loss 1.7119673887888591, accuracy 0.36\n",
            "Epoch 2: train loss 1.8118579652574327, accuracy 0.3111111111111111\n",
            "Epoch 2: train loss 1.7477178970972698, accuracy 0.32222222222222224\n",
            "Epoch 2: train loss 1.7945023377736409, accuracy 0.3511111111111111\n",
            "Epoch 2: train loss 1.8362728622224596, accuracy 0.32222222222222224\n",
            "Epoch 2: train loss 1.8050780693689983, accuracy 0.35333333333333333\n",
            "Epoch 2: train loss 1.803444226582845, accuracy 0.31333333333333335\n",
            "Epoch 2: train loss 1.83203125, accuracy 0.3\n",
            "Epoch 3: train loss 1.812490118874444, accuracy 0.3111111111111111\n",
            "Epoch 3: train loss 1.7085755003823175, accuracy 0.32222222222222224\n",
            "Epoch 3: train loss 2.031106154123942, accuracy 0.29777777777777775\n",
            "Epoch 3: train loss 1.7627381218804254, accuracy 0.3377777777777778\n",
            "Epoch 3: train loss 1.7219176954693265, accuracy 0.36\n",
            "Epoch 3: train loss 1.7828069130579631, accuracy 0.3244444444444444\n",
            "Epoch 3: train loss 1.763273662990994, accuracy 0.31555555555555553\n",
            "Epoch 3: train loss 1.7791260083516438, accuracy 0.3422222222222222\n",
            "Epoch 3: train loss 1.7943514453040228, accuracy 0.3288888888888889\n",
            "Epoch 3: train loss 1.7636446820365057, accuracy 0.31333333333333335\n",
            "Epoch 4: train loss 1.800154407819112, accuracy 0.32666666666666666\n",
            "Epoch 4: train loss 1.9505258666144476, accuracy 0.3\n",
            "Epoch 4: train loss 1.8419671456019084, accuracy 0.33555555555555555\n",
            "Epoch 4: train loss 1.753583312034607, accuracy 0.3622222222222222\n",
            "Epoch 4: train loss 1.7005386352539062, accuracy 0.4066666666666667\n",
            "Epoch 4: train loss 1.6603209575017293, accuracy 0.3933333333333333\n",
            "Epoch 4: train loss 1.7893122302161322, accuracy 0.3422222222222222\n",
            "Epoch 4: train loss 1.7298425568474665, accuracy 0.32666666666666666\n",
            "Epoch 4: train loss 1.7233494652642145, accuracy 0.3688888888888889\n",
            "Epoch 4: train loss 1.7558586067623563, accuracy 0.34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:05:39,613 | server.py:229 | fit_round 12 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.7308188676834106, accuracy 0.3422222222222222\n",
            "Epoch 5: train loss 1.7093607981999714, accuracy 0.36666666666666664\n",
            "Epoch 5: train loss 1.744027230474684, accuracy 0.38\n",
            "Epoch 5: train loss 1.7664960092968411, accuracy 0.33555555555555555\n",
            "Epoch 5: train loss 1.7427482340070937, accuracy 0.32666666666666666\n",
            "Epoch 5: train loss 1.812027374903361, accuracy 0.32\n",
            "Epoch 5: train loss 1.7292601532406278, accuracy 0.3711111111111111\n",
            "Epoch 5: train loss 1.713108155462477, accuracy 0.3466666666666667\n",
            "Epoch 5: train loss 1.7066060702006023, accuracy 0.35555555555555557\n",
            "Epoch 5: train loss 1.720226486523946, accuracy 0.3466666666666667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:05:42,161 | server.py:116 | fit progress: (12, 1.6355706119537354, {'accuracy': 0.4121}, 221.3640436980004)\n",
            "INFO flower 2023-01-02 13:05:42,161 | server.py:163 | evaluate_round 12: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:05:42,162 | server.py:215 | fit_round 13: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.6355706119537354 / accuracy 0.4121\n",
            "[Client 30, round 13] fit, config: {'server_round': 13, 'local_epochs': 5, 'learning_rate': 0.2215962179290323}\n",
            "[Client 4, round 13] fit, config: {'server_round': 13, 'local_epochs': 5, 'learning_rate': 0.2215962179290323}\n",
            "[Client 31, round 13] fit, config: {'server_round': 13, 'local_epochs': 5, 'learning_rate': 0.2215962179290323}\n",
            "[Client 26, round 13] fit, config: {'server_round': 13, 'local_epochs': 5, 'learning_rate': 0.2215962179290323}\n",
            "[Client 9, round 13] fit, config: {'server_round': 13, 'local_epochs': 5, 'learning_rate': 0.2215962179290323}\n",
            "[Client 51, round 13] fit, config: {'server_round': 13, 'local_epochs': 5, 'learning_rate': 0.2215962179290323}\n",
            "[Client 3, round 13] fit, config: {'server_round': 13, 'local_epochs': 5, 'learning_rate': 0.2215962179290323}\n",
            "[Client 1, round 13] fit, config: {'server_round': 13, 'local_epochs': 5, 'learning_rate': 0.2215962179290323}\n",
            "[Client 52, round 13] fit, config: {'server_round': 13, 'local_epochs': 5, 'learning_rate': 0.2215962179290323}\n",
            "[Client 83, round 13] fit, config: {'server_round': 13, 'local_epochs': 5, 'learning_rate': 0.2215962179290323}\n",
            "Epoch 1: train loss 1.7312416500515408, accuracy 0.3466666666666667\n",
            "Epoch 1: train loss 1.7799605131149292, accuracy 0.3466666666666667\n",
            "Epoch 1: train loss 1.7316743665271335, accuracy 0.35555555555555557\n",
            "Epoch 1: train loss 1.7608860731124878, accuracy 0.36444444444444446\n",
            "Epoch 1: train loss 1.7925937970479329, accuracy 0.3288888888888889\n",
            "Epoch 1: train loss 1.7286120653152466, accuracy 0.3377777777777778\n",
            "Epoch 1: train loss 1.7757526371214125, accuracy 0.34444444444444444\n",
            "Epoch 1: train loss 1.7909957832760282, accuracy 0.3466666666666667\n",
            "Epoch 1: train loss 1.76626808113522, accuracy 0.3422222222222222\n",
            "Epoch 1: train loss 1.7034051683213975, accuracy 0.38\n",
            "Epoch 2: train loss 1.8352790011299982, accuracy 0.36444444444444446\n",
            "Epoch 2: train loss 1.7185455295774672, accuracy 0.3377777777777778\n",
            "Epoch 2: train loss 1.7539842393663194, accuracy 0.38\n",
            "Epoch 2: train loss 1.6463992728127375, accuracy 0.39111111111111113\n",
            "Epoch 2: train loss 1.8352514372931585, accuracy 0.35777777777777775\n",
            "Epoch 2: train loss 1.7335922585593329, accuracy 0.3622222222222222\n",
            "Epoch 2: train loss 1.7484808762868245, accuracy 0.35777777777777775\n",
            "Epoch 2: train loss 1.7755897177590265, accuracy 0.37333333333333335\n",
            "Epoch 2: train loss 1.7486429611841838, accuracy 0.3511111111111111\n",
            "Epoch 2: train loss 1.683703859647115, accuracy 0.38222222222222224\n",
            "Epoch 3: train loss 1.6652910974290636, accuracy 0.4066666666666667\n",
            "Epoch 3: train loss 1.8602186308966742, accuracy 0.3466666666666667\n",
            "Epoch 3: train loss 1.6810824473698933, accuracy 0.37777777777777777\n",
            "Epoch 3: train loss 1.7253555059432983, accuracy 0.36666666666666664\n",
            "Epoch 3: train loss 1.682728237575955, accuracy 0.38222222222222224\n",
            "Epoch 3: train loss 1.7141455147001479, accuracy 0.37555555555555553\n",
            "Epoch 3: train loss 1.7232864167955186, accuracy 0.38\n",
            "Epoch 3: train loss 1.7452045414182875, accuracy 0.37555555555555553\n",
            "Epoch 3: train loss 1.780120677418179, accuracy 0.3688888888888889\n",
            "Epoch 3: train loss 1.7428232298956976, accuracy 0.3488888888888889\n",
            "Epoch 4: train loss 1.6936131848229303, accuracy 0.35555555555555557\n",
            "Epoch 4: train loss 1.7988068262736003, accuracy 0.31777777777777777\n",
            "Epoch 4: train loss 1.7512973414527044, accuracy 0.37333333333333335\n",
            "Epoch 4: train loss 1.6995267338222928, accuracy 0.34\n",
            "Epoch 4: train loss 1.7514781289630466, accuracy 0.35333333333333333\n",
            "Epoch 4: train loss 1.6909262074364557, accuracy 0.3711111111111111\n",
            "Epoch 4: train loss 1.7359048657947116, accuracy 0.37333333333333335\n",
            "Epoch 4: train loss 1.6925709777408176, accuracy 0.38666666666666666\n",
            "Epoch 4: train loss 1.7283224794599745, accuracy 0.3511111111111111\n",
            "Epoch 4: train loss 1.7436893516116672, accuracy 0.34444444444444444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:05:55,991 | server.py:229 | fit_round 13 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.6455899344550238, accuracy 0.4022222222222222\n",
            "Epoch 5: train loss 1.8267641067504883, accuracy 0.37333333333333335\n",
            "Epoch 5: train loss 1.7225087351269193, accuracy 0.3844444444444444\n",
            "Epoch 5: train loss 1.6158446073532104, accuracy 0.4022222222222222\n",
            "Epoch 5: train loss 1.75866695245107, accuracy 0.35777777777777775\n",
            "Epoch 5: train loss 1.802494313981798, accuracy 0.3377777777777778\n",
            "Epoch 5: train loss 1.72171065542433, accuracy 0.3933333333333333\n",
            "Epoch 5: train loss 1.6587480041715834, accuracy 0.36444444444444446\n",
            "Epoch 5: train loss 1.6734071969985962, accuracy 0.3488888888888889\n",
            "Epoch 5: train loss 1.6382562981711493, accuracy 0.37555555555555553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:05:58,508 | server.py:116 | fit progress: (13, 1.604927464723587, {'accuracy': 0.4217}, 237.7111636890004)\n",
            "INFO flower 2023-01-02 13:05:58,508 | server.py:163 | evaluate_round 13: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:05:58,509 | server.py:215 | fit_round 14: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.604927464723587 / accuracy 0.4217\n",
            "[Client 41, round 14] fit, config: {'server_round': 14, 'local_epochs': 5, 'learning_rate': 0.21938025574974196}\n",
            "[Client 70, round 14] fit, config: {'server_round': 14, 'local_epochs': 5, 'learning_rate': 0.21938025574974196}\n",
            "[Client 3, round 14] fit, config: {'server_round': 14, 'local_epochs': 5, 'learning_rate': 0.21938025574974196}\n",
            "[Client 5, round 14] fit, config: {'server_round': 14, 'local_epochs': 5, 'learning_rate': 0.21938025574974196}\n",
            "[Client 93, round 14] fit, config: {'server_round': 14, 'local_epochs': 5, 'learning_rate': 0.21938025574974196}\n",
            "[Client 55, round 14] fit, config: {'server_round': 14, 'local_epochs': 5, 'learning_rate': 0.21938025574974196}\n",
            "[Client 31, round 14] fit, config: {'server_round': 14, 'local_epochs': 5, 'learning_rate': 0.21938025574974196}\n",
            "[Client 89, round 14] fit, config: {'server_round': 14, 'local_epochs': 5, 'learning_rate': 0.21938025574974196}\n",
            "[Client 37, round 14] fit, config: {'server_round': 14, 'local_epochs': 5, 'learning_rate': 0.21938025574974196}\n",
            "[Client 23, round 14] fit, config: {'server_round': 14, 'local_epochs': 5, 'learning_rate': 0.21938025574974196}\n",
            "Epoch 1: train loss 1.6272427373462253, accuracy 0.4088888888888889\n",
            "Epoch 1: train loss 1.7739078336291842, accuracy 0.33555555555555555\n",
            "Epoch 1: train loss 1.770787239074707, accuracy 0.3488888888888889\n",
            "Epoch 1: train loss 1.7187097205056086, accuracy 0.38666666666666666\n",
            "Epoch 1: train loss 1.7819878260294597, accuracy 0.3377777777777778\n",
            "Epoch 1: train loss 1.7422816223568387, accuracy 0.3488888888888889\n",
            "Epoch 1: train loss 1.7184791962305705, accuracy 0.3711111111111111\n",
            "Epoch 1: train loss 1.753314773241679, accuracy 0.37555555555555553\n",
            "Epoch 1: train loss 1.7791275448269315, accuracy 0.3488888888888889\n",
            "Epoch 1: train loss 1.7357418934504192, accuracy 0.35333333333333333\n",
            "Epoch 2: train loss 1.759078131781684, accuracy 0.35333333333333333\n",
            "Epoch 2: train loss 1.706782062848409, accuracy 0.35333333333333333\n",
            "Epoch 2: train loss 1.7811613480250041, accuracy 0.37777777777777777\n",
            "Epoch 2: train loss 1.7326826122072008, accuracy 0.36666666666666664\n",
            "Epoch 2: train loss 1.662736005253262, accuracy 0.39111111111111113\n",
            "Epoch 2: train loss 1.7754994365904067, accuracy 0.35777777777777775\n",
            "Epoch 2: train loss 1.7384257713953655, accuracy 0.3711111111111111\n",
            "Epoch 2: train loss 1.8300133678648207, accuracy 0.32666666666666666\n",
            "Epoch 2: train loss 1.6905935737821791, accuracy 0.3977777777777778\n",
            "Epoch 2: train loss 1.697687519921197, accuracy 0.3511111111111111\n",
            "Epoch 3: train loss 1.667068017853631, accuracy 0.3688888888888889\n",
            "Epoch 3: train loss 1.6024943722618952, accuracy 0.42444444444444446\n",
            "Epoch 3: train loss 1.6335581673516169, accuracy 0.3977777777777778\n",
            "Epoch 3: train loss 1.7948260307312012, accuracy 0.3288888888888889\n",
            "Epoch 3: train loss 1.822970257865058, accuracy 0.32\n",
            "Epoch 3: train loss 1.7310210598839655, accuracy 0.3244444444444444\n",
            "Epoch 3: train loss 1.7389545440673828, accuracy 0.36444444444444446\n",
            "Epoch 3: train loss 1.616832309299045, accuracy 0.38666666666666666\n",
            "Epoch 3: train loss 1.674381481276618, accuracy 0.38\n",
            "Epoch 3: train loss 1.7998055087195501, accuracy 0.3466666666666667\n",
            "Epoch 4: train loss 1.7515667147106595, accuracy 0.3688888888888889\n",
            "Epoch 4: train loss 1.5572135580910578, accuracy 0.3888888888888889\n",
            "Epoch 4: train loss 1.6462009880277846, accuracy 0.3977777777777778\n",
            "Epoch 4: train loss 1.744633608394199, accuracy 0.33555555555555555\n",
            "Epoch 4: train loss 1.8028176095750597, accuracy 0.3244444444444444\n",
            "Epoch 4: train loss 1.7454846170213487, accuracy 0.31333333333333335\n",
            "Epoch 4: train loss 1.741871436436971, accuracy 0.35777777777777775\n",
            "Epoch 4: train loss 1.7524482938978407, accuracy 0.35777777777777775\n",
            "Epoch 4: train loss 1.6827916834089491, accuracy 0.35555555555555557\n",
            "Epoch 4: train loss 1.7114800479676988, accuracy 0.36666666666666664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:06:12,781 | server.py:229 | fit_round 14 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.7681614425447252, accuracy 0.3333333333333333\n",
            "Epoch 5: train loss 1.6160165866216023, accuracy 0.39555555555555555\n",
            "Epoch 5: train loss 1.6778192785051134, accuracy 0.3844444444444444\n",
            "Epoch 5: train loss 1.6594780153698392, accuracy 0.36666666666666664\n",
            "Epoch 5: train loss 1.7295196188820734, accuracy 0.3622222222222222\n",
            "Epoch 5: train loss 1.6924526823891535, accuracy 0.36444444444444446\n",
            "Epoch 5: train loss 1.8004126416312323, accuracy 0.3466666666666667\n",
            "Epoch 5: train loss 1.7442264159520466, accuracy 0.3622222222222222\n",
            "Epoch 5: train loss 1.8099117146597967, accuracy 0.31333333333333335\n",
            "Epoch 5: train loss 1.784102029270596, accuracy 0.32222222222222224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:06:16,120 | server.py:116 | fit progress: (14, 1.594452024102211, {'accuracy': 0.4148}, 255.3235854630002)\n",
            "INFO flower 2023-01-02 13:06:16,121 | server.py:163 | evaluate_round 14: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:06:16,121 | server.py:215 | fit_round 15: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.594452024102211 / accuracy 0.4148\n",
            "[Client 38, round 15] fit, config: {'server_round': 15, 'local_epochs': 5, 'learning_rate': 0.21718645319224456}\n",
            "[Client 14, round 15] fit, config: {'server_round': 15, 'local_epochs': 5, 'learning_rate': 0.21718645319224456}\n",
            "[Client 36, round 15] fit, config: {'server_round': 15, 'local_epochs': 5, 'learning_rate': 0.21718645319224456}\n",
            "[Client 85, round 15] fit, config: {'server_round': 15, 'local_epochs': 5, 'learning_rate': 0.21718645319224456}\n",
            "[Client 41, round 15] fit, config: {'server_round': 15, 'local_epochs': 5, 'learning_rate': 0.21718645319224456}\n",
            "[Client 82, round 15] fit, config: {'server_round': 15, 'local_epochs': 5, 'learning_rate': 0.21718645319224456}\n",
            "[Client 27, round 15] fit, config: {'server_round': 15, 'local_epochs': 5, 'learning_rate': 0.21718645319224456}\n",
            "[Client 65, round 15] fit, config: {'server_round': 15, 'local_epochs': 5, 'learning_rate': 0.21718645319224456}\n",
            "[Client 3, round 15] fit, config: {'server_round': 15, 'local_epochs': 5, 'learning_rate': 0.21718645319224456}\n",
            "[Client 95, round 15] fit, config: {'server_round': 15, 'local_epochs': 5, 'learning_rate': 0.21718645319224456}\n",
            "Epoch 1: train loss 1.7331319120195177, accuracy 0.36\n",
            "Epoch 1: train loss 1.6893532938427396, accuracy 0.39555555555555555\n",
            "Epoch 1: train loss 1.7115116251839533, accuracy 0.38222222222222224\n",
            "Epoch 1: train loss 1.7640270392100017, accuracy 0.36\n",
            "Epoch 1: train loss 1.7475759718153212, accuracy 0.3622222222222222\n",
            "Epoch 1: train loss 1.5834888749652438, accuracy 0.4266666666666667\n",
            "Epoch 1: train loss 1.6972080734041002, accuracy 0.37333333333333335\n",
            "Epoch 1: train loss 1.7784810198677912, accuracy 0.35333333333333333\n",
            "Epoch 1: train loss 1.7274654044045343, accuracy 0.37777777777777777\n",
            "Epoch 1: train loss 1.766927891307407, accuracy 0.3888888888888889\n",
            "Epoch 2: train loss 1.7267738050884671, accuracy 0.36\n",
            "Epoch 2: train loss 1.719046605957879, accuracy 0.39555555555555555\n",
            "Epoch 2: train loss 1.6921190023422241, accuracy 0.39111111111111113\n",
            "Epoch 2: train loss 1.8828541305330064, accuracy 0.31555555555555553\n",
            "Epoch 2: train loss 1.6663926839828491, accuracy 0.37777777777777777\n",
            "Epoch 2: train loss 1.7434173027674358, accuracy 0.3466666666666667\n",
            "Epoch 2: train loss 1.7222486072116427, accuracy 0.36444444444444446\n",
            "Epoch 2: train loss 1.6861216359668307, accuracy 0.38222222222222224\n",
            "Epoch 2: train loss 1.604030688603719, accuracy 0.40444444444444444\n",
            "Epoch 2: train loss 1.6604019006093342, accuracy 0.37555555555555553\n",
            "Epoch 3: train loss 1.6689441071616278, accuracy 0.37777777777777777\n",
            "Epoch 3: train loss 1.7636774778366089, accuracy 0.34444444444444444\n",
            "Epoch 3: train loss 1.7091403537326388, accuracy 0.35333333333333333\n",
            "Epoch 3: train loss 1.6883639891942341, accuracy 0.35333333333333333\n",
            "Epoch 3: train loss 1.7780623303519354, accuracy 0.36444444444444446\n",
            "Epoch 3: train loss 1.7100293636322021, accuracy 0.3511111111111111\n",
            "Epoch 3: train loss 1.7471452818976507, accuracy 0.3688888888888889\n",
            "Epoch 3: train loss 1.7113433016671076, accuracy 0.3711111111111111\n",
            "Epoch 3: train loss 1.6993158525890775, accuracy 0.39555555555555555\n",
            "Epoch 3: train loss 1.6642129553688898, accuracy 0.37777777777777777\n",
            "Epoch 4: train loss 1.6504912376403809, accuracy 0.3711111111111111\n",
            "Epoch 4: train loss 1.7021889289220173, accuracy 0.37777777777777777\n",
            "Epoch 4: train loss 1.6130393346150715, accuracy 0.42\n",
            "Epoch 4: train loss 1.6442331340577867, accuracy 0.3977777777777778\n",
            "Epoch 4: train loss 1.6847828494177923, accuracy 0.36444444444444446\n",
            "Epoch 4: train loss 1.7084288332197402, accuracy 0.38666666666666666\n",
            "Epoch 4: train loss 1.6394720209969416, accuracy 0.40444444444444444\n",
            "Epoch 4: train loss 1.7594127787484064, accuracy 0.38\n",
            "Epoch 4: train loss 1.698438737127516, accuracy 0.38222222222222224\n",
            "Epoch 4: train loss 1.5918366379208035, accuracy 0.42444444444444446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:06:32,439 | server.py:229 | fit_round 15 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.6179063717524211, accuracy 0.4066666666666667\n",
            "Epoch 5: train loss 1.6733371946546767, accuracy 0.3844444444444444\n",
            "Epoch 5: train loss 1.665958907869127, accuracy 0.3888888888888889\n",
            "Epoch 5: train loss 1.7041857242584229, accuracy 0.40444444444444444\n",
            "Epoch 5: train loss 1.6842546727922227, accuracy 0.3688888888888889\n",
            "Epoch 5: train loss 1.6976583931181166, accuracy 0.3933333333333333\n",
            "Epoch 5: train loss 1.6321955256991916, accuracy 0.3844444444444444\n",
            "Epoch 5: train loss 1.6318930917316012, accuracy 0.39555555555555555\n",
            "Epoch 5: train loss 1.830537690056695, accuracy 0.33111111111111113\n",
            "Epoch 5: train loss 1.5433382325702243, accuracy 0.4666666666666667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:06:35,141 | server.py:116 | fit progress: (15, 1.5789094483852386, {'accuracy': 0.4274}, 274.3444487800007)\n",
            "INFO flower 2023-01-02 13:06:35,142 | server.py:163 | evaluate_round 15: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:06:35,142 | server.py:215 | fit_round 16: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.5789094483852386 / accuracy 0.4274\n",
            "[Client 46, round 16] fit, config: {'server_round': 16, 'local_epochs': 5, 'learning_rate': 0.2150145886603221}\n",
            "[Client 19, round 16] fit, config: {'server_round': 16, 'local_epochs': 5, 'learning_rate': 0.2150145886603221}\n",
            "[Client 59, round 16] fit, config: {'server_round': 16, 'local_epochs': 5, 'learning_rate': 0.2150145886603221}\n",
            "[Client 28, round 16] fit, config: {'server_round': 16, 'local_epochs': 5, 'learning_rate': 0.2150145886603221}\n",
            "[Client 65, round 16] fit, config: {'server_round': 16, 'local_epochs': 5, 'learning_rate': 0.2150145886603221}\n",
            "[Client 84, round 16] fit, config: {'server_round': 16, 'local_epochs': 5, 'learning_rate': 0.2150145886603221}\n",
            "[Client 53, round 16] fit, config: {'server_round': 16, 'local_epochs': 5, 'learning_rate': 0.2150145886603221}\n",
            "[Client 55, round 16] fit, config: {'server_round': 16, 'local_epochs': 5, 'learning_rate': 0.2150145886603221}\n",
            "[Client 50, round 16] fit, config: {'server_round': 16, 'local_epochs': 5, 'learning_rate': 0.2150145886603221}\n",
            "[Client 71, round 16] fit, config: {'server_round': 16, 'local_epochs': 5, 'learning_rate': 0.2150145886603221}\n",
            "Epoch 1: train loss 1.6716162893507216, accuracy 0.38222222222222224\n",
            "Epoch 1: train loss 1.7154144446055095, accuracy 0.35555555555555557\n",
            "Epoch 1: train loss 1.7325065268410578, accuracy 0.36\n",
            "Epoch 1: train loss 1.704596824116177, accuracy 0.37777777777777777\n",
            "Epoch 1: train loss 1.677990158398946, accuracy 0.37777777777777777\n",
            "Epoch 1: train loss 1.7688494126001995, accuracy 0.3844444444444444\n",
            "Epoch 1: train loss 1.626880619261, accuracy 0.40444444444444444\n",
            "Epoch 1: train loss 1.6626592212253146, accuracy 0.36444444444444446\n",
            "Epoch 1: train loss 1.6932342052459717, accuracy 0.35555555555555557\n",
            "Epoch 1: train loss 1.7318329016367595, accuracy 0.34444444444444444\n",
            "Epoch 2: train loss 1.6819676293267145, accuracy 0.38666666666666666\n",
            "Epoch 2: train loss 1.6375234127044678, accuracy 0.37777777777777777\n",
            "Epoch 2: train loss 1.6298534472783406, accuracy 0.43555555555555553\n",
            "Epoch 2: train loss 1.6475439336564806, accuracy 0.3977777777777778\n",
            "Epoch 2: train loss 1.7156039873758953, accuracy 0.37333333333333335\n",
            "Epoch 2: train loss 1.6893615457746718, accuracy 0.35777777777777775\n",
            "Epoch 2: train loss 1.6696333090464275, accuracy 0.37555555555555553\n",
            "Epoch 2: train loss 1.7078751458062067, accuracy 0.3377777777777778\n",
            "Epoch 2: train loss 1.650207731458876, accuracy 0.3933333333333333\n",
            "Epoch 2: train loss 1.7598892317877874, accuracy 0.3377777777777778\n",
            "Epoch 3: train loss 1.5536304579840765, accuracy 0.4311111111111111\n",
            "Epoch 3: train loss 1.6253208451800876, accuracy 0.39111111111111113\n",
            "Epoch 3: train loss 1.647366960843404, accuracy 0.38222222222222224\n",
            "Epoch 3: train loss 1.6648413472705417, accuracy 0.3933333333333333\n",
            "Epoch 3: train loss 1.7295395400789049, accuracy 0.36444444444444446\n",
            "Epoch 3: train loss 1.6886674563090007, accuracy 0.36444444444444446\n",
            "Epoch 3: train loss 1.6890238126118977, accuracy 0.33555555555555555\n",
            "Epoch 3: train loss 1.6949617597791884, accuracy 0.38222222222222224\n",
            "Epoch 3: train loss 1.5451340410444472, accuracy 0.41333333333333333\n",
            "Epoch 3: train loss 1.728791144159105, accuracy 0.35555555555555557\n",
            "Epoch 4: train loss 1.6489146947860718, accuracy 0.37777777777777777\n",
            "Epoch 4: train loss 1.6261214415232341, accuracy 0.3844444444444444\n",
            "Epoch 4: train loss 1.75211681260003, accuracy 0.38666666666666666\n",
            "Epoch 4: train loss 1.6405039760801527, accuracy 0.37333333333333335\n",
            "Epoch 4: train loss 1.6621136400434706, accuracy 0.37777777777777777\n",
            "Epoch 4: train loss 1.6027909914652507, accuracy 0.38222222222222224\n",
            "Epoch 4: train loss 1.6394721534517076, accuracy 0.36444444444444446\n",
            "Epoch 4: train loss 1.5532930294672649, accuracy 0.4088888888888889\n",
            "Epoch 4: train loss 1.716054810418023, accuracy 0.36666666666666664\n",
            "Epoch 4: train loss 1.6883570088280573, accuracy 0.3711111111111111\n",
            "Epoch 5: train loss 1.5867119232813518, accuracy 0.4088888888888889\n",
            "Epoch 5: train loss 1.5631645917892456, accuracy 0.41555555555555557\n",
            "Epoch 5: train loss 1.6094554397794936, accuracy 0.42444444444444446\n",
            "Epoch 5: train loss 1.6676477723651462, accuracy 0.39111111111111113\n",
            "Epoch 5: train loss 1.6798770560158625, accuracy 0.35777777777777775\n",
            "Epoch 5: train loss 1.5077865388658311, accuracy 0.4177777777777778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:06:51,075 | server.py:229 | fit_round 16 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.5849765009350247, accuracy 0.37777777777777777\n",
            "Epoch 5: train loss 1.6813403500450983, accuracy 0.3688888888888889\n",
            "Epoch 5: train loss 1.5646418068144057, accuracy 0.38222222222222224\n",
            "Epoch 5: train loss 1.5698759688271418, accuracy 0.41333333333333333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:06:53,963 | server.py:116 | fit progress: (16, 1.5227009838819503, {'accuracy': 0.4461}, 293.1660834409995)\n",
            "INFO flower 2023-01-02 13:06:53,963 | server.py:163 | evaluate_round 16: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:06:53,964 | server.py:215 | fit_round 17: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.5227009838819503 / accuracy 0.4461\n",
            "[Client 24, round 17] fit, config: {'server_round': 17, 'local_epochs': 5, 'learning_rate': 0.21286444277371888}\n",
            "[Client 49, round 17] fit, config: {'server_round': 17, 'local_epochs': 5, 'learning_rate': 0.21286444277371888}\n",
            "[Client 9, round 17] fit, config: {'server_round': 17, 'local_epochs': 5, 'learning_rate': 0.21286444277371888}\n",
            "[Client 63, round 17] fit, config: {'server_round': 17, 'local_epochs': 5, 'learning_rate': 0.21286444277371888}\n",
            "[Client 5, round 17] fit, config: {'server_round': 17, 'local_epochs': 5, 'learning_rate': 0.21286444277371888}\n",
            "[Client 36, round 17] fit, config: {'server_round': 17, 'local_epochs': 5, 'learning_rate': 0.21286444277371888}\n",
            "[Client 17, round 17] fit, config: {'server_round': 17, 'local_epochs': 5, 'learning_rate': 0.21286444277371888}\n",
            "[Client 60, round 17] fit, config: {'server_round': 17, 'local_epochs': 5, 'learning_rate': 0.21286444277371888}\n",
            "[Client 92, round 17] fit, config: {'server_round': 17, 'local_epochs': 5, 'learning_rate': 0.21286444277371888}\n",
            "[Client 93, round 17] fit, config: {'server_round': 17, 'local_epochs': 5, 'learning_rate': 0.21286444277371888}\n",
            "Epoch 1: train loss 1.7653318246205647, accuracy 0.3288888888888889\n",
            "Epoch 1: train loss 1.6581527127159967, accuracy 0.39555555555555555\n",
            "Epoch 1: train loss 1.7263735797670152, accuracy 0.34444444444444444\n",
            "Epoch 1: train loss 1.6688780652152166, accuracy 0.39555555555555555\n",
            "Epoch 1: train loss 1.720523132218255, accuracy 0.3933333333333333\n",
            "Epoch 1: train loss 1.622719062699212, accuracy 0.4111111111111111\n",
            "Epoch 1: train loss 1.7943223714828491, accuracy 0.36666666666666664\n",
            "Epoch 1: train loss 1.703469157218933, accuracy 0.36666666666666664\n",
            "Epoch 1: train loss 1.6925864219665527, accuracy 0.37777777777777777\n",
            "Epoch 1: train loss 1.6735270420710247, accuracy 0.34\n",
            "Epoch 2: train loss 1.6776673793792725, accuracy 0.38\n",
            "Epoch 2: train loss 1.647466739018758, accuracy 0.4111111111111111\n",
            "Epoch 2: train loss 1.6870259311464098, accuracy 0.38666666666666666\n",
            "Epoch 2: train loss 1.7612331443362765, accuracy 0.38222222222222224\n",
            "Epoch 2: train loss 1.687421441078186, accuracy 0.39111111111111113\n",
            "Epoch 2: train loss 1.706360353363885, accuracy 0.36666666666666664\n",
            "Epoch 2: train loss 1.6434223784340753, accuracy 0.4022222222222222\n",
            "Epoch 2: train loss 1.7652058866288927, accuracy 0.3488888888888889\n",
            "Epoch 2: train loss 1.6072130468156602, accuracy 0.3888888888888889\n",
            "Epoch 2: train loss 1.6903574334250555, accuracy 0.38666666666666666\n",
            "Epoch 3: train loss 1.6665689945220947, accuracy 0.36\n",
            "Epoch 3: train loss 1.710660868220859, accuracy 0.3844444444444444\n",
            "Epoch 3: train loss 1.579838130209181, accuracy 0.4222222222222222\n",
            "Epoch 3: train loss 1.5797199275758531, accuracy 0.3933333333333333\n",
            "Epoch 3: train loss 1.7451041009691026, accuracy 0.38222222222222224\n",
            "Epoch 3: train loss 1.734097162882487, accuracy 0.37333333333333335\n",
            "Epoch 3: train loss 1.6549465258916218, accuracy 0.3711111111111111\n",
            "Epoch 3: train loss 1.741748081313239, accuracy 0.3844444444444444\n",
            "Epoch 3: train loss 1.6175973018010457, accuracy 0.3844444444444444\n",
            "Epoch 3: train loss 1.60901055071089, accuracy 0.3711111111111111\n",
            "Epoch 4: train loss 1.681145429611206, accuracy 0.3977777777777778\n",
            "Epoch 4: train loss 1.734521018134223, accuracy 0.37333333333333335\n",
            "Epoch 4: train loss 1.6200206279754639, accuracy 0.4088888888888889\n",
            "Epoch 4: train loss 1.560296932856242, accuracy 0.4266666666666667\n",
            "Epoch 4: train loss 1.6549811098310683, accuracy 0.35333333333333333\n",
            "Epoch 4: train loss 1.531511492199368, accuracy 0.43777777777777777\n",
            "Epoch 4: train loss 1.5867425335778131, accuracy 0.41555555555555557\n",
            "Epoch 4: train loss 1.5752351681391399, accuracy 0.4022222222222222\n",
            "Epoch 4: train loss 1.6277283827463787, accuracy 0.35777777777777775\n",
            "Epoch 4: train loss 1.6073463890287611, accuracy 0.37555555555555553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:07:08,539 | server.py:229 | fit_round 17 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.7087595992618136, accuracy 0.4022222222222222\n",
            "Epoch 5: train loss 1.615629063712226, accuracy 0.3933333333333333\n",
            "Epoch 5: train loss 1.6466545926200018, accuracy 0.3888888888888889\n",
            "Epoch 5: train loss 1.6628449625439115, accuracy 0.38666666666666666\n",
            "Epoch 5: train loss 1.6399537722269695, accuracy 0.38\n",
            "Epoch 5: train loss 1.577792313363817, accuracy 0.4088888888888889\n",
            "Epoch 5: train loss 1.6167765193515353, accuracy 0.3888888888888889\n",
            "Epoch 5: train loss 1.542430837949117, accuracy 0.40444444444444444\n",
            "Epoch 5: train loss 1.722929384973314, accuracy 0.36666666666666664\n",
            "Epoch 5: train loss 1.652632474899292, accuracy 0.3688888888888889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:07:11,274 | server.py:116 | fit progress: (17, 1.5273851621150971, {'accuracy': 0.442}, 310.4774479030002)\n",
            "INFO flower 2023-01-02 13:07:11,275 | server.py:163 | evaluate_round 17: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:07:11,275 | server.py:215 | fit_round 18: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.5273851621150971 / accuracy 0.442\n",
            "[Client 13, round 18] fit, config: {'server_round': 18, 'local_epochs': 5, 'learning_rate': 0.2107357983459817}\n",
            "[Client 16, round 18] fit, config: {'server_round': 18, 'local_epochs': 5, 'learning_rate': 0.2107357983459817}\n",
            "[Client 15, round 18] fit, config: {'server_round': 18, 'local_epochs': 5, 'learning_rate': 0.2107357983459817}\n",
            "[Client 58, round 18] fit, config: {'server_round': 18, 'local_epochs': 5, 'learning_rate': 0.2107357983459817}\n",
            "[Client 45, round 18] fit, config: {'server_round': 18, 'local_epochs': 5, 'learning_rate': 0.2107357983459817}\n",
            "[Client 70, round 18] fit, config: {'server_round': 18, 'local_epochs': 5, 'learning_rate': 0.2107357983459817}\n",
            "[Client 78, round 18] fit, config: {'server_round': 18, 'local_epochs': 5, 'learning_rate': 0.2107357983459817}\n",
            "[Client 2, round 18] fit, config: {'server_round': 18, 'local_epochs': 5, 'learning_rate': 0.2107357983459817}\n",
            "[Client 56, round 18] fit, config: {'server_round': 18, 'local_epochs': 5, 'learning_rate': 0.2107357983459817}\n",
            "[Client 66, round 18] fit, config: {'server_round': 18, 'local_epochs': 5, 'learning_rate': 0.2107357983459817}\n",
            "Epoch 1: train loss 1.641431411107381, accuracy 0.4111111111111111\n",
            "Epoch 1: train loss 1.638738989830017, accuracy 0.42444444444444446\n",
            "Epoch 1: train loss 1.6857674519220989, accuracy 0.37333333333333335\n",
            "Epoch 1: train loss 1.6469921668370564, accuracy 0.3711111111111111\n",
            "Epoch 1: train loss 1.6267182297176785, accuracy 0.40444444444444444\n",
            "Epoch 1: train loss 1.6952295038435194, accuracy 0.4022222222222222\n",
            "Epoch 1: train loss 1.6306642029020522, accuracy 0.4066666666666667\n",
            "Epoch 1: train loss 1.6512791977988348, accuracy 0.39111111111111113\n",
            "Epoch 1: train loss 1.6322341230180528, accuracy 0.42444444444444446\n",
            "Epoch 1: train loss 1.674531512790256, accuracy 0.3688888888888889\n",
            "Epoch 2: train loss 1.61273811923133, accuracy 0.38666666666666666\n",
            "Epoch 2: train loss 1.5727918412950304, accuracy 0.41333333333333333\n",
            "Epoch 2: train loss 1.648859633339776, accuracy 0.3933333333333333\n",
            "Epoch 2: train loss 1.6116712225808039, accuracy 0.43333333333333335\n",
            "Epoch 2: train loss 1.642291784286499, accuracy 0.4022222222222222\n",
            "Epoch 2: train loss 1.7060925960540771, accuracy 0.35777777777777775\n",
            "Epoch 2: train loss 1.643192556169298, accuracy 0.38666666666666666\n",
            "Epoch 2: train loss 1.62651793162028, accuracy 0.4022222222222222\n",
            "Epoch 2: train loss 1.7119020620981853, accuracy 0.36666666666666664\n",
            "Epoch 2: train loss 1.632457176844279, accuracy 0.37333333333333335\n",
            "Epoch 3: train loss 1.6424124638239543, accuracy 0.39555555555555555\n",
            "Epoch 3: train loss 1.5547930532031589, accuracy 0.42\n",
            "Epoch 3: train loss 1.5463533931308322, accuracy 0.4533333333333333\n",
            "Epoch 3: train loss 1.650731020503574, accuracy 0.4022222222222222\n",
            "Epoch 3: train loss 1.6278558042314317, accuracy 0.4111111111111111\n",
            "Epoch 3: train loss 1.66040657626258, accuracy 0.3622222222222222\n",
            "Epoch 3: train loss 1.6316807005140517, accuracy 0.44\n",
            "Epoch 3: train loss 1.6033436589770846, accuracy 0.38\n",
            "Epoch 3: train loss 1.5576190551122029, accuracy 0.4311111111111111\n",
            "Epoch 3: train loss 1.612729059325324, accuracy 0.4088888888888889\n",
            "Epoch 4: train loss 1.5958324273427327, accuracy 0.3888888888888889\n",
            "Epoch 4: train loss 1.652792877621121, accuracy 0.3888888888888889\n",
            "Epoch 4: train loss 1.5980358256234064, accuracy 0.42444444444444446\n",
            "Epoch 4: train loss 1.6110461685392592, accuracy 0.4066666666666667\n",
            "Epoch 4: train loss 1.5953007804022894, accuracy 0.41555555555555557\n",
            "Epoch 4: train loss 1.5713142553965251, accuracy 0.42\n",
            "Epoch 4: train loss 1.6322935422261555, accuracy 0.4111111111111111\n",
            "Epoch 4: train loss 1.66933008035024, accuracy 0.37555555555555553\n",
            "Epoch 4: train loss 1.5568459696239896, accuracy 0.43555555555555553\n",
            "Epoch 4: train loss 1.6487022108501859, accuracy 0.3977777777777778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:07:26,350 | server.py:229 | fit_round 18 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.5297268761528864, accuracy 0.41555555555555557\n",
            "Epoch 5: train loss 1.630689223607381, accuracy 0.4066666666666667\n",
            "Epoch 5: train loss 1.5446850193871393, accuracy 0.42444444444444446\n",
            "Epoch 5: train loss 1.6519183582729764, accuracy 0.4022222222222222\n",
            "Epoch 5: train loss 1.5916836791568332, accuracy 0.3977777777777778\n",
            "Epoch 5: train loss 1.5737609068552654, accuracy 0.4111111111111111\n",
            "Epoch 5: train loss 1.592426790131463, accuracy 0.44222222222222224\n",
            "Epoch 5: train loss 1.5842842260996501, accuracy 0.4222222222222222\n",
            "Epoch 5: train loss 1.7022870646582708, accuracy 0.4066666666666667\n",
            "Epoch 5: train loss 1.4800212118360732, accuracy 0.43555555555555553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:07:28,995 | server.py:116 | fit progress: (18, 1.4979898434877397, {'accuracy': 0.4534}, 328.19873994800037)\n",
            "INFO flower 2023-01-02 13:07:28,996 | server.py:163 | evaluate_round 18: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:07:28,997 | server.py:215 | fit_round 19: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.4979898434877397 / accuracy 0.4534\n",
            "[Client 45, round 19] fit, config: {'server_round': 19, 'local_epochs': 5, 'learning_rate': 0.20862844036252187}\n",
            "[Client 46, round 19] fit, config: {'server_round': 19, 'local_epochs': 5, 'learning_rate': 0.20862844036252187}\n",
            "[Client 36, round 19] fit, config: {'server_round': 19, 'local_epochs': 5, 'learning_rate': 0.20862844036252187}\n",
            "[Client 27, round 19] fit, config: {'server_round': 19, 'local_epochs': 5, 'learning_rate': 0.20862844036252187}\n",
            "[Client 49, round 19] fit, config: {'server_round': 19, 'local_epochs': 5, 'learning_rate': 0.20862844036252187}\n",
            "[Client 6, round 19] fit, config: {'server_round': 19, 'local_epochs': 5, 'learning_rate': 0.20862844036252187}\n",
            "[Client 13, round 19] fit, config: {'server_round': 19, 'local_epochs': 5, 'learning_rate': 0.20862844036252187}\n",
            "[Client 96, round 19] fit, config: {'server_round': 19, 'local_epochs': 5, 'learning_rate': 0.20862844036252187}\n",
            "[Client 65, round 19] fit, config: {'server_round': 19, 'local_epochs': 5, 'learning_rate': 0.20862844036252187}\n",
            "[Client 12, round 19] fit, config: {'server_round': 19, 'local_epochs': 5, 'learning_rate': 0.20862844036252187}\n",
            "Epoch 1: train loss 1.5845313999387953, accuracy 0.4288888888888889\n",
            "Epoch 1: train loss 1.5992730193667941, accuracy 0.4088888888888889\n",
            "Epoch 1: train loss 1.676683823267619, accuracy 0.3711111111111111\n",
            "Epoch 1: train loss 1.6254899104436238, accuracy 0.4088888888888889\n",
            "Epoch 1: train loss 1.6371532413694594, accuracy 0.40444444444444444\n",
            "Epoch 1: train loss 1.569598502582974, accuracy 0.46\n",
            "Epoch 1: train loss 1.6121494505140517, accuracy 0.42\n",
            "Epoch 1: train loss 1.6537712812423706, accuracy 0.38666666666666666\n",
            "Epoch 1: train loss 1.6120020018683539, accuracy 0.37777777777777777\n",
            "Epoch 1: train loss 1.6539056168662176, accuracy 0.3933333333333333\n",
            "Epoch 2: train loss 1.6215216583675809, accuracy 0.3888888888888889\n",
            "Epoch 2: train loss 1.73596371544732, accuracy 0.3466666666666667\n",
            "Epoch 2: train loss 1.6897161271837022, accuracy 0.37333333333333335\n",
            "Epoch 2: train loss 1.6194467279646132, accuracy 0.43333333333333335\n",
            "Epoch 2: train loss 1.6044739087422688, accuracy 0.4111111111111111\n",
            "Epoch 2: train loss 1.6137145360310872, accuracy 0.38666666666666666\n",
            "Epoch 2: train loss 1.5894592338138156, accuracy 0.3977777777777778\n",
            "Epoch 2: train loss 1.590152793460422, accuracy 0.42444444444444446\n",
            "Epoch 2: train loss 1.5907051033443875, accuracy 0.41333333333333333\n",
            "Epoch 2: train loss 1.6228813992606268, accuracy 0.44\n",
            "Epoch 3: train loss 1.6066099537743463, accuracy 0.38222222222222224\n",
            "Epoch 3: train loss 1.7424896160761516, accuracy 0.38\n",
            "Epoch 3: train loss 1.6478019555409749, accuracy 0.37555555555555553\n",
            "Epoch 3: train loss 1.5953555901845295, accuracy 0.41555555555555557\n",
            "Epoch 3: train loss 1.6232195032967462, accuracy 0.4311111111111111\n",
            "Epoch 3: train loss 1.6477738089031644, accuracy 0.38222222222222224\n",
            "Epoch 3: train loss 1.5959740082422893, accuracy 0.4088888888888889\n",
            "Epoch 3: train loss 1.6127003166410658, accuracy 0.3933333333333333\n",
            "Epoch 3: train loss 1.691775295469496, accuracy 0.3711111111111111\n",
            "Epoch 3: train loss 1.690529704093933, accuracy 0.3711111111111111\n",
            "Epoch 4: train loss 1.597775591744317, accuracy 0.41555555555555557\n",
            "Epoch 4: train loss 1.5471010870403714, accuracy 0.42\n",
            "Epoch 4: train loss 1.5953908761342366, accuracy 0.3888888888888889\n",
            "Epoch 4: train loss 1.6157413985994127, accuracy 0.37777777777777777\n",
            "Epoch 4: train loss 1.5984477467007108, accuracy 0.43777777777777777\n",
            "Epoch 4: train loss 1.5884694655736287, accuracy 0.39555555555555555\n",
            "Epoch 4: train loss 1.5800090101030138, accuracy 0.4222222222222222\n",
            "Epoch 4: train loss 1.5682837035920885, accuracy 0.46\n",
            "Epoch 4: train loss 1.624721844991048, accuracy 0.4111111111111111\n",
            "Epoch 4: train loss 1.5689778327941895, accuracy 0.41333333333333333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:07:43,596 | server.py:229 | fit_round 19 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.5960714022318523, accuracy 0.42Epoch 5: train loss 1.6241389248106215, accuracy 0.41333333333333333\n",
            "\n",
            "Epoch 5: train loss 1.5469098885854085, accuracy 0.43777777777777777\n",
            "Epoch 5: train loss 1.5403373771243625, accuracy 0.4311111111111111\n",
            "Epoch 5: train loss 1.5439459085464478, accuracy 0.45111111111111113\n",
            "Epoch 5: train loss 1.531611031956143, accuracy 0.42\n",
            "Epoch 5: train loss 1.6177615059746637, accuracy 0.4\n",
            "Epoch 5: train loss 1.5711089505089655, accuracy 0.42\n",
            "Epoch 5: train loss 1.5361890527937148, accuracy 0.43333333333333335\n",
            "Epoch 5: train loss 1.5814222362306383, accuracy 0.4177777777777778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:07:46,347 | server.py:116 | fit progress: (19, 1.4835423177480698, {'accuracy': 0.4596}, 345.5502458310002)\n",
            "INFO flower 2023-01-02 13:07:46,348 | server.py:163 | evaluate_round 19: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:07:46,348 | server.py:215 | fit_round 20: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.4835423177480698 / accuracy 0.4596\n",
            "[Client 75, round 20] fit, config: {'server_round': 20, 'local_epochs': 5, 'learning_rate': 0.20654215595889666}\n",
            "[Client 85, round 20] fit, config: {'server_round': 20, 'local_epochs': 5, 'learning_rate': 0.20654215595889666}\n",
            "[Client 94, round 20] fit, config: {'server_round': 20, 'local_epochs': 5, 'learning_rate': 0.20654215595889666}\n",
            "[Client 10, round 20] fit, config: {'server_round': 20, 'local_epochs': 5, 'learning_rate': 0.20654215595889666}\n",
            "[Client 99, round 20] fit, config: {'server_round': 20, 'local_epochs': 5, 'learning_rate': 0.20654215595889666}\n",
            "[Client 41, round 20] fit, config: {'server_round': 20, 'local_epochs': 5, 'learning_rate': 0.20654215595889666}\n",
            "[Client 26, round 20] fit, config: {'server_round': 20, 'local_epochs': 5, 'learning_rate': 0.20654215595889666}\n",
            "[Client 49, round 20] fit, config: {'server_round': 20, 'local_epochs': 5, 'learning_rate': 0.20654215595889666}\n",
            "[Client 23, round 20] fit, config: {'server_round': 20, 'local_epochs': 5, 'learning_rate': 0.20654215595889666}\n",
            "[Client 53, round 20] fit, config: {'server_round': 20, 'local_epochs': 5, 'learning_rate': 0.20654215595889666}\n",
            "Epoch 1: train loss 1.6900298595428467, accuracy 0.4\n",
            "Epoch 1: train loss 1.6280774407916598, accuracy 0.3977777777777778\n",
            "Epoch 1: train loss 1.6408447821935017, accuracy 0.38666666666666666\n",
            "Epoch 1: train loss 1.6448698706097074, accuracy 0.3977777777777778\n",
            "Epoch 1: train loss 1.6371217171351116, accuracy 0.41333333333333333\n",
            "Epoch 1: train loss 1.6376351912816365, accuracy 0.36666666666666664\n",
            "Epoch 1: train loss 1.6830217043558757, accuracy 0.38\n",
            "Epoch 1: train loss 1.620466907819112, accuracy 0.37555555555555553\n",
            "Epoch 1: train loss 1.5807077752219305, accuracy 0.4311111111111111\n",
            "Epoch 1: train loss 1.6889330678515964, accuracy 0.36666666666666664\n",
            "Epoch 2: train loss 1.6643024285634358, accuracy 0.3977777777777778\n",
            "Epoch 2: train loss 1.6240007215076022, accuracy 0.38222222222222224\n",
            "Epoch 2: train loss 1.5389203098085191, accuracy 0.45555555555555555\n",
            "Epoch 2: train loss 1.6658699247572157, accuracy 0.3688888888888889\n",
            "Epoch 2: train loss 1.6452252335018582, accuracy 0.38222222222222224\n",
            "Epoch 2: train loss 1.6380580531226263, accuracy 0.37555555555555553\n",
            "Epoch 2: train loss 1.7397988239924114, accuracy 0.38222222222222224\n",
            "Epoch 2: train loss 1.6358856625027127, accuracy 0.38\n",
            "Epoch 2: train loss 1.5902137756347656, accuracy 0.4177777777777778\n",
            "Epoch 2: train loss 1.5886229409111872, accuracy 0.4177777777777778\n",
            "Epoch 3: train loss 1.642738355530633, accuracy 0.40444444444444444\n",
            "Epoch 3: train loss 1.603992952240838, accuracy 0.4\n",
            "Epoch 3: train loss 1.6648907793892755, accuracy 0.3844444444444444\n",
            "Epoch 3: train loss 1.6555543608135648, accuracy 0.37333333333333335\n",
            "Epoch 3: train loss 1.5906426774130926, accuracy 0.4\n",
            "Epoch 3: train loss 1.5786078373591106, accuracy 0.4311111111111111\n",
            "Epoch 3: train loss 1.5917778147591486, accuracy 0.4111111111111111\n",
            "Epoch 3: train loss 1.5873878796895344, accuracy 0.39111111111111113\n",
            "Epoch 3: train loss 1.5101972818374634, accuracy 0.44666666666666666\n",
            "Epoch 3: train loss 1.6717842287487454, accuracy 0.39555555555555555\n",
            "Epoch 4: train loss 1.6959142949846056, accuracy 0.3488888888888889\n",
            "Epoch 4: train loss 1.6278829177220662, accuracy 0.4111111111111111\n",
            "Epoch 4: train loss 1.5756288369496663, accuracy 0.41333333333333333\n",
            "Epoch 4: train loss 1.630011796951294, accuracy 0.41333333333333333\n",
            "Epoch 4: train loss 1.5795610613293118, accuracy 0.42\n",
            "Epoch 4: train loss 1.5558263725704617, accuracy 0.4288888888888889\n",
            "Epoch 4: train loss 1.583295742670695, accuracy 0.44666666666666666\n",
            "Epoch 4: train loss 1.632664680480957, accuracy 0.3888888888888889\n",
            "Epoch 4: train loss 1.577267713016934, accuracy 0.4088888888888889\n",
            "Epoch 4: train loss 1.5977034038967557, accuracy 0.4222222222222222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:08:01,187 | server.py:229 | fit_round 20 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.5722376373079088, accuracy 0.43333333333333335\n",
            "Epoch 5: train loss 1.4855645497639973, accuracy 0.4488888888888889\n",
            "Epoch 5: train loss 1.602047284444173, accuracy 0.43333333333333335\n",
            "Epoch 5: train loss 1.600733346409268, accuracy 0.39111111111111113\n",
            "Epoch 5: train loss 1.5628117190466986, accuracy 0.4222222222222222\n",
            "Epoch 5: train loss 1.5096042421129015, accuracy 0.45111111111111113\n",
            "Epoch 5: train loss 1.5698905785878499, accuracy 0.41333333333333333\n",
            "Epoch 5: train loss 1.5864929225709703, accuracy 0.42\n",
            "Epoch 5: train loss 1.5769753456115723, accuracy 0.4066666666666667\n",
            "Epoch 5: train loss 1.5720090336269803, accuracy 0.4111111111111111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:08:03,804 | server.py:116 | fit progress: (20, 1.4820896822214127, {'accuracy': 0.4585}, 363.0075771110005)\n",
            "INFO flower 2023-01-02 13:08:03,805 | server.py:163 | evaluate_round 20: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:08:03,805 | server.py:215 | fit_round 21: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.4820896822214127 / accuracy 0.4585\n",
            "[Client 16, round 21] fit, config: {'server_round': 21, 'local_epochs': 5, 'learning_rate': 0.2044767343993077}\n",
            "[Client 60, round 21] fit, config: {'server_round': 21, 'local_epochs': 5, 'learning_rate': 0.2044767343993077}\n",
            "[Client 17, round 21] fit, config: {'server_round': 21, 'local_epochs': 5, 'learning_rate': 0.2044767343993077}\n",
            "[Client 0, round 21] fit, config: {'server_round': 21, 'local_epochs': 5, 'learning_rate': 0.2044767343993077}\n",
            "[Client 42, round 21] fit, config: {'server_round': 21, 'local_epochs': 5, 'learning_rate': 0.2044767343993077}\n",
            "[Client 11, round 21] fit, config: {'server_round': 21, 'local_epochs': 5, 'learning_rate': 0.2044767343993077}\n",
            "[Client 20, round 21] fit, config: {'server_round': 21, 'local_epochs': 5, 'learning_rate': 0.2044767343993077}\n",
            "[Client 12, round 21] fit, config: {'server_round': 21, 'local_epochs': 5, 'learning_rate': 0.2044767343993077}\n",
            "[Client 18, round 21] fit, config: {'server_round': 21, 'local_epochs': 5, 'learning_rate': 0.2044767343993077}\n",
            "[Client 4, round 21] fit, config: {'server_round': 21, 'local_epochs': 5, 'learning_rate': 0.2044767343993077}\n",
            "Epoch 1: train loss 1.639172328843011, accuracy 0.36666666666666664\n",
            "Epoch 1: train loss 1.7110793855455186, accuracy 0.36666666666666664\n",
            "Epoch 1: train loss 1.6810111469692655, accuracy 0.3977777777777778\n",
            "Epoch 1: train loss 1.6342666149139404, accuracy 0.3977777777777778\n",
            "Epoch 1: train loss 1.6535221205817328, accuracy 0.3844444444444444\n",
            "Epoch 1: train loss 1.66300368309021, accuracy 0.3622222222222222\n",
            "Epoch 1: train loss 1.5320042371749878, accuracy 0.4266666666666667\n",
            "Epoch 1: train loss 1.645389609866672, accuracy 0.3977777777777778\n",
            "Epoch 1: train loss 1.5939812395307753, accuracy 0.38222222222222224\n",
            "Epoch 1: train loss 1.5929791265063815, accuracy 0.4111111111111111\n",
            "Epoch 2: train loss 1.561659296353658, accuracy 0.42\n",
            "Epoch 2: train loss 1.5801072120666504, accuracy 0.39111111111111113\n",
            "Epoch 2: train loss 1.6266540553834703, accuracy 0.4311111111111111\n",
            "Epoch 2: train loss 1.598015586535136, accuracy 0.3688888888888889\n",
            "Epoch 2: train loss 1.545623050795661, accuracy 0.3933333333333333\n",
            "Epoch 2: train loss 1.5994774500528972, accuracy 0.39555555555555555\n",
            "Epoch 2: train loss 1.6170335345798068, accuracy 0.39555555555555555\n",
            "Epoch 2: train loss 1.5889650185902913, accuracy 0.38666666666666666\n",
            "Epoch 2: train loss 1.5686129331588745, accuracy 0.3888888888888889\n",
            "Epoch 2: train loss 1.5366038348939683, accuracy 0.44222222222222224\n",
            "Epoch 3: train loss 1.6088002522786458, accuracy 0.4022222222222222\n",
            "Epoch 3: train loss 1.5989932351642184, accuracy 0.44\n",
            "Epoch 3: train loss 1.5719260374704997, accuracy 0.38666666666666666\n",
            "Epoch 3: train loss 1.5493660900327895, accuracy 0.4533333333333333\n",
            "Epoch 3: train loss 1.5935041507085164, accuracy 0.35555555555555557\n",
            "Epoch 3: train loss 1.5646578073501587, accuracy 0.4488888888888889\n",
            "Epoch 3: train loss 1.6320960256788466, accuracy 0.38666666666666666\n",
            "Epoch 3: train loss 1.56128810511695, accuracy 0.4088888888888889\n",
            "Epoch 3: train loss 1.5959936910205417, accuracy 0.42\n",
            "Epoch 3: train loss 1.5709205600950453, accuracy 0.4266666666666667\n",
            "Epoch 4: train loss 1.491695311334398, accuracy 0.46444444444444444\n",
            "Epoch 4: train loss 1.6129315031899347, accuracy 0.3977777777777778\n",
            "Epoch 4: train loss 1.6089517143037584, accuracy 0.43333333333333335\n",
            "Epoch 4: train loss 1.5185825294918485, accuracy 0.43555555555555553\n",
            "Epoch 4: train loss 1.6440488762325711, accuracy 0.3888888888888889\n",
            "Epoch 4: train loss 1.6217861970265706, accuracy 0.4022222222222222\n",
            "Epoch 4: train loss 1.5528382195366754, accuracy 0.42444444444444446\n",
            "Epoch 4: train loss 1.541333556175232, accuracy 0.4444444444444444\n",
            "Epoch 4: train loss 1.5542147954305012, accuracy 0.4177777777777778\n",
            "Epoch 4: train loss 1.576785100830926, accuracy 0.4111111111111111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:08:18,239 | server.py:229 | fit_round 21 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.4849422772725422, accuracy 0.44222222222222224\n",
            "Epoch 5: train loss 1.4678902758492365, accuracy 0.44222222222222224\n",
            "Epoch 5: train loss 1.5254859394497342, accuracy 0.4311111111111111\n",
            "Epoch 5: train loss 1.5117662482791476, accuracy 0.4444444444444444\n",
            "Epoch 5: train loss 1.5523103475570679, accuracy 0.43555555555555553\n",
            "Epoch 5: train loss 1.7024461693233914, accuracy 0.36444444444444446\n",
            "Epoch 5: train loss 1.4721868303087022, accuracy 0.4622222222222222\n",
            "Epoch 5: train loss 1.5389986435572307, accuracy 0.4066666666666667\n",
            "Epoch 5: train loss 1.5576774544186063, accuracy 0.3888888888888889\n",
            "Epoch 5: train loss 1.5413744449615479, accuracy 0.44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:08:21,008 | server.py:116 | fit progress: (21, 1.4764712953567505, {'accuracy': 0.4629}, 380.21170249699935)\n",
            "INFO flower 2023-01-02 13:08:21,009 | server.py:163 | evaluate_round 21: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:08:21,010 | server.py:215 | fit_round 22: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.4764712953567505 / accuracy 0.4629\n",
            "[Client 28, round 22] fit, config: {'server_round': 22, 'local_epochs': 5, 'learning_rate': 0.2024319670553146}\n",
            "[Client 55, round 22] fit, config: {'server_round': 22, 'local_epochs': 5, 'learning_rate': 0.2024319670553146}\n",
            "[Client 25, round 22] fit, config: {'server_round': 22, 'local_epochs': 5, 'learning_rate': 0.2024319670553146}\n",
            "[Client 58, round 22] fit, config: {'server_round': 22, 'local_epochs': 5, 'learning_rate': 0.2024319670553146}\n",
            "[Client 84, round 22] fit, config: {'server_round': 22, 'local_epochs': 5, 'learning_rate': 0.2024319670553146}\n",
            "[Client 51, round 22] fit, config: {'server_round': 22, 'local_epochs': 5, 'learning_rate': 0.2024319670553146}\n",
            "[Client 7, round 22] fit, config: {'server_round': 22, 'local_epochs': 5, 'learning_rate': 0.2024319670553146}\n",
            "[Client 19, round 22] fit, config: {'server_round': 22, 'local_epochs': 5, 'learning_rate': 0.2024319670553146}\n",
            "[Client 14, round 22] fit, config: {'server_round': 22, 'local_epochs': 5, 'learning_rate': 0.2024319670553146}\n",
            "[Client 59, round 22] fit, config: {'server_round': 22, 'local_epochs': 5, 'learning_rate': 0.2024319670553146}\n",
            "Epoch 1: train loss 1.5913552973005507, accuracy 0.40444444444444444\n",
            "Epoch 1: train loss 1.5916650030348036, accuracy 0.43777777777777777\n",
            "Epoch 1: train loss 1.5870118141174316, accuracy 0.4022222222222222\n",
            "Epoch 1: train loss 1.592843042479621, accuracy 0.4111111111111111\n",
            "Epoch 1: train loss 1.5239355829026964, accuracy 0.4222222222222222\n",
            "Epoch 1: train loss 1.6483939223819308, accuracy 0.3888888888888889\n",
            "Epoch 1: train loss 1.716010954644945, accuracy 0.4066666666666667\n",
            "Epoch 1: train loss 1.6610349946551852, accuracy 0.39555555555555555\n",
            "Epoch 1: train loss 1.6215435531404283, accuracy 0.4288888888888889\n",
            "Epoch 1: train loss 1.680861512819926, accuracy 0.42\n",
            "Epoch 2: train loss 1.6038113037745159, accuracy 0.41555555555555557\n",
            "Epoch 2: train loss 1.5501022736231487, accuracy 0.41555555555555557\n",
            "Epoch 2: train loss 1.5902639892366197, accuracy 0.44222222222222224\n",
            "Epoch 2: train loss 1.6581732034683228, accuracy 0.4111111111111111\n",
            "Epoch 2: train loss 1.6026965777079265, accuracy 0.3933333333333333\n",
            "Epoch 2: train loss 1.4719439480039809, accuracy 0.44\n",
            "Epoch 2: train loss 1.5915358861287434, accuracy 0.4266666666666667\n",
            "Epoch 2: train loss 1.5793427493837144, accuracy 0.4177777777777778\n",
            "Epoch 2: train loss 1.5500568019019232, accuracy 0.43777777777777777\n",
            "Epoch 2: train loss 1.5768856869803534, accuracy 0.4266666666666667\n",
            "Epoch 3: train loss 1.5548668569988675, accuracy 0.4177777777777778\n",
            "Epoch 3: train loss 1.5354377958509657, accuracy 0.44\n",
            "Epoch 3: train loss 1.5698343912760417, accuracy 0.4177777777777778\n",
            "Epoch 3: train loss 1.509669303894043, accuracy 0.4533333333333333\n",
            "Epoch 3: train loss 1.5403258403142293, accuracy 0.4311111111111111\n",
            "Epoch 3: train loss 1.5721560716629028, accuracy 0.4066666666666667\n",
            "Epoch 3: train loss 1.631894999080234, accuracy 0.41555555555555557\n",
            "Epoch 3: train loss 1.4206981261571248, accuracy 0.47555555555555556\n",
            "Epoch 3: train loss 1.5508659813139174, accuracy 0.43555555555555553\n",
            "Epoch 3: train loss 1.6190681457519531, accuracy 0.43333333333333335\n",
            "Epoch 4: train loss 1.4621885882483587, accuracy 0.4488888888888889\n",
            "Epoch 4: train loss 1.6429015795389812, accuracy 0.40444444444444444\n",
            "Epoch 4: train loss 1.5295845799975925, accuracy 0.4177777777777778\n",
            "Epoch 4: train loss 1.507711238331265, accuracy 0.4311111111111111\n",
            "Epoch 4: train loss 1.4896018770005968, accuracy 0.44222222222222224\n",
            "Epoch 4: train loss 1.5369932783974543, accuracy 0.43555555555555553\n",
            "Epoch 4: train loss 1.5859477122624714, accuracy 0.39555555555555555\n",
            "Epoch 4: train loss 1.5847538577185736, accuracy 0.4688888888888889\n",
            "Epoch 4: train loss 1.513263914320204, accuracy 0.3933333333333333\n",
            "Epoch 4: train loss 1.546691722340054, accuracy 0.4533333333333333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:08:36,407 | server.py:229 | fit_round 22 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.5317277908325195, accuracy 0.43333333333333335\n",
            "Epoch 5: train loss 1.527605454126994, accuracy 0.4111111111111111\n",
            "Epoch 5: train loss 1.5025623109605577, accuracy 0.44222222222222224\n",
            "Epoch 5: train loss 1.413293374909295, accuracy 0.4777777777777778\n",
            "Epoch 5: train loss 1.4800292518403795, accuracy 0.46444444444444444\n",
            "Epoch 5: train loss 1.4355610741509333, accuracy 0.4533333333333333\n",
            "Epoch 5: train loss 1.506337496969435, accuracy 0.43555555555555553\n",
            "Epoch 5: train loss 1.5424193011389837, accuracy 0.41555555555555557\n",
            "Epoch 5: train loss 1.593760119544135, accuracy 0.4\n",
            "Epoch 5: train loss 1.573988185988532, accuracy 0.42444444444444446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:08:39,150 | server.py:116 | fit progress: (22, 1.4415018260478973, {'accuracy': 0.4801}, 398.35304839200035)\n",
            "INFO flower 2023-01-02 13:08:39,150 | server.py:163 | evaluate_round 22: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:08:39,151 | server.py:215 | fit_round 23: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.4415018260478973 / accuracy 0.4801\n",
            "[Client 11, round 23] fit, config: {'server_round': 23, 'local_epochs': 5, 'learning_rate': 0.20040764738476147}\n",
            "[Client 89, round 23] fit, config: {'server_round': 23, 'local_epochs': 5, 'learning_rate': 0.20040764738476147}\n",
            "[Client 17, round 23] fit, config: {'server_round': 23, 'local_epochs': 5, 'learning_rate': 0.20040764738476147}\n",
            "[Client 85, round 23] fit, config: {'server_round': 23, 'local_epochs': 5, 'learning_rate': 0.20040764738476147}\n",
            "[Client 5, round 23] fit, config: {'server_round': 23, 'local_epochs': 5, 'learning_rate': 0.20040764738476147}\n",
            "[Client 45, round 23] fit, config: {'server_round': 23, 'local_epochs': 5, 'learning_rate': 0.20040764738476147}\n",
            "[Client 56, round 23] fit, config: {'server_round': 23, 'local_epochs': 5, 'learning_rate': 0.20040764738476147}\n",
            "[Client 26, round 23] fit, config: {'server_round': 23, 'local_epochs': 5, 'learning_rate': 0.20040764738476147}\n",
            "[Client 30, round 23] fit, config: {'server_round': 23, 'local_epochs': 5, 'learning_rate': 0.20040764738476147}\n",
            "[Client 55, round 23] fit, config: {'server_round': 23, 'local_epochs': 5, 'learning_rate': 0.20040764738476147}\n",
            "Epoch 1: train loss 1.6732840802934434, accuracy 0.4266666666666667\n",
            "Epoch 1: train loss 1.6801520453559027, accuracy 0.4\n",
            "Epoch 1: train loss 1.5652925305896335, accuracy 0.4222222222222222\n",
            "Epoch 1: train loss 1.7304053836398654, accuracy 0.3933333333333333\n",
            "Epoch 1: train loss 1.5272455877727933, accuracy 0.42444444444444446\n",
            "Epoch 1: train loss 1.5916426579157512, accuracy 0.3844444444444444\n",
            "Epoch 1: train loss 1.5413951608869765, accuracy 0.4111111111111111\n",
            "Epoch 1: train loss 1.6040760543611314, accuracy 0.39111111111111113\n",
            "Epoch 1: train loss 1.6201808585060968, accuracy 0.38666666666666666\n",
            "Epoch 1: train loss 1.5160598357518513, accuracy 0.41333333333333333\n",
            "Epoch 2: train loss 1.571034590403239, accuracy 0.4222222222222222\n",
            "Epoch 2: train loss 1.6258836189905803, accuracy 0.3844444444444444\n",
            "Epoch 2: train loss 1.5607407357957628, accuracy 0.43777777777777777\n",
            "Epoch 2: train loss 1.5745724042256672, accuracy 0.4111111111111111\n",
            "Epoch 2: train loss 1.5744910902447171, accuracy 0.4311111111111111\n",
            "Epoch 2: train loss 1.5392468108071222, accuracy 0.43333333333333335\n",
            "Epoch 2: train loss 1.547831932703654, accuracy 0.4444444444444444\n",
            "Epoch 2: train loss 1.5211733844545152, accuracy 0.4688888888888889\n",
            "Epoch 2: train loss 1.501309461063809, accuracy 0.4222222222222222\n",
            "Epoch 2: train loss 1.6330491569307115, accuracy 0.4288888888888889\n",
            "Epoch 3: train loss 1.53209830654992, accuracy 0.4\n",
            "Epoch 3: train loss 1.5418362352583144, accuracy 0.45555555555555555\n",
            "Epoch 3: train loss 1.5163931449254353, accuracy 0.44\n",
            "Epoch 3: train loss 1.5229928758409288, accuracy 0.4444444444444444\n",
            "Epoch 3: train loss 1.4942493836085002, accuracy 0.46\n",
            "Epoch 3: train loss 1.5671158234278362, accuracy 0.4311111111111111\n",
            "Epoch 3: train loss 1.6867895391252306, accuracy 0.38222222222222224\n",
            "Epoch 3: train loss 1.4793702231513128, accuracy 0.45111111111111113\n",
            "Epoch 3: train loss 1.5528379281361897, accuracy 0.43777777777777777\n",
            "Epoch 3: train loss 1.5296294424268935, accuracy 0.44\n",
            "Epoch 4: train loss 1.5338275962405734, accuracy 0.4222222222222222\n",
            "Epoch 4: train loss 1.5364083846410115, accuracy 0.4577777777777778\n",
            "Epoch 4: train loss 1.6126744482252333, accuracy 0.4488888888888889\n",
            "Epoch 4: train loss 1.5270243088404338, accuracy 0.4488888888888889\n",
            "Epoch 4: train loss 1.5612577199935913, accuracy 0.41333333333333333\n",
            "Epoch 4: train loss 1.508627520667182, accuracy 0.4688888888888889\n",
            "Epoch 4: train loss 1.4903695053524442, accuracy 0.44\n",
            "Epoch 4: train loss 1.4898603624767728, accuracy 0.43777777777777777\n",
            "Epoch 4: train loss 1.5271819432576497, accuracy 0.43333333333333335\n",
            "Epoch 4: train loss 1.5469891097810533, accuracy 0.38222222222222224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:08:54,546 | server.py:229 | fit_round 23 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.4967344734403822, accuracy 0.4111111111111111\n",
            "Epoch 5: train loss 1.5222143861982558, accuracy 0.4222222222222222\n",
            "Epoch 5: train loss 1.5423115491867065, accuracy 0.46\n",
            "Epoch 5: train loss 1.4889628622266982, accuracy 0.47333333333333333\n",
            "Epoch 5: train loss 1.4751092725329928, accuracy 0.4311111111111111\n",
            "Epoch 5: train loss 1.4518377913369074, accuracy 0.4622222222222222\n",
            "Epoch 5: train loss 1.4864787525600858, accuracy 0.43333333333333335\n",
            "Epoch 5: train loss 1.481506175465054, accuracy 0.44222222222222224\n",
            "Epoch 5: train loss 1.4742967287699382, accuracy 0.47333333333333333\n",
            "Epoch 5: train loss 1.4870991971757677, accuracy 0.44222222222222224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:08:57,253 | server.py:116 | fit progress: (23, 1.4402703523635865, {'accuracy': 0.4813}, 416.45629492400076)\n",
            "INFO flower 2023-01-02 13:08:57,253 | server.py:163 | evaluate_round 23: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:08:57,254 | server.py:215 | fit_round 24: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.4402703523635865 / accuracy 0.4813\n",
            "[Client 43, round 24] fit, config: {'server_round': 24, 'local_epochs': 5, 'learning_rate': 0.19840357091091385}\n",
            "[Client 85, round 24] fit, config: {'server_round': 24, 'local_epochs': 5, 'learning_rate': 0.19840357091091385}\n",
            "[Client 18, round 24] fit, config: {'server_round': 24, 'local_epochs': 5, 'learning_rate': 0.19840357091091385}\n",
            "[Client 11, round 24] fit, config: {'server_round': 24, 'local_epochs': 5, 'learning_rate': 0.19840357091091385}\n",
            "[Client 86, round 24] fit, config: {'server_round': 24, 'local_epochs': 5, 'learning_rate': 0.19840357091091385}\n",
            "[Client 1, round 24] fit, config: {'server_round': 24, 'local_epochs': 5, 'learning_rate': 0.19840357091091385}\n",
            "[Client 41, round 24] fit, config: {'server_round': 24, 'local_epochs': 5, 'learning_rate': 0.19840357091091385}\n",
            "[Client 37, round 24] fit, config: {'server_round': 24, 'local_epochs': 5, 'learning_rate': 0.19840357091091385}\n",
            "[Client 51, round 24] fit, config: {'server_round': 24, 'local_epochs': 5, 'learning_rate': 0.19840357091091385}\n",
            "[Client 44, round 24] fit, config: {'server_round': 24, 'local_epochs': 5, 'learning_rate': 0.19840357091091385}\n",
            "Epoch 1: train loss 1.5541132556067572, accuracy 0.4177777777777778\n",
            "Epoch 1: train loss 1.5613774988386366, accuracy 0.43555555555555553\n",
            "Epoch 1: train loss 1.5287415319018893, accuracy 0.4311111111111111\n",
            "Epoch 1: train loss 1.6052760812971327, accuracy 0.4111111111111111\n",
            "Epoch 1: train loss 1.7165009842978582, accuracy 0.37333333333333335\n",
            "Epoch 1: train loss 1.4965361489189997, accuracy 0.44\n",
            "Epoch 1: train loss 1.6074392795562744, accuracy 0.4311111111111111\n",
            "Epoch 1: train loss 1.5781309207280476, accuracy 0.4022222222222222\n",
            "Epoch 1: train loss 1.6227619383070204, accuracy 0.37555555555555553\n",
            "Epoch 1: train loss 1.6391046047210693, accuracy 0.35333333333333333\n",
            "Epoch 2: train loss 1.608002954059177, accuracy 0.41555555555555557\n",
            "Epoch 2: train loss 1.575428432888455, accuracy 0.4266666666666667\n",
            "Epoch 2: train loss 1.5281118816799588, accuracy 0.42\n",
            "Epoch 2: train loss 1.5579824447631836, accuracy 0.4177777777777778\n",
            "Epoch 2: train loss 1.6433677275975545, accuracy 0.36444444444444446\n",
            "Epoch 2: train loss 1.5318127738104925, accuracy 0.44\n",
            "Epoch 2: train loss 1.5444876750310261, accuracy 0.43555555555555553\n",
            "Epoch 2: train loss 1.5864635705947876, accuracy 0.41555555555555557\n",
            "Epoch 2: train loss 1.6775622367858887, accuracy 0.38222222222222224\n",
            "Epoch 2: train loss 1.5464596350987752, accuracy 0.4533333333333333\n",
            "Epoch 3: train loss 1.5229285425610013, accuracy 0.45111111111111113\n",
            "Epoch 3: train loss 1.4691379070281982, accuracy 0.42\n",
            "Epoch 3: train loss 1.5584542883767023, accuracy 0.4288888888888889\n",
            "Epoch 3: train loss 1.5879136323928833, accuracy 0.4066666666666667\n",
            "Epoch 3: train loss 1.5495285855399237, accuracy 0.43555555555555553\n",
            "Epoch 3: train loss 1.4579892820782132, accuracy 0.46\n",
            "Epoch 3: train loss 1.592137826813592, accuracy 0.4066666666666667\n",
            "Epoch 3: train loss 1.624607218636407, accuracy 0.4111111111111111\n",
            "Epoch 3: train loss 1.5496362580193415, accuracy 0.4266666666666667\n",
            "Epoch 3: train loss 1.5389125479592218, accuracy 0.4533333333333333\n",
            "Epoch 4: train loss 1.534259517987569, accuracy 0.4177777777777778\n",
            "Epoch 4: train loss 1.4354876942104764, accuracy 0.4822222222222222\n",
            "Epoch 4: train loss 1.7360616127649944, accuracy 0.3422222222222222\n",
            "Epoch 4: train loss 1.5673712227079604, accuracy 0.37555555555555553\n",
            "Epoch 4: train loss 1.495204382472568, accuracy 0.4688888888888889\n",
            "Epoch 4: train loss 1.4724953307045832, accuracy 0.4622222222222222\n",
            "Epoch 4: train loss 1.4921905861960516, accuracy 0.47555555555555556\n",
            "Epoch 4: train loss 1.5961110326978896, accuracy 0.42\n",
            "Epoch 4: train loss 1.4841006464428372, accuracy 0.4622222222222222\n",
            "Epoch 4: train loss 1.5564688046773274, accuracy 0.4622222222222222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:09:12,057 | server.py:229 | fit_round 24 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.4192160765329997, accuracy 0.4888888888888889\n",
            "Epoch 5: train loss 1.4882780578401353, accuracy 0.4622222222222222\n",
            "Epoch 5: train loss 1.5055180655585394, accuracy 0.44\n",
            "Epoch 5: train loss 1.4009639422098796, accuracy 0.47333333333333333\n",
            "Epoch 5: train loss 1.6098502079645793, accuracy 0.3933333333333333\n",
            "Epoch 5: train loss 1.5513378779093425, accuracy 0.42\n",
            "Epoch 5: train loss 1.485391550593906, accuracy 0.4488888888888889\n",
            "Epoch 5: train loss 1.558778961499532, accuracy 0.4311111111111111\n",
            "Epoch 5: train loss 1.4057027498881023, accuracy 0.4866666666666667\n",
            "Epoch 5: train loss 1.4871948957443237, accuracy 0.4577777777777778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:09:15,002 | server.py:116 | fit progress: (24, 1.4257594925165176, {'accuracy': 0.486}, 434.20542581799964)\n",
            "INFO flower 2023-01-02 13:09:15,003 | server.py:163 | evaluate_round 24: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:09:15,003 | server.py:215 | fit_round 25: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.4257594925165176 / accuracy 0.486\n",
            "[Client 29, round 25] fit, config: {'server_round': 25, 'local_epochs': 5, 'learning_rate': 0.1964195352018047}\n",
            "[Client 7, round 25] fit, config: {'server_round': 25, 'local_epochs': 5, 'learning_rate': 0.1964195352018047}\n",
            "[Client 8, round 25] fit, config: {'server_round': 25, 'local_epochs': 5, 'learning_rate': 0.1964195352018047}\n",
            "[Client 70, round 25] fit, config: {'server_round': 25, 'local_epochs': 5, 'learning_rate': 0.1964195352018047}\n",
            "[Client 14, round 25] fit, config: {'server_round': 25, 'local_epochs': 5, 'learning_rate': 0.1964195352018047}\n",
            "[Client 31, round 25] fit, config: {'server_round': 25, 'local_epochs': 5, 'learning_rate': 0.1964195352018047}\n",
            "[Client 36, round 25] fit, config: {'server_round': 25, 'local_epochs': 5, 'learning_rate': 0.1964195352018047}\n",
            "[Client 16, round 25] fit, config: {'server_round': 25, 'local_epochs': 5, 'learning_rate': 0.1964195352018047}\n",
            "[Client 30, round 25] fit, config: {'server_round': 25, 'local_epochs': 5, 'learning_rate': 0.1964195352018047}\n",
            "[Client 71, round 25] fit, config: {'server_round': 25, 'local_epochs': 5, 'learning_rate': 0.1964195352018047}\n",
            "Epoch 1: train loss 1.635840031835768, accuracy 0.37777777777777777\n",
            "Epoch 1: train loss 1.6286820040808783, accuracy 0.4088888888888889\n",
            "Epoch 1: train loss 1.51005838976966, accuracy 0.46\n",
            "Epoch 1: train loss 1.4757255183325872, accuracy 0.4488888888888889\n",
            "Epoch 1: train loss 1.6213587919871013, accuracy 0.41555555555555557\n",
            "Epoch 1: train loss 1.511971354484558, accuracy 0.4311111111111111\n",
            "Epoch 1: train loss 1.5856605503294203, accuracy 0.4222222222222222\n",
            "Epoch 1: train loss 1.6682937145233154, accuracy 0.4111111111111111\n",
            "Epoch 1: train loss 1.6054624451531305, accuracy 0.43333333333333335\n",
            "Epoch 1: train loss 1.6029819912380643, accuracy 0.39111111111111113\n",
            "Epoch 2: train loss 1.613667607307434, accuracy 0.43777777777777777\n",
            "Epoch 2: train loss 1.555950125058492, accuracy 0.4533333333333333\n",
            "Epoch 2: train loss 1.4323468208312988, accuracy 0.4688888888888889\n",
            "Epoch 2: train loss 1.509654786851671, accuracy 0.43333333333333335\n",
            "Epoch 2: train loss 1.524504926469591, accuracy 0.44\n",
            "Epoch 2: train loss 1.474299669265747, accuracy 0.43333333333333335\n",
            "Epoch 2: train loss 1.5127190616395738, accuracy 0.4488888888888889\n",
            "Epoch 2: train loss 1.542744755744934, accuracy 0.44666666666666666\n",
            "Epoch 2: train loss 1.5197415351867676, accuracy 0.4488888888888889\n",
            "Epoch 2: train loss 1.5785625378290813, accuracy 0.3933333333333333\n",
            "Epoch 3: train loss 1.5881513489617243, accuracy 0.40444444444444444\n",
            "Epoch 3: train loss 1.4638970560497708, accuracy 0.4444444444444444\n",
            "Epoch 3: train loss 1.606507831149631, accuracy 0.40444444444444444\n",
            "Epoch 3: train loss 1.4573515388700697, accuracy 0.46444444444444444\n",
            "Epoch 3: train loss 1.5244301557540894, accuracy 0.4222222222222222\n",
            "Epoch 3: train loss 1.5367447667651706, accuracy 0.43777777777777777\n",
            "Epoch 3: train loss 1.4652991029951308, accuracy 0.48\n",
            "Epoch 3: train loss 1.5037416219711304, accuracy 0.46\n",
            "Epoch 3: train loss 1.623396144972907, accuracy 0.37333333333333335\n",
            "Epoch 3: train loss 1.4650873475604587, accuracy 0.4622222222222222\n",
            "Epoch 4: train loss 1.51418670018514, accuracy 0.4622222222222222\n",
            "Epoch 4: train loss 1.5805382066302829, accuracy 0.39555555555555555\n",
            "Epoch 4: train loss 1.566118836402893, accuracy 0.43333333333333335\n",
            "Epoch 4: train loss 1.5240230957667034, accuracy 0.4533333333333333\n",
            "Epoch 4: train loss 1.5546820561091106, accuracy 0.42\n",
            "Epoch 4: train loss 1.5087640020582411, accuracy 0.43777777777777777\n",
            "Epoch 4: train loss 1.5145041677686903, accuracy 0.43777777777777777\n",
            "Epoch 4: train loss 1.5165005922317505, accuracy 0.46\n",
            "Epoch 4: train loss 1.5297351678212483, accuracy 0.46\n",
            "Epoch 4: train loss 1.4769675334294636, accuracy 0.4822222222222222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:09:29,580 | server.py:229 | fit_round 25 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.3990595208273993, accuracy 0.4822222222222222\n",
            "Epoch 5: train loss 1.497490366299947, accuracy 0.48\n",
            "Epoch 5: train loss 1.5329602559407551, accuracy 0.4488888888888889\n",
            "Epoch 5: train loss 1.4337855180104573, accuracy 0.4955555555555556\n",
            "Epoch 5: train loss 1.405192255973816, accuracy 0.44666666666666666\n",
            "Epoch 5: train loss 1.5347076521979437, accuracy 0.4577777777777778\n",
            "Epoch 5: train loss 1.497618211640252, accuracy 0.43777777777777777\n",
            "Epoch 5: train loss 1.4543980360031128, accuracy 0.47333333333333333\n",
            "Epoch 5: train loss 1.5734143786960177, accuracy 0.42444444444444446\n",
            "Epoch 5: train loss 1.3929453558391995, accuracy 0.47555555555555556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:09:32,218 | server.py:116 | fit progress: (25, 1.4134849882125855, {'accuracy': 0.4913}, 451.42158075000043)\n",
            "INFO flower 2023-01-02 13:09:32,219 | server.py:163 | evaluate_round 25: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:09:32,219 | server.py:215 | fit_round 26: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.4134849882125855 / accuracy 0.4913\n",
            "[Client 0, round 26] fit, config: {'server_round': 26, 'local_epochs': 5, 'learning_rate': 0.19445533984978666}\n",
            "[Client 77, round 26] fit, config: {'server_round': 26, 'local_epochs': 5, 'learning_rate': 0.19445533984978666}\n",
            "[Client 98, round 26] fit, config: {'server_round': 26, 'local_epochs': 5, 'learning_rate': 0.19445533984978666}\n",
            "[Client 33, round 26] fit, config: {'server_round': 26, 'local_epochs': 5, 'learning_rate': 0.19445533984978666}\n",
            "[Client 69, round 26] fit, config: {'server_round': 26, 'local_epochs': 5, 'learning_rate': 0.19445533984978666}\n",
            "[Client 82, round 26] fit, config: {'server_round': 26, 'local_epochs': 5, 'learning_rate': 0.19445533984978666}\n",
            "[Client 53, round 26] fit, config: {'server_round': 26, 'local_epochs': 5, 'learning_rate': 0.19445533984978666}\n",
            "[Client 71, round 26] fit, config: {'server_round': 26, 'local_epochs': 5, 'learning_rate': 0.19445533984978666}\n",
            "[Client 80, round 26] fit, config: {'server_round': 26, 'local_epochs': 5, 'learning_rate': 0.19445533984978666}\n",
            "[Client 47, round 26] fit, config: {'server_round': 26, 'local_epochs': 5, 'learning_rate': 0.19445533984978666}\n",
            "Epoch 1: train loss 1.5592462221781414, accuracy 0.42444444444444446\n",
            "Epoch 1: train loss 1.5028239091237385, accuracy 0.4311111111111111\n",
            "Epoch 1: train loss 1.5297584533691406, accuracy 0.4288888888888889\n",
            "Epoch 1: train loss 1.5400621228747897, accuracy 0.4266666666666667\n",
            "Epoch 1: train loss 1.64273915025923, accuracy 0.3933333333333333\n",
            "Epoch 1: train loss 1.6318773825963337, accuracy 0.40444444444444444\n",
            "Epoch 1: train loss 1.6656534141964383, accuracy 0.4066666666666667\n",
            "Epoch 1: train loss 1.6329591936535306, accuracy 0.36666666666666664\n",
            "Epoch 1: train loss 1.6159679889678955, accuracy 0.4222222222222222\n",
            "Epoch 1: train loss 1.5127822558085124, accuracy 0.45111111111111113\n",
            "Epoch 2: train loss 1.5075577100118, accuracy 0.44666666666666666\n",
            "Epoch 2: train loss 1.6245839728249445, accuracy 0.3933333333333333\n",
            "Epoch 2: train loss 1.5329034063551161, accuracy 0.43555555555555553\n",
            "Epoch 2: train loss 1.4815761778089735, accuracy 0.47333333333333333\n",
            "Epoch 2: train loss 1.569539917839898, accuracy 0.4111111111111111\n",
            "Epoch 2: train loss 1.4631401432885065, accuracy 0.4688888888888889\n",
            "Epoch 2: train loss 1.6553392940097384, accuracy 0.3977777777777778\n",
            "Epoch 2: train loss 1.5523388385772705, accuracy 0.39555555555555555\n",
            "Epoch 2: train loss 1.6377492215898302, accuracy 0.4111111111111111\n",
            "Epoch 2: train loss 1.5289485587014093, accuracy 0.42444444444444446\n",
            "Epoch 3: train loss 1.497829066382514, accuracy 0.44\n",
            "Epoch 3: train loss 1.5618245601654053, accuracy 0.40444444444444444\n",
            "Epoch 3: train loss 1.43907802634769, accuracy 0.4688888888888889\n",
            "Epoch 3: train loss 1.4587131871117487, accuracy 0.46\n",
            "Epoch 3: train loss 1.404458483060201, accuracy 0.49333333333333335\n",
            "Epoch 3: train loss 1.5763540135489569, accuracy 0.4266666666666667\n",
            "Epoch 3: train loss 1.627135780122545, accuracy 0.4111111111111111\n",
            "Epoch 3: train loss 1.5153318643569946, accuracy 0.4777777777777778\n",
            "Epoch 3: train loss 1.5147522158092923, accuracy 0.4288888888888889\n",
            "Epoch 3: train loss 1.524174729983012, accuracy 0.4222222222222222\n",
            "Epoch 4: train loss 1.4421837859683566, accuracy 0.47555555555555556\n",
            "Epoch 4: train loss 1.4889064762327406, accuracy 0.4222222222222222\n",
            "Epoch 4: train loss 1.3476206594043307, accuracy 0.49777777777777776\n",
            "Epoch 4: train loss 1.4602637026045058, accuracy 0.4266666666666667\n",
            "Epoch 4: train loss 1.4644842280281916, accuracy 0.47555555555555556\n",
            "Epoch 4: train loss 1.6273139317830403, accuracy 0.38\n",
            "Epoch 4: train loss 1.5063383314344618, accuracy 0.4444444444444444\n",
            "Epoch 4: train loss 1.6274712483088176, accuracy 0.3888888888888889\n",
            "Epoch 4: train loss 1.5388051403893366, accuracy 0.41333333333333333\n",
            "Epoch 4: train loss 1.437375585238139, accuracy 0.44222222222222224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:09:46,515 | server.py:229 | fit_round 26 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.528459495968289, accuracy 0.44222222222222224\n",
            "Epoch 5: train loss 1.549384872118632, accuracy 0.43555555555555553\n",
            "Epoch 5: train loss 1.4023930099275377, accuracy 0.4777777777777778\n",
            "Epoch 5: train loss 1.4999072684182062, accuracy 0.46444444444444444\n",
            "Epoch 5: train loss 1.4506035380893283, accuracy 0.44\n",
            "Epoch 5: train loss 1.498450689845615, accuracy 0.43555555555555553\n",
            "Epoch 5: train loss 1.4338156249788072, accuracy 0.4688888888888889\n",
            "Epoch 5: train loss 1.4265318579143949, accuracy 0.4622222222222222\n",
            "Epoch 5: train loss 1.504269414477878, accuracy 0.43333333333333335\n",
            "Epoch 5: train loss 1.5574414200252957, accuracy 0.42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:09:49,137 | server.py:116 | fit progress: (26, 1.40368508040905, {'accuracy': 0.4968}, 468.33995079600027)\n",
            "INFO flower 2023-01-02 13:09:49,137 | server.py:163 | evaluate_round 26: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:09:49,138 | server.py:215 | fit_round 27: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.40368508040905 / accuracy 0.4968\n",
            "[Client 16, round 27] fit, config: {'server_round': 27, 'local_epochs': 5, 'learning_rate': 0.19251078645128877}\n",
            "[Client 53, round 27] fit, config: {'server_round': 27, 'local_epochs': 5, 'learning_rate': 0.19251078645128877}\n",
            "[Client 4, round 27] fit, config: {'server_round': 27, 'local_epochs': 5, 'learning_rate': 0.19251078645128877}\n",
            "[Client 77, round 27] fit, config: {'server_round': 27, 'local_epochs': 5, 'learning_rate': 0.19251078645128877}\n",
            "[Client 44, round 27] fit, config: {'server_round': 27, 'local_epochs': 5, 'learning_rate': 0.19251078645128877}\n",
            "[Client 37, round 27] fit, config: {'server_round': 27, 'local_epochs': 5, 'learning_rate': 0.19251078645128877}\n",
            "[Client 88, round 27] fit, config: {'server_round': 27, 'local_epochs': 5, 'learning_rate': 0.19251078645128877}\n",
            "[Client 64, round 27] fit, config: {'server_round': 27, 'local_epochs': 5, 'learning_rate': 0.19251078645128877}\n",
            "[Client 0, round 27] fit, config: {'server_round': 27, 'local_epochs': 5, 'learning_rate': 0.19251078645128877}\n",
            "[Client 40, round 27] fit, config: {'server_round': 27, 'local_epochs': 5, 'learning_rate': 0.19251078645128877}\n",
            "Epoch 1: train loss 1.5453273322847154, accuracy 0.45111111111111113\n",
            "Epoch 1: train loss 1.4953390492333307, accuracy 0.4177777777777778\n",
            "Epoch 1: train loss 1.513329850302802, accuracy 0.44666666666666666\n",
            "Epoch 1: train loss 1.5864219400617812, accuracy 0.4022222222222222\n",
            "Epoch 1: train loss 1.5088743766148884, accuracy 0.41555555555555557\n",
            "Epoch 1: train loss 1.5600941843456693, accuracy 0.45555555555555555\n",
            "Epoch 1: train loss 1.5073021915223863, accuracy 0.4622222222222222\n",
            "Epoch 1: train loss 1.499272280269199, accuracy 0.4444444444444444\n",
            "Epoch 1: train loss 1.654196302096049, accuracy 0.37555555555555553\n",
            "Epoch 1: train loss 1.5181639989217122, accuracy 0.44222222222222224\n",
            "Epoch 2: train loss 1.5201525290807087, accuracy 0.4711111111111111\n",
            "Epoch 2: train loss 1.5271357430352106, accuracy 0.4688888888888889\n",
            "Epoch 2: train loss 1.4787495930989583, accuracy 0.44222222222222224\n",
            "Epoch 2: train loss 1.6235183477401733, accuracy 0.41333333333333333\n",
            "Epoch 2: train loss 1.489818228615655, accuracy 0.43777777777777777\n",
            "Epoch 2: train loss 1.4255242082807753, accuracy 0.45555555555555555\n",
            "Epoch 2: train loss 1.4712248510784574, accuracy 0.43555555555555553\n",
            "Epoch 2: train loss 1.4786260657840304, accuracy 0.44666666666666666\n",
            "Epoch 2: train loss 1.5140739811791315, accuracy 0.44222222222222224\n",
            "Epoch 2: train loss 1.4162554608450995, accuracy 0.48444444444444446\n",
            "Epoch 3: train loss 1.486600677172343, accuracy 0.4488888888888889\n",
            "Epoch 3: train loss 1.5151268508699205, accuracy 0.43555555555555553\n",
            "Epoch 3: train loss 1.5060725874371, accuracy 0.4533333333333333\n",
            "Epoch 3: train loss 1.583636654747857, accuracy 0.39555555555555555\n",
            "Epoch 3: train loss 1.5588786337110732, accuracy 0.42\n",
            "Epoch 3: train loss 1.4294492668575711, accuracy 0.4666666666666667\n",
            "Epoch 3: train loss 1.4596503973007202, accuracy 0.47333333333333333\n",
            "Epoch 3: train loss 1.5913944244384766, accuracy 0.44222222222222224\n",
            "Epoch 3: train loss 1.5045613050460815, accuracy 0.4488888888888889\n",
            "Epoch 3: train loss 1.4480513201819525, accuracy 0.4577777777777778\n",
            "Epoch 4: train loss 1.5139975945154827, accuracy 0.44666666666666666\n",
            "Epoch 4: train loss 1.4361373451020982, accuracy 0.4866666666666667\n",
            "Epoch 4: train loss 1.549546824561225, accuracy 0.4488888888888889\n",
            "Epoch 4: train loss 1.5124828550550673, accuracy 0.43777777777777777\n",
            "Epoch 4: train loss 1.5600395335091486, accuracy 0.4\n",
            "Epoch 4: train loss 1.4005451732211642, accuracy 0.43555555555555553\n",
            "Epoch 4: train loss 1.444529374440511, accuracy 0.45111111111111113\n",
            "Epoch 4: train loss 1.5025731060240004, accuracy 0.46444444444444444\n",
            "Epoch 4: train loss 1.41565121544732, accuracy 0.47555555555555556\n",
            "Epoch 4: train loss 1.4531198607550726, accuracy 0.45111111111111113\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:10:03,752 | server.py:229 | fit_round 27 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.4655913511912029, accuracy 0.45555555555555555\n",
            "Epoch 5: train loss 1.4395540820227728, accuracy 0.4777777777777778\n",
            "Epoch 5: train loss 1.3335306776894464, accuracy 0.4888888888888889\n",
            "Epoch 5: train loss 1.5378938515981038, accuracy 0.4177777777777778\n",
            "Epoch 5: train loss 1.614902138710022, accuracy 0.4177777777777778\n",
            "Epoch 5: train loss 1.4388269583384197, accuracy 0.46\n",
            "Epoch 5: train loss 1.410971588558621, accuracy 0.45555555555555555\n",
            "Epoch 5: train loss 1.466906295882331, accuracy 0.4577777777777778\n",
            "Epoch 5: train loss 1.397080871793959, accuracy 0.49333333333333335\n",
            "Epoch 5: train loss 1.4182633293999567, accuracy 0.4822222222222222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:10:06,446 | server.py:116 | fit progress: (27, 1.4024064886569976, {'accuracy': 0.4951}, 485.6492057710002)\n",
            "INFO flower 2023-01-02 13:10:06,446 | server.py:163 | evaluate_round 27: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:10:06,447 | server.py:215 | fit_round 28: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.4024064886569976 / accuracy 0.4951\n",
            "[Client 97, round 28] fit, config: {'server_round': 28, 'local_epochs': 5, 'learning_rate': 0.1905856785867759}\n",
            "[Client 0, round 28] fit, config: {'server_round': 28, 'local_epochs': 5, 'learning_rate': 0.1905856785867759}\n",
            "[Client 82, round 28] fit, config: {'server_round': 28, 'local_epochs': 5, 'learning_rate': 0.1905856785867759}\n",
            "[Client 37, round 28] fit, config: {'server_round': 28, 'local_epochs': 5, 'learning_rate': 0.1905856785867759}\n",
            "[Client 10, round 28] fit, config: {'server_round': 28, 'local_epochs': 5, 'learning_rate': 0.1905856785867759}\n",
            "[Client 92, round 28] fit, config: {'server_round': 28, 'local_epochs': 5, 'learning_rate': 0.1905856785867759}\n",
            "[Client 48, round 28] fit, config: {'server_round': 28, 'local_epochs': 5, 'learning_rate': 0.1905856785867759}\n",
            "[Client 23, round 28] fit, config: {'server_round': 28, 'local_epochs': 5, 'learning_rate': 0.1905856785867759}\n",
            "[Client 41, round 28] fit, config: {'server_round': 28, 'local_epochs': 5, 'learning_rate': 0.1905856785867759}\n",
            "[Client 78, round 28] fit, config: {'server_round': 28, 'local_epochs': 5, 'learning_rate': 0.1905856785867759}\n",
            "Epoch 1: train loss 1.4712389310201008, accuracy 0.45555555555555555\n",
            "Epoch 1: train loss 1.5433648692237005, accuracy 0.4288888888888889\n",
            "Epoch 1: train loss 1.6077818075815837, accuracy 0.4\n",
            "Epoch 1: train loss 1.4465730455186632, accuracy 0.47333333333333333\n",
            "Epoch 1: train loss 1.5801449484295316, accuracy 0.4311111111111111\n",
            "Epoch 1: train loss 1.5805000596576266, accuracy 0.4288888888888889\n",
            "Epoch 1: train loss 1.541408273908827, accuracy 0.4311111111111111\n",
            "Epoch 1: train loss 1.5837431616253324, accuracy 0.39555555555555555\n",
            "Epoch 1: train loss 1.5197980801264446, accuracy 0.44666666666666666\n",
            "Epoch 1: train loss 1.508751802974277, accuracy 0.43333333333333335\n",
            "Epoch 2: train loss 1.492949578497145, accuracy 0.42444444444444446\n",
            "Epoch 2: train loss 1.48103842470381, accuracy 0.44666666666666666\n",
            "Epoch 2: train loss 1.5535857280095418, accuracy 0.4222222222222222\n",
            "Epoch 2: train loss 1.4917541080050998, accuracy 0.4177777777777778\n",
            "Epoch 2: train loss 1.581175512737698, accuracy 0.4222222222222222\n",
            "Epoch 2: train loss 1.5472667084799872, accuracy 0.45111111111111113\n",
            "Epoch 2: train loss 1.5634317795435588, accuracy 0.4222222222222222\n",
            "Epoch 2: train loss 1.4934081236521404, accuracy 0.4288888888888889\n",
            "Epoch 2: train loss 1.4933017359839544, accuracy 0.4533333333333333\n",
            "Epoch 2: train loss 1.4779629839791193, accuracy 0.4444444444444444\n",
            "Epoch 3: train loss 1.4094507826699152, accuracy 0.5\n",
            "Epoch 3: train loss 1.3828152550591364, accuracy 0.4888888888888889\n",
            "Epoch 3: train loss 1.481000198258294, accuracy 0.4622222222222222\n",
            "Epoch 3: train loss 1.5581239859263103, accuracy 0.43333333333333335\n",
            "Epoch 3: train loss 1.5225396421220567, accuracy 0.44222222222222224\n",
            "Epoch 3: train loss 1.4832883675893147, accuracy 0.4666666666666667\n",
            "Epoch 3: train loss 1.4523481925328572, accuracy 0.4822222222222222\n",
            "Epoch 3: train loss 1.4056249724494085, accuracy 0.4955555555555556\n",
            "Epoch 3: train loss 1.4907850821812947, accuracy 0.41555555555555557\n",
            "Epoch 3: train loss 1.4504317707485623, accuracy 0.4444444444444444\n",
            "Epoch 4: train loss 1.4464210934109158, accuracy 0.4688888888888889\n",
            "Epoch 4: train loss 1.381659746170044, accuracy 0.4911111111111111\n",
            "Epoch 4: train loss 1.5249617099761963, accuracy 0.4444444444444444\n",
            "Epoch 4: train loss 1.5117504596710205, accuracy 0.4711111111111111\n",
            "Epoch 4: train loss 1.4459280570348103, accuracy 0.4711111111111111\n",
            "Epoch 4: train loss 1.4310616784625583, accuracy 0.5044444444444445\n",
            "Epoch 4: train loss 1.4692674742804632, accuracy 0.46444444444444444\n",
            "Epoch 4: train loss 1.434686369366116, accuracy 0.4666666666666667\n",
            "Epoch 4: train loss 1.4449713627497356, accuracy 0.4577777777777778\n",
            "Epoch 4: train loss 1.3880373239517212, accuracy 0.4911111111111111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:10:21,135 | server.py:229 | fit_round 28 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.4065014388826158, accuracy 0.46444444444444444\n",
            "Epoch 5: train loss 1.4032207197613187, accuracy 0.4711111111111111\n",
            "Epoch 5: train loss 1.5170626772774591, accuracy 0.44222222222222224\n",
            "Epoch 5: train loss 1.3998114267985027, accuracy 0.5\n",
            "Epoch 5: train loss 1.403125352329678, accuracy 0.4688888888888889\n",
            "Epoch 5: train loss 1.4650195704566107, accuracy 0.45111111111111113\n",
            "Epoch 5: train loss 1.4789629247453477, accuracy 0.46\n",
            "Epoch 5: train loss 1.4791232744852703, accuracy 0.4622222222222222\n",
            "Epoch 5: train loss 1.4077794816758897, accuracy 0.48\n",
            "Epoch 5: train loss 1.3727800183826022, accuracy 0.47333333333333333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:10:23,932 | server.py:116 | fit progress: (28, 1.3945075535774232, {'accuracy': 0.4975}, 503.1350990669998)\n",
            "INFO flower 2023-01-02 13:10:23,932 | server.py:163 | evaluate_round 28: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:10:23,933 | server.py:215 | fit_round 29: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.3945075535774232 / accuracy 0.4975\n",
            "[Client 56, round 29] fit, config: {'server_round': 29, 'local_epochs': 5, 'learning_rate': 0.18867982180090814}\n",
            "[Client 13, round 29] fit, config: {'server_round': 29, 'local_epochs': 5, 'learning_rate': 0.18867982180090814}\n",
            "[Client 76, round 29] fit, config: {'server_round': 29, 'local_epochs': 5, 'learning_rate': 0.18867982180090814}\n",
            "[Client 93, round 29] fit, config: {'server_round': 29, 'local_epochs': 5, 'learning_rate': 0.18867982180090814}\n",
            "[Client 95, round 29] fit, config: {'server_round': 29, 'local_epochs': 5, 'learning_rate': 0.18867982180090814}\n",
            "[Client 68, round 29] fit, config: {'server_round': 29, 'local_epochs': 5, 'learning_rate': 0.18867982180090814}\n",
            "[Client 51, round 29] fit, config: {'server_round': 29, 'local_epochs': 5, 'learning_rate': 0.18867982180090814}\n",
            "[Client 25, round 29] fit, config: {'server_round': 29, 'local_epochs': 5, 'learning_rate': 0.18867982180090814}\n",
            "[Client 81, round 29] fit, config: {'server_round': 29, 'local_epochs': 5, 'learning_rate': 0.18867982180090814}\n",
            "[Client 86, round 29] fit, config: {'server_round': 29, 'local_epochs': 5, 'learning_rate': 0.18867982180090814}\n",
            "Epoch 1: train loss 1.6000093221664429, accuracy 0.4488888888888889\n",
            "Epoch 1: train loss 1.52855118115743, accuracy 0.44666666666666666\n",
            "Epoch 1: train loss 1.5729778872595892, accuracy 0.4666666666666667\n",
            "Epoch 1: train loss 1.4197501341501872, accuracy 0.4533333333333333\n",
            "Epoch 1: train loss 1.4365369876225789, accuracy 0.45111111111111113\n",
            "Epoch 1: train loss 1.546626051266988, accuracy 0.4177777777777778\n",
            "Epoch 1: train loss 1.6382642984390259, accuracy 0.4622222222222222\n",
            "Epoch 1: train loss 1.6004243426852756, accuracy 0.44\n",
            "Epoch 1: train loss 1.557155794567532, accuracy 0.42444444444444446\n",
            "Epoch 1: train loss 1.5275724199083116, accuracy 0.4777777777777778\n",
            "Epoch 2: train loss 1.52467061413659, accuracy 0.4444444444444444Epoch 2: train loss 1.4591170416937933, accuracy 0.47333333333333333\n",
            "\n",
            "Epoch 2: train loss 1.502503792444865, accuracy 0.4777777777777778\n",
            "Epoch 2: train loss 1.4763632482952542, accuracy 0.43777777777777777\n",
            "Epoch 2: train loss 1.4591832160949707, accuracy 0.4777777777777778\n",
            "Epoch 2: train loss 1.5360214180416532, accuracy 0.42444444444444446\n",
            "Epoch 2: train loss 1.5728095637427435, accuracy 0.46444444444444444\n",
            "Epoch 2: train loss 1.5778670443428888, accuracy 0.43333333333333335\n",
            "Epoch 2: train loss 1.473501271671719, accuracy 0.43333333333333335\n",
            "Epoch 2: train loss 1.5143882698482938, accuracy 0.4666666666666667\n",
            "Epoch 3: train loss 1.436376028590732, accuracy 0.46444444444444444\n",
            "Epoch 3: train loss 1.4714929130342271, accuracy 0.47333333333333333\n",
            "Epoch 3: train loss 1.4542381366093953, accuracy 0.47555555555555556\n",
            "Epoch 3: train loss 1.4032787217034235, accuracy 0.48\n",
            "Epoch 3: train loss 1.4779505199856229, accuracy 0.47555555555555556\n",
            "Epoch 3: train loss 1.564081867535909, accuracy 0.41333333333333333\n",
            "Epoch 3: train loss 1.5353557401233249, accuracy 0.4311111111111111\n",
            "Epoch 3: train loss 1.368677510155572, accuracy 0.4666666666666667\n",
            "Epoch 3: train loss 1.4729735056559246, accuracy 0.45111111111111113\n",
            "Epoch 3: train loss 1.4899849494298298, accuracy 0.4866666666666667\n",
            "Epoch 4: train loss 1.418845123714871, accuracy 0.45111111111111113\n",
            "Epoch 4: train loss 1.3951442771487765, accuracy 0.5133333333333333\n",
            "Epoch 4: train loss 1.4428083499272664, accuracy 0.43555555555555553\n",
            "Epoch 4: train loss 1.5004526774088542, accuracy 0.4488888888888889\n",
            "Epoch 4: train loss 1.466840730773078, accuracy 0.48\n",
            "Epoch 4: train loss 1.501224398612976, accuracy 0.4444444444444444\n",
            "Epoch 4: train loss 1.445522599750095, accuracy 0.4533333333333333\n",
            "Epoch 4: train loss 1.5046108298831515, accuracy 0.42\n",
            "Epoch 4: train loss 1.4603738254970975, accuracy 0.4488888888888889\n",
            "Epoch 4: train loss 1.4654174248377483, accuracy 0.4822222222222222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:10:39,624 | server.py:229 | fit_round 29 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.6141634517245822, accuracy 0.42\n",
            "Epoch 5: train loss 1.4117594030168321, accuracy 0.4888888888888889\n",
            "Epoch 5: train loss 1.342003795835707, accuracy 0.48444444444444446\n",
            "Epoch 5: train loss 1.4768896102905273, accuracy 0.44\n",
            "Epoch 5: train loss 1.3976498312420316, accuracy 0.4866666666666667\n",
            "Epoch 5: train loss 1.3326694700453017, accuracy 0.5066666666666667\n",
            "Epoch 5: train loss 1.4675788746939764, accuracy 0.4777777777777778\n",
            "Epoch 5: train loss 1.54441233476003, accuracy 0.4311111111111111\n",
            "Epoch 5: train loss 1.4824403259489272, accuracy 0.4222222222222222\n",
            "Epoch 5: train loss 1.3856807284884982, accuracy 0.48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:10:42,257 | server.py:116 | fit progress: (29, 1.384690603017807, {'accuracy': 0.5065}, 521.4600773799993)\n",
            "INFO flower 2023-01-02 13:10:42,257 | server.py:163 | evaluate_round 29: no clients selected, cancel\n",
            "DEBUG flower 2023-01-02 13:10:42,258 | server.py:215 | fit_round 30: strategy sampled 10 clients (out of 100)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.384690603017807 / accuracy 0.5065\n",
            "[Client 9, round 30] fit, config: {'server_round': 30, 'local_epochs': 5, 'learning_rate': 0.18679302358289904}\n",
            "[Client 24, round 30] fit, config: {'server_round': 30, 'local_epochs': 5, 'learning_rate': 0.18679302358289904}\n",
            "[Client 26, round 30] fit, config: {'server_round': 30, 'local_epochs': 5, 'learning_rate': 0.18679302358289904}\n",
            "[Client 92, round 30] fit, config: {'server_round': 30, 'local_epochs': 5, 'learning_rate': 0.18679302358289904}\n",
            "[Client 45, round 30] fit, config: {'server_round': 30, 'local_epochs': 5, 'learning_rate': 0.18679302358289904}\n",
            "[Client 54, round 30] fit, config: {'server_round': 30, 'local_epochs': 5, 'learning_rate': 0.18679302358289904}\n",
            "[Client 99, round 30] fit, config: {'server_round': 30, 'local_epochs': 5, 'learning_rate': 0.18679302358289904}\n",
            "[Client 61, round 30] fit, config: {'server_round': 30, 'local_epochs': 5, 'learning_rate': 0.18679302358289904}\n",
            "[Client 36, round 30] fit, config: {'server_round': 30, 'local_epochs': 5, 'learning_rate': 0.18679302358289904}\n",
            "[Client 83, round 30] fit, config: {'server_round': 30, 'local_epochs': 5, 'learning_rate': 0.18679302358289904}\n",
            "Epoch 1: train loss 1.5280056397120159, accuracy 0.46\n",
            "Epoch 1: train loss 1.5596435334947374, accuracy 0.43777777777777777\n",
            "Epoch 1: train loss 1.549019906255934, accuracy 0.4088888888888889\n",
            "Epoch 1: train loss 1.6292895078659058, accuracy 0.3888888888888889\n",
            "Epoch 1: train loss 1.5119237105051677, accuracy 0.47555555555555556\n",
            "Epoch 1: train loss 1.5077046023474798, accuracy 0.44666666666666666\n",
            "Epoch 1: train loss 1.4742665820651584, accuracy 0.4666666666666667\n",
            "Epoch 1: train loss 1.5600954824023776, accuracy 0.41333333333333333\n",
            "Epoch 1: train loss 1.4987019565370348, accuracy 0.4444444444444444\n",
            "Epoch 1: train loss 1.6260354386435614, accuracy 0.3977777777777778\n",
            "Epoch 2: train loss 1.58931475215488, accuracy 0.4088888888888889\n",
            "Epoch 2: train loss 1.580432693163554, accuracy 0.3977777777777778\n",
            "Epoch 2: train loss 1.4662575324376423, accuracy 0.45111111111111113\n",
            "Epoch 2: train loss 1.4641923242145114, accuracy 0.4666666666666667\n",
            "Epoch 2: train loss 1.4967755873998005, accuracy 0.4666666666666667\n",
            "Epoch 2: train loss 1.446948183907403, accuracy 0.45555555555555555\n",
            "Epoch 2: train loss 1.5028446780310736, accuracy 0.4022222222222222\n",
            "Epoch 2: train loss 1.4201269547144573, accuracy 0.48444444444444446\n",
            "Epoch 2: train loss 1.4626955191294353, accuracy 0.48444444444444446\n",
            "Epoch 2: train loss 1.5020533402760823, accuracy 0.4288888888888889\n",
            "Epoch 3: train loss 1.4235318104426067, accuracy 0.4911111111111111\n",
            "Epoch 3: train loss 1.4566551049550374, accuracy 0.4577777777777778\n",
            "Epoch 3: train loss 1.5614980591668024, accuracy 0.40444444444444444\n",
            "Epoch 3: train loss 1.517713361316257, accuracy 0.4711111111111111\n",
            "Epoch 3: train loss 1.4711702002419367, accuracy 0.47333333333333333\n",
            "Epoch 3: train loss 1.5253545575671725, accuracy 0.41333333333333333\n",
            "Epoch 3: train loss 1.3840267260869343, accuracy 0.5177777777777778\n",
            "Epoch 3: train loss 1.4445453882217407, accuracy 0.4488888888888889\n",
            "Epoch 3: train loss 1.466184311442905, accuracy 0.46444444444444444\n",
            "Epoch 3: train loss 1.600761718220181, accuracy 0.43777777777777777\n",
            "Epoch 4: train loss 1.3603809807035658, accuracy 0.49777777777777776\n",
            "Epoch 4: train loss 1.5058757596545749, accuracy 0.4488888888888889\n",
            "Epoch 4: train loss 1.5326384703318279, accuracy 0.42\n",
            "Epoch 4: train loss 1.415664792060852, accuracy 0.48\n",
            "Epoch 4: train loss 1.4359996716181438, accuracy 0.4622222222222222\n",
            "Epoch 4: train loss 1.36559972498152, accuracy 0.5\n",
            "Epoch 4: train loss 1.4257357385423448, accuracy 0.4666666666666667\n",
            "Epoch 4: train loss 1.4452389346228705, accuracy 0.45555555555555555\n",
            "Epoch 4: train loss 1.507441308763292, accuracy 0.45555555555555555\n",
            "Epoch 4: train loss 1.4392445882161458, accuracy 0.46444444444444444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flower 2023-01-02 13:10:56,963 | server.py:229 | fit_round 30 received 10 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss 1.4444191985660129, accuracy 0.4533333333333333\n",
            "Epoch 5: train loss 1.3792986869812012, accuracy 0.4955555555555556\n",
            "Epoch 5: train loss 1.4568883975346882, accuracy 0.45555555555555555\n",
            "Epoch 5: train loss 1.384166677792867, accuracy 0.5022222222222222\n",
            "Epoch 5: train loss 1.553785628742642, accuracy 0.4111111111111111\n",
            "Epoch 5: train loss 1.4523183107376099, accuracy 0.4822222222222222\n",
            "Epoch 5: train loss 1.4010872178607516, accuracy 0.4711111111111111\n",
            "Epoch 5: train loss 1.4717725780275133, accuracy 0.43555555555555553\n",
            "Epoch 5: train loss 1.3967507017983332, accuracy 0.4533333333333333\n",
            "Epoch 5: train loss 1.3530786964628432, accuracy 0.5044444444444445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flower 2023-01-02 13:10:59,533 | server.py:116 | fit progress: (30, 1.3758857941627503, {'accuracy': 0.5074}, 538.7369124489996)\n",
            "INFO flower 2023-01-02 13:10:59,534 | server.py:163 | evaluate_round 30: no clients selected, cancel\n",
            "INFO flower 2023-01-02 13:10:59,535 | server.py:144 | FL finished in 538.7381432809998\n",
            "INFO flower 2023-01-02 13:10:59,536 | app.py:180 | app_fit: losses_distributed []\n",
            "INFO flower 2023-01-02 13:10:59,536 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO flower 2023-01-02 13:10:59,537 | app.py:182 | app_fit: losses_centralized [(0, 2.30655566573143), (1, 2.1898021697998047), (2, 2.0629611456394197), (3, 2.0181534522771836), (4, 1.9932282614707946), (5, 1.9428342407941819), (6, 1.9086399233341218), (7, 1.937952494621277), (8, 1.7613398510217666), (9, 1.7244032686948776), (10, 1.7422066110372543), (11, 1.696931614279747), (12, 1.6355706119537354), (13, 1.604927464723587), (14, 1.594452024102211), (15, 1.5789094483852386), (16, 1.5227009838819503), (17, 1.5273851621150971), (18, 1.4979898434877397), (19, 1.4835423177480698), (20, 1.4820896822214127), (21, 1.4764712953567505), (22, 1.4415018260478973), (23, 1.4402703523635865), (24, 1.4257594925165176), (25, 1.4134849882125855), (26, 1.40368508040905), (27, 1.4024064886569976), (28, 1.3945075535774232), (29, 1.384690603017807), (30, 1.3758857941627503)]\n",
            "INFO flower 2023-01-02 13:10:59,537 | app.py:183 | app_fit: metrics_centralized {'accuracy': [(0, 0.1), (1, 0.1751), (2, 0.2207), (3, 0.2438), (4, 0.2604), (5, 0.2868), (6, 0.3141), (7, 0.2845), (8, 0.3668), (9, 0.3858), (10, 0.3839), (11, 0.3896), (12, 0.4121), (13, 0.4217), (14, 0.4148), (15, 0.4274), (16, 0.4461), (17, 0.442), (18, 0.4534), (19, 0.4596), (20, 0.4585), (21, 0.4629), (22, 0.4801), (23, 0.4813), (24, 0.486), (25, 0.4913), (26, 0.4968), (27, 0.4951), (28, 0.4975), (29, 0.5065), (30, 0.5074)]}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Server-side evaluation loss 1.3758857941627503 / accuracy 0.5074\n"
          ]
        }
      ],
      "source": [
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=FRACTION_FIT,              # Train on 10 clients (each round)\n",
        "    fraction_evaluate=FRACTION_EVAL,        # Evaluate on 50 clients (each round)\n",
        "    min_fit_clients=int(NUM_CLIENTS * FRACTION_FIT),\n",
        "    min_evaluate_clients=int(NUM_CLIENTS * FRACTION_EVAL),\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=initial_parameters,  # Pass the initial parameters\n",
        "    on_fit_config_fn=fit_config,            # Pass the fit_config function\n",
        "    evaluate_fn=evaluate,                   # Pass the evaluation function\n",
        ")\n",
        "\n",
        "history = start_simulation(\n",
        "    strategy=strategy,\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=NUM_ROUNDS),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "iZLAeVlRk_gv",
        "outputId": "51c46718-07bf-4bf0-9444-97b66f6e8630"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7b5cf49cc0>]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot([v for _, v in history.losses_centralized])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "uwmF_IKBQLg6",
        "outputId": "d7984e96-eaad-4113-cba5-f730519e5c5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7b5d6d1330>]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot([v for _, v in history.metrics_centralized[\"accuracy\"]])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "f4e66fa4acf8f75cb7e5bf746b87cb26119baafbc935380f682e62cbdd8df510"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
