{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFTvemfOWVAQ"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/passerim/peer-reviewed-flower.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTrCL2FmC5U5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "from typing import Callable, Dict, List, Optional, Tuple\n",
        "\n",
        "import flwr as fl\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from flwr.common import (\n",
        "    EvaluateIns,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    MetricsAggregationFn,\n",
        "    Parameters,\n",
        "    Scalar,\n",
        "    Weights,\n",
        "    parameters_to_weights,\n",
        "    weights_to_parameters\n",
        ")\n",
        "from flwr.server.client_manager import ClientManager, SimpleClientManager\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
        "from prflwr.peer_review import PeerReviewClient\n",
        "from prflwr.peer_review import PeerReviewServer\n",
        "from prflwr.peer_review.strategy import PeerReviewStrategy\n",
        "from prflwr.peer_review.strategy import (\n",
        "    AggregateTrainException,\n",
        "    AggregateReviewException,\n",
        "    ConfigureReviewException,\n",
        ")\n",
        "from prflwr.simulation import start_simulation\n",
        "from prflwr.utils import import_dataset_utils\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "from torchvision import datasets\n",
        "\n",
        "import_dataset_utils()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpLBow6s-CNy"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4bKI8oK2Ubx"
      },
      "outputs": [],
      "source": [
        "# Setting random seed for reproducibility\n",
        "SEED = 123\n",
        "set_seed(SEED)\n",
        "\n",
        "DATASET = \"CIFAR10\"  # possible values: \"CIFAR10\" or \"CIFAR100\"\n",
        "NUM_EPOCHS = 50\n",
        "NUM_CLIENTS = 50\n",
        "LOCAL_EPOCHS = 2\n",
        "BATCH_SIZE = 32\n",
        "FRACTION_REV = 1 / 4\n",
        "FRACTION_FIT = 1 / 4\n",
        "FRACTION_EVAL = 0\n",
        "NUM_ROUNDS = int(NUM_EPOCHS // (LOCAL_EPOCHS * FRACTION_FIT))\n",
        "REVIEW_SCORE = \"review_score\"\n",
        "\n",
        "# Device to use for training and evaluation\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "print(f\"Training on {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4Em7BPNTXeX"
      },
      "outputs": [],
      "source": [
        "def load_datasets(\n",
        "    num_clients: int, \n",
        "    dataset: str = \"CIFAR10\",\n",
        "    src: str = \".\",\n",
        "    iid: bool = True,\n",
        "    concentration: float = 1,\n",
        "    use_augmentation: bool = False\n",
        ") -> Tuple[List[DataLoader], List[DataLoader], DataLoader]:\n",
        "    if dataset not in [\"CIFAR10\", \"CIFAR100\"]:\n",
        "        raise ValueError(\n",
        "            \"Unknown dataset! Admissible values are: 'CIFAR10' or 'CIFAR100'.\"\n",
        "        )\n",
        "\n",
        "    # Download and transform CIFAR dataset (train and test)\n",
        "    augmentation = [\n",
        "        transforms.Pad(4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(32),\n",
        "    ] if use_augmentation else []\n",
        "    transform = [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ]\n",
        "    trainset = getattr(datasets, dataset)(\n",
        "        os.path.join(src, \"./data\"),\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([*augmentation, *transform]),\n",
        "    )\n",
        "    testset = getattr(datasets, dataset)(\n",
        "        os.path.join(src, \"./data\"),\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([*transform]),\n",
        "    )\n",
        "\n",
        "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
        "    if not iid:\n",
        "        targets = np.array(trainset.targets)\n",
        "        idxs = np.array(range(len(targets)))\n",
        "        dataset = [idxs, targets]\n",
        "        train_partitions, _ = fl.dataset.utils.common.create_lda_partitions(\n",
        "            dataset,\n",
        "            num_partitions=num_clients,\n",
        "            concentration=concentration,\n",
        "            accept_imbalanced=False,\n",
        "        )\n",
        "        subsets = list(map(lambda p: Subset(trainset, p[0]), train_partitions))\n",
        "    else:\n",
        "        partition_size = len(trainset) // num_clients\n",
        "        lengths = [partition_size] * num_clients\n",
        "        subsets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in subsets:\n",
        "        len_val = len(ds) // 10  # 10 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "    return trainloaders, valloaders, testloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2X3cVBXMpP6w"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes: int) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(512, 64)\n",
        "        self.fc2 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 512)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss.item() * labels.size(0)\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= total\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net: nn.Module, testloader: DataLoader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item() * labels.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= total\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPeFWwyFrY9f"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS, DATASET)\n",
        "NUM_CLASSES = len(np.unique(testloader.dataset.targets))\n",
        "\n",
        "# Create an instance of the model\n",
        "net = Net(NUM_CLASSES).to(DEVICE)\n",
        "with torch.no_grad():\n",
        "    assert net(torch.randn((3, 32, 32), device=DEVICE)).shape == torch.Size(\n",
        "        [1, NUM_CLASSES]\n",
        "    )\n",
        "\n",
        "# Print some stats about the model and the data\n",
        "print(\"Model parameters:\", sum(p.numel() for p in net.parameters() if p.requires_grad))\n",
        "print(\"Client's trainset size:\", len(trainloaders[0].dataset))\n",
        "print(\"Client's validation set size:\", len(valloaders[0].dataset))\n",
        "print(\"Server's testset size:\", len(testloader.dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZH3f2rt7h-Ih"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(PeerReviewClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def train(self, parameters, config):\n",
        "        # Read values from config\n",
        "        current_round = config[\"current_round\"]\n",
        "        local_epochs = config[\"local_epochs\"]\n",
        "        # Use values provided by the config\n",
        "        print(f\"[Client {self.cid}, round {current_round}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, local_epochs)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def review(self, parameters, config):\n",
        "        # print(\"start review\", flush=True)\n",
        "        loss, num_examples, _ = self.evaluate(parameters, {})\n",
        "        # print(\"reviewed\", flush=True)\n",
        "        return [], num_examples, {REVIEW_SCORE: loss}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        # print(\"model loaded\", flush=True)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QP5CZ2yGXbb"
      },
      "outputs": [],
      "source": [
        "class FedLS(PeerReviewStrategy):\n",
        "    def __init__(\n",
        "        self,\n",
        "        max_review_rounds: int = 5,\n",
        "        max_step_size: float = 1,\n",
        "        min_step_size: float = 1e-3,\n",
        "        step_size_decay: float = 0.1,\n",
        "        gamma: float = 0,\n",
        "        fraction_review: float = 0.1,\n",
        "        fraction_fit: float = 0.1,\n",
        "        fraction_eval: float = 0.1,\n",
        "        min_review_clients: int = 2,\n",
        "        min_fit_clients: int = 2,\n",
        "        min_eval_clients: int = 2,\n",
        "        min_available_clients: int = 2,\n",
        "        eval_fn: Optional[\n",
        "            Callable[[Weights], Optional[Tuple[float, Dict[str, Scalar]]]]\n",
        "        ] = None,\n",
        "        on_review_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        accept_failures: bool = True,\n",
        "        initial_parameters: Optional[Parameters] = None,\n",
        "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "    ) -> None:\n",
        "        super(FedLS, self).__init__()\n",
        "\n",
        "        # Strategy adapter fields\n",
        "        self.max_review_rounds = max_review_rounds\n",
        "        self.max_step_size = max_step_size\n",
        "        self.min_step_size = min_step_size\n",
        "        self.step_size_decay = step_size_decay\n",
        "        self.gamma = gamma\n",
        "        self.step_size: float = 0.0\n",
        "        self.current_loss: float = np.inf\n",
        "        self.candidate_loss: float = np.inf\n",
        "\n",
        "        # Strategy adapter fields\n",
        "        self.fraction_review = fraction_review\n",
        "        self.min_review_clients = min_review_clients\n",
        "        self.on_review_config_fn = on_review_config_fn\n",
        "        self.fedavg = FedAvg(\n",
        "            fraction_fit=fraction_fit,\n",
        "            fraction_eval=fraction_eval,\n",
        "            min_fit_clients=min_fit_clients,\n",
        "            min_eval_clients=min_eval_clients,\n",
        "            min_available_clients=min_available_clients,\n",
        "            eval_fn=eval_fn,\n",
        "            on_fit_config_fn=on_fit_config_fn,\n",
        "            on_evaluate_config_fn=on_evaluate_config_fn,\n",
        "            accept_failures=accept_failures,\n",
        "            initial_parameters=initial_parameters,\n",
        "            fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,\n",
        "            evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,\n",
        "        )\n",
        "\n",
        "    def num_review_clients(self, num_available_clients: int):\n",
        "        \"\"\"Return the sample size and the required number of available\n",
        "        clients.\"\"\"\n",
        "        num_clients = int(num_available_clients * self.fraction_review)\n",
        "        return (\n",
        "            max(num_clients, self.min_review_clients),\n",
        "            self.fedavg.min_available_clients,\n",
        "        )\n",
        "\n",
        "    # Standard strategy\n",
        "    def initialize_parameters(\n",
        "        self, client_manager: ClientManager\n",
        "    ) -> Optional[Parameters]:\n",
        "        return self.fedavg.initialize_parameters(client_manager)\n",
        "\n",
        "    def configure_evaluate(\n",
        "        self, rnd: int, parameters, client_manager: ClientManager\n",
        "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
        "        return self.fedavg.configure_evaluate(rnd, parameters, client_manager)\n",
        "\n",
        "    def aggregate_evaluate(\n",
        "        self,\n",
        "        rnd: int,\n",
        "        results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: BaseException,\n",
        "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
        "        loss, metrics = self.fedavg.aggregate_evaluate(rnd, results, failures)\n",
        "        self.current_loss = loss\n",
        "        return loss, metrics\n",
        "\n",
        "    def evaluate(\n",
        "        self, parameters: Parameters\n",
        "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
        "        loss, metrics = self.fedavg.evaluate(parameters)\n",
        "        self.current_loss = loss\n",
        "        return loss, metrics\n",
        "\n",
        "    # Multiple reviews strategy\n",
        "    def configure_train(\n",
        "        self, rnd: int, parameters: Parameters, client_manager: ClientManager\n",
        "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
        "        print(f\"Round: {rnd}, configure_train\")\n",
        "        self.step_size = self.max_step_size\n",
        "        return self.fedavg.configure_fit(rnd, parameters, client_manager)\n",
        "\n",
        "    def aggregate_train(\n",
        "        self,\n",
        "        rnd: int,\n",
        "        results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[BaseException],\n",
        "        parameters: Optional[Parameters],\n",
        "    ) -> List[Tuple[Optional[Parameters], Dict[str, Scalar]]]:\n",
        "        print(f\"Round: {rnd}, aggregate_train\")\n",
        "        if not results:\n",
        "            raise AggregateTrainException\n",
        "\n",
        "        # Do not aggregate if there are failures and failures are not accepted\n",
        "        if not self.fedavg.accept_failures and failures:\n",
        "            raise AggregateTrainException\n",
        "\n",
        "        # Convert results\n",
        "        weights_aggregated = aggregate(\n",
        "            [\n",
        "                (parameters_to_weights(fit_res.parameters), fit_res.num_examples)\n",
        "                for _, fit_res in results\n",
        "            ]\n",
        "        )\n",
        "        current_weights = parameters_to_weights(parameters)\n",
        "        gradient = [\n",
        "            weights_aggregated[i] - current_weights[i]\n",
        "            for i in range(len(weights_aggregated))\n",
        "        ]\n",
        "        gradient_params = weights_to_parameters(gradient)\n",
        "        del weights_aggregated, current_weights, gradient\n",
        "        return [(gradient_params, {})]\n",
        "\n",
        "    def configure_review(\n",
        "        self,\n",
        "        rnd: int,\n",
        "        review_rnd: int,\n",
        "        parameters: Parameters,\n",
        "        client_manager: ClientManager,\n",
        "        parameters_aggregated: List[Optional[Parameters]],\n",
        "        metrics_aggregated: List[Dict[str, Scalar]],\n",
        "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
        "        # Do not configure federated review if fraction_review is 0\n",
        "        if self.fraction_review == 0.0:\n",
        "            raise ConfigureReviewException\n",
        "\n",
        "        # Parameters and config\n",
        "        config = {}\n",
        "        if self.on_review_config_fn is not None:\n",
        "            # Custom fit config function provided\n",
        "            config = self.on_review_config_fn(rnd, review_rnd)\n",
        "\n",
        "        # Prepare review instructions\n",
        "        gradient = parameters_to_weights(parameters_aggregated[0])\n",
        "        current_weights = parameters_to_weights(parameters)\n",
        "        self.step_size = max(\n",
        "            self.min_step_size,\n",
        "            self.max_step_size * (self.step_size_decay ** (review_rnd - 1)),\n",
        "        )\n",
        "        weights = [\n",
        "            gradient[i] * self.step_size + current_weights[i]\n",
        "            for i in range(len(gradient))\n",
        "        ]\n",
        "        review_ins = FitIns(weights_to_parameters(weights), config)\n",
        "\n",
        "        # Sample clients\n",
        "        sample_size, min_num_clients = self.num_review_clients(\n",
        "            client_manager.num_available()\n",
        "        )\n",
        "        clients = client_manager.sample(\n",
        "            num_clients=sample_size, min_num_clients=min_num_clients\n",
        "        )\n",
        "\n",
        "        del weights, gradient, current_weights\n",
        "        print(\n",
        "            f\"Round: {rnd}, review_round: {review_rnd}, configure_review, step_size: {self.step_size}\"\n",
        "        )\n",
        "        # Return client/config pairs\n",
        "        return [(client, review_ins) for client in clients]\n",
        "\n",
        "    def aggregate_review(\n",
        "        self,\n",
        "        rnd: int,\n",
        "        review_rnd: int,\n",
        "        results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[BaseException],\n",
        "        parameters: Parameters,\n",
        "        parameters_aggregated: List[Optional[Parameters]],\n",
        "        metrics_aggregated: List[Dict[str, Scalar]],\n",
        "    ) -> List[Tuple[Optional[Parameters], Dict[str, Scalar]]]:\n",
        "        print(f\"Round: {rnd}, aggregate_review\")\n",
        "        if not results:\n",
        "            raise AggregateReviewException\n",
        "\n",
        "        # Do not aggregate if there are failures and failures are not accepted\n",
        "        if not self.fedavg.accept_failures and failures:\n",
        "            raise AggregateReviewException\n",
        "\n",
        "        # Aggregate results\n",
        "        aggregated_loss = weighted_loss_avg(\n",
        "            [\n",
        "                (review_res.num_examples, review_res.metrics[REVIEW_SCORE])\n",
        "                for _, review_res in results\n",
        "            ]\n",
        "        )\n",
        "        self.candidate_loss = aggregated_loss\n",
        "        return list(zip(parameters_aggregated, metrics_aggregated))\n",
        "\n",
        "    def aggregate_after_review(\n",
        "        self,\n",
        "        rnd: int,\n",
        "        parameters_aggregated: List[Optional[Parameters]],\n",
        "        metrics_aggregated: List[Dict[str, Scalar]],\n",
        "        parameters: Optional[Parameters],\n",
        "    ) -> Optional[Parameters]:\n",
        "        print(f\"Round: {rnd}, aggregate_after_review\")\n",
        "        current_weights = parameters_to_weights(parameters)\n",
        "        gradient = parameters_to_weights(parameters_aggregated[0])\n",
        "\n",
        "        # Compute update\n",
        "        for j, tensor in enumerate(gradient):\n",
        "            current_weights[j] += self.step_size * gradient[j]\n",
        "        print(f\"Round {rnd}: lr {self.step_size}\")\n",
        "\n",
        "        # Return\n",
        "        parameters_prime = weights_to_parameters(current_weights)\n",
        "        del current_weights, gradient\n",
        "        return parameters_prime\n",
        "\n",
        "    def stop_review(\n",
        "        self,\n",
        "        rnd: int,\n",
        "        review_rnd: int,\n",
        "        parameters: Parameters,\n",
        "        client_manager: ClientManager,\n",
        "        parameters_aggregated: List[Optional[Parameters]],\n",
        "        metrics_aggregated: List[Dict[str, Scalar]],\n",
        "    ) -> bool:\n",
        "        print(\n",
        "            f\"Round: {rnd}, review_rnd: {review_rnd}, stop_review, candidate loss: {self.candidate_loss}\"\n",
        "        )\n",
        "        gradient = parameters_to_weights(parameters_aggregated[0])\n",
        "        if self.candidate_loss <= (\n",
        "            self.current_loss\n",
        "            - self.gamma\n",
        "            * self.step_size\n",
        "            * sum(map(lambda x: np.linalg.norm(x) ** 2, gradient))\n",
        "        ):\n",
        "            del gradient\n",
        "            return True\n",
        "        else:\n",
        "            del gradient\n",
        "            if (self.step_size > self.min_step_size) and (\n",
        "                review_rnd < (self.max_review_rounds + 1)\n",
        "            ):\n",
        "                return False\n",
        "            else:\n",
        "                return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfZ5cDTNF_WC"
      },
      "outputs": [],
      "source": [
        "def client_fn(cid) -> FlowerClient:\n",
        "    net = Net(NUM_CLASSES).to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader)\n",
        "\n",
        "\n",
        "def evaluate(\n",
        "    weights: fl.common.Weights,\n",
        ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "    net = Net(NUM_CLASSES).to(DEVICE)\n",
        "    set_parameters(net, weights)  # Update model with the latest parameters\n",
        "    loss, accuracy = test(net, testloader)\n",
        "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
        "    return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "\n",
        "def review_config(rnd: int, review_rnd: int):\n",
        "    return {\"rnd\": rnd, \"review_rnd\": review_rnd}\n",
        "\n",
        "\n",
        "def fit_config(rnd: int):\n",
        "    \"\"\"Return training configuration dict for each round.\n",
        "\n",
        "    Perform two rounds of training with one local epoch, increase to two local\n",
        "    epochs afterwards.\n",
        "    \"\"\"\n",
        "    config = {\n",
        "        \"current_round\": rnd,  # The current round of federated learning\n",
        "        \"local_epochs\": 1 if rnd < 2 else LOCAL_EPOCHS,  #\n",
        "    }\n",
        "    return config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g7jVivPma00"
      },
      "outputs": [],
      "source": [
        "strategy = FedLS(\n",
        "    fraction_review=FRACTION_REV,\n",
        "    fraction_fit=FRACTION_FIT,\n",
        "    fraction_eval=FRACTION_EVAL,\n",
        "    min_review_clients=int(FRACTION_REV * NUM_CLIENTS),\n",
        "    min_fit_clients=int(FRACTION_FIT * NUM_CLIENTS),\n",
        "    min_eval_clients=int(FRACTION_EVAL * NUM_CLIENTS),\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=fl.common.weights_to_parameters(get_parameters(net)),\n",
        "    on_fit_config_fn=fit_config,\n",
        "    on_review_config_fn=review_config,\n",
        "    eval_fn=evaluate,\n",
        ")\n",
        "client_manager = SimpleClientManager()\n",
        "\n",
        "start_simulation(\n",
        "    server=PeerReviewServer(client_manager, strategy),\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    num_rounds=NUM_ROUNDS,\n",
        "    strategy=strategy,\n",
        "    client_manager=client_manager,\n",
        "    client_resources={\"num_cpus\": 1, \"num_gpus\": 1},\n",
        "    ray_init_args={\"local_mode\": True, \"include_dashboard\": False}\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sim_fedls_gpu.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "567eb23278dc48458ee3370825b5f7f3a84494f863de725a2aacc447ea9c55e5"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 (conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
