{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UFTvemfOWVAQ",
        "outputId": "ea11f6aa-74ca-4b02-8139-fb1f9ac7bbdc"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/passerim/peer-reviewed-flower.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTrCL2FmC5U5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "import flwr as fl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from flwr.common import (\n",
        "    EvaluateRes,\n",
        "    EvaluateIns,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    MetricsAggregationFn,\n",
        "    Parameters,\n",
        "    Scalar,\n",
        "    NDArrays,\n",
        "    parameters_to_ndarrays,\n",
        "    ndarrays_to_parameters,\n",
        ")\n",
        "from flwr.server import ServerConfig\n",
        "from flwr.server.client_manager import ClientManager, SimpleClientManager\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg\n",
        "from flwr.simulation import start_simulation\n",
        "from overrides import overrides\n",
        "from prflwr.peer_review import PeerReviewClient\n",
        "from prflwr.peer_review import PeerReviewServer\n",
        "from prflwr.peer_review.strategy import PeerReviewStrategy\n",
        "from prflwr.peer_review.strategy import (\n",
        "    AggregateTrainException,\n",
        "    AggregateReviewException,\n",
        "    ConfigureReviewException,\n",
        ")\n",
        "from prflwr.utils import non_iid_partitions\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "from torchvision import datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpLBow6s-CNy"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4bKI8oK2Ubx",
        "outputId": "20764d7d-66f2-43b4-d1a2-ab1f4561e783"
      },
      "outputs": [],
      "source": [
        "# Setting random seed for reproducibility\n",
        "SEED = 123\n",
        "set_seed(SEED)\n",
        "\n",
        "DATASET = \"CIFAR10\"  # possible values: \"CIFAR10\" or \"CIFAR100\"\n",
        "NUM_EPOCHS = 50\n",
        "NUM_CLIENTS = 50\n",
        "LOCAL_EPOCHS = 2\n",
        "BATCH_SIZE = 32\n",
        "FRACTION_REV = 1 / 4\n",
        "FRACTION_FIT = 1 / 4\n",
        "FRACTION_EVAL = 0\n",
        "REVIEW_SCORE = \"review_score\"\n",
        "NUM_ROUNDS = int((NUM_EPOCHS // (LOCAL_EPOCHS * FRACTION_FIT)) * (1 + FRACTION_FIT))\n",
        "print(f\"Training for {NUM_ROUNDS} rounds\")\n",
        "\n",
        "# Device to use for training and evaluation\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "print(f\"Training on {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4Em7BPNTXeX"
      },
      "outputs": [],
      "source": [
        "def load_datasets(\n",
        "    num_clients: int,\n",
        "    dataset: str = \"CIFAR10\",\n",
        "    src: str = \".\",\n",
        "    iid: bool = True,\n",
        "    concentration: float = 1,\n",
        "    use_augmentation: bool = False,\n",
        ") -> Tuple[List[DataLoader], List[DataLoader], DataLoader]:\n",
        "    if dataset not in [\"CIFAR10\", \"CIFAR100\"]:\n",
        "        raise ValueError(\n",
        "            \"Unknown dataset! Admissible values are: 'CIFAR10' or 'CIFAR100'.\"\n",
        "        )\n",
        "\n",
        "    # Download and transform CIFAR dataset (train and test)\n",
        "    augmentation = (\n",
        "        [\n",
        "            transforms.Pad(4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomCrop(32),\n",
        "        ]\n",
        "        if use_augmentation\n",
        "        else []\n",
        "    )\n",
        "    transform = [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ]\n",
        "    trainset = getattr(datasets, dataset)(\n",
        "        os.path.join(src, \"./data\"),\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([*augmentation, *transform]),\n",
        "    )\n",
        "    testset = getattr(datasets, dataset)(\n",
        "        os.path.join(src, \"./data\"),\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([*transform]),\n",
        "    )\n",
        "\n",
        "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
        "    if not iid:\n",
        "        targets = np.array(trainset.targets)\n",
        "        idxs = np.array(range(len(targets)))\n",
        "        dataset = [idxs, targets]\n",
        "        train_partitions = non_iid_partitions(\n",
        "            dataset,\n",
        "            num_partitions=num_clients,\n",
        "            concentration=concentration,\n",
        "        )\n",
        "        subsets = list(map(lambda p: Subset(trainset, p), train_partitions))\n",
        "    else:\n",
        "        partition_size = len(trainset) // num_clients\n",
        "        lengths = [partition_size] * num_clients\n",
        "        subsets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in subsets:\n",
        "        len_val = len(ds) // 10  # 10 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "    return trainloaders, valloaders, testloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2X3cVBXMpP6w"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes: int) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(512, 64)\n",
        "        self.fc2 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 512)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss.item() * labels.size(0)\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= total\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net: nn.Module, testloader: DataLoader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item() * labels.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= total\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "0d733d3456094af386394b7fd2c03173",
            "468c9e8faee04203997eb8a4d73a3509",
            "57299616e5874f9a81b8749c114e8120",
            "e733490f85e14c27a96a8d6d8703ccb9",
            "c62a75920efe4340b87fa7a433ed7013",
            "754c794b2b0e47ecad43050323f8cc23",
            "8f0e5f89dd8449dca14e3772f7f7361d",
            "b082c7cc82cd41c9b9a5456da07de957",
            "67bf7b1829eb4f65ad0919c614618eb5",
            "69d735d80a2c4b2bbdfdd179c12c66b1",
            "9ec95ceabccc461184abce4aa7f502d4"
          ]
        },
        "id": "GPeFWwyFrY9f",
        "outputId": "71a450e3-584a-42e2-ceb9-8c59cc19b127"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "trainloaders, valloaders, testloader = load_datasets(\n",
        "    NUM_CLIENTS, DATASET, iid=False, concentration=0.1\n",
        ")\n",
        "NUM_CLASSES = len(np.unique(testloader.dataset.targets))\n",
        "\n",
        "# Create an instance of the model\n",
        "net = Net(NUM_CLASSES).to(DEVICE)\n",
        "with torch.no_grad():\n",
        "    assert net(torch.randn((3, 32, 32), device=DEVICE)).shape == torch.Size(\n",
        "        [1, NUM_CLASSES]\n",
        "    )\n",
        "\n",
        "# Print some stats about the model and the data\n",
        "print(\"Model parameters:\", sum(p.numel() for p in net.parameters() if p.requires_grad))\n",
        "print(\"Client's trainset size:\", len(trainloaders[0].dataset))\n",
        "print(\"Client's validation set size:\", len(valloaders[0].dataset))\n",
        "print(\"Server's testset size:\", len(testloader.dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "D2q3mW8eG2Lw",
        "outputId": "1e7083f7-5493-49f6-9bbc-8042e4c99d0a"
      },
      "outputs": [],
      "source": [
        "def histshow(loader):\n",
        "    plt.hist(torch.concat([labels for _, labels in iter(loader)]))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "histshow(trainloaders[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZH3f2rt7h-Ih"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(PeerReviewClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def train(self, parameters, config):\n",
        "        # Read values from config\n",
        "        current_round = config[\"current_round\"]\n",
        "        local_epochs = config[\"local_epochs\"]\n",
        "        # Use values provided by the config\n",
        "        print(f\"[Client {self.cid}, round {current_round}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, local_epochs)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def review(self, parameters, config):\n",
        "        loss, num_examples, _ = self.evaluate(parameters, {})\n",
        "        return [], num_examples, {REVIEW_SCORE: loss}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QP5CZ2yGXbb"
      },
      "outputs": [],
      "source": [
        "class FedLS(PeerReviewStrategy):\n",
        "    def __init__(\n",
        "        self,\n",
        "        max_review_rounds: int = 5,\n",
        "        max_step_size: float = 1,\n",
        "        min_step_size: float = 1e-3,\n",
        "        step_size_decay: float = 0.1,\n",
        "        gamma: float = 0,\n",
        "        fraction_review: float = 0.1,\n",
        "        fraction_fit: float = 0.1,\n",
        "        fraction_evaluate: float = 0.1,\n",
        "        min_review_clients: int = 2,\n",
        "        min_fit_clients: int = 2,\n",
        "        min_evaluate_clients: int = 2,\n",
        "        min_available_clients: int = 2,\n",
        "        evaluate_fn: Optional[\n",
        "            Callable[\n",
        "                [int, NDArrays, Dict[str, Scalar]],\n",
        "                Optional[Tuple[float, Dict[str, Scalar]]],\n",
        "            ]\n",
        "        ] = None,\n",
        "        on_review_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        accept_failures: bool = True,\n",
        "        initial_parameters: Optional[Parameters] = None,\n",
        "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "    ) -> None:\n",
        "        super(FedLS, self).__init__()\n",
        "\n",
        "        # Strategy adapter fields\n",
        "        self.max_review_rounds = max_review_rounds\n",
        "        self.max_step_size = max_step_size\n",
        "        self.min_step_size = min_step_size\n",
        "        self.step_size_decay = step_size_decay\n",
        "        self.gamma = gamma\n",
        "        self.step_size: float = 0.0\n",
        "        self.current_loss: float = np.inf\n",
        "        self.candidate_loss: float = np.inf\n",
        "\n",
        "        # Strategy adapter fields\n",
        "        self.fraction_review = fraction_review\n",
        "        self.min_review_clients = min_review_clients\n",
        "        self.on_review_config_fn = on_review_config_fn\n",
        "        self.fedavg = FedAvg(\n",
        "            fraction_fit=fraction_fit,\n",
        "            fraction_evaluate=fraction_evaluate,\n",
        "            min_fit_clients=min_fit_clients,\n",
        "            min_evaluate_clients=min_evaluate_clients,\n",
        "            min_available_clients=min_available_clients,\n",
        "            evaluate_fn=evaluate_fn,\n",
        "            on_fit_config_fn=on_fit_config_fn,\n",
        "            on_evaluate_config_fn=on_evaluate_config_fn,\n",
        "            accept_failures=accept_failures,\n",
        "            initial_parameters=initial_parameters,\n",
        "            fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,\n",
        "            evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,\n",
        "        )\n",
        "\n",
        "    def num_review_clients(self, num_available_clients: int):\n",
        "        \"\"\"Return the sample size and the required number of available\n",
        "        clients.\"\"\"\n",
        "        num_clients = int(num_available_clients * self.fraction_review)\n",
        "        return (\n",
        "            max(num_clients, self.min_review_clients),\n",
        "            self.fedavg.min_available_clients,\n",
        "        )\n",
        "\n",
        "    # Standard strategy\n",
        "    @overrides\n",
        "    def initialize_parameters(\n",
        "        self, client_manager: ClientManager\n",
        "    ) -> Optional[Parameters]:\n",
        "        return self.fedavg.initialize_parameters(client_manager)\n",
        "\n",
        "    @overrides\n",
        "    def configure_evaluate(\n",
        "        self, server_round: int, parameters, client_manager: ClientManager\n",
        "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
        "        return self.fedavg.configure_evaluate(server_round, parameters, client_manager)\n",
        "\n",
        "    @overrides\n",
        "    def aggregate_evaluate(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
        "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
        "        loss, metrics = self.fedavg.aggregate_evaluate(server_round, results, failures)\n",
        "        self.current_loss = loss\n",
        "        return loss, metrics\n",
        "\n",
        "    @overrides\n",
        "    def evaluate(\n",
        "        self, server_round: int, parameters: Parameters\n",
        "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
        "        loss, metrics = self.fedavg.evaluate(server_round, parameters)\n",
        "        self.current_loss = loss\n",
        "        return loss, metrics\n",
        "\n",
        "    # Multiple reviews strategy\n",
        "    @overrides\n",
        "    def configure_train(\n",
        "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
        "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
        "        print(f\"Round: {server_round}, configure_train\")\n",
        "        self.step_size = self.max_step_size\n",
        "        return self.fedavg.configure_fit(server_round, parameters, client_manager)\n",
        "\n",
        "    @overrides\n",
        "    def aggregate_train(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "        parameters: Optional[Parameters],\n",
        "    ) -> List[Tuple[Optional[Parameters], Dict[str, Scalar]]]:\n",
        "        print(f\"Round: {server_round}, aggregate_train\")\n",
        "        if not results:\n",
        "            raise AggregateTrainException\n",
        "\n",
        "        # Do not aggregate if there are failures and failures are not accepted\n",
        "        if not self.fedavg.accept_failures and failures:\n",
        "            raise AggregateTrainException\n",
        "\n",
        "        # Convert results\n",
        "        weights_aggregated = aggregate(\n",
        "            [\n",
        "                (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
        "                for _, fit_res in results\n",
        "            ]\n",
        "        )\n",
        "        current_weights = parameters_to_ndarrays(parameters)\n",
        "        gradient = [\n",
        "            weights_aggregated[i] - current_weights[i]\n",
        "            for i in range(len(weights_aggregated))\n",
        "        ]\n",
        "        gradient_params = ndarrays_to_parameters(gradient)\n",
        "        del weights_aggregated, current_weights, gradient\n",
        "        return [(gradient_params, {})]\n",
        "\n",
        "    @overrides\n",
        "    def configure_review(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        review_round: int,\n",
        "        parameters: Parameters,\n",
        "        client_manager: ClientManager,\n",
        "        parameters_aggregated: List[Optional[Parameters]],\n",
        "        metrics_aggregated: List[Dict[str, Scalar]],\n",
        "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
        "        # Do not configure federated review if fraction_review is 0\n",
        "        if self.fraction_review == 0.0:\n",
        "            raise ConfigureReviewException\n",
        "\n",
        "        # Parameters and config\n",
        "        config = {}\n",
        "        if self.on_review_config_fn is not None:\n",
        "            # Custom fit config function provided\n",
        "            config = self.on_review_config_fn(server_round, review_round)\n",
        "\n",
        "        # Prepare review instructions\n",
        "        gradient = parameters_to_ndarrays(parameters_aggregated[0])\n",
        "        current_weights = parameters_to_ndarrays(parameters)\n",
        "        self.step_size = max(\n",
        "            self.min_step_size,\n",
        "            self.max_step_size * (self.step_size_decay ** (review_round - 1)),\n",
        "        )\n",
        "        weights = [\n",
        "            gradient[i] * self.step_size + current_weights[i]\n",
        "            for i in range(len(gradient))\n",
        "        ]\n",
        "        review_ins = FitIns(ndarrays_to_parameters(weights), config)\n",
        "\n",
        "        # Sample clients\n",
        "        sample_size, min_num_clients = self.num_review_clients(\n",
        "            client_manager.num_available()\n",
        "        )\n",
        "        clients = client_manager.sample(\n",
        "            num_clients=sample_size, min_num_clients=min_num_clients\n",
        "        )\n",
        "\n",
        "        del weights, gradient, current_weights\n",
        "        print(\n",
        "            f\"Round: {server_round}, review_round: {review_round}, configure_review, step_size: {self.step_size}\"\n",
        "        )\n",
        "        # Return client/config pairs\n",
        "        return [(client, review_ins) for client in clients]\n",
        "\n",
        "    @overrides\n",
        "    def aggregate_review(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        review_round: int,\n",
        "        results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "        parameters: Parameters,\n",
        "        parameters_aggregated: List[Optional[Parameters]],\n",
        "        metrics_aggregated: List[Dict[str, Scalar]],\n",
        "    ) -> List[Tuple[Optional[Parameters], Dict[str, Scalar]]]:\n",
        "        print(f\"Round: {server_round}, aggregate_review\")\n",
        "        if not results:\n",
        "            raise AggregateReviewException\n",
        "\n",
        "        # Do not aggregate if there are failures and failures are not accepted\n",
        "        if not self.fedavg.accept_failures and failures:\n",
        "            raise AggregateReviewException\n",
        "\n",
        "        # Aggregate results\n",
        "        aggregated_loss = weighted_loss_avg(\n",
        "            [\n",
        "                (review_res.num_examples, review_res.metrics[REVIEW_SCORE])\n",
        "                for _, review_res in results\n",
        "            ]\n",
        "        )\n",
        "        self.candidate_loss = aggregated_loss\n",
        "        return list(zip(parameters_aggregated, metrics_aggregated))\n",
        "\n",
        "    @overrides\n",
        "    def aggregate_after_review(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        parameters: Optional[Parameters],\n",
        "        parameters_aggregated: List[Optional[Parameters]],\n",
        "        metrics_aggregated: List[Dict[str, Scalar]],\n",
        "    ) -> Optional[Parameters]:\n",
        "        print(f\"Round: {server_round}, aggregate_after_review\")\n",
        "        current_weights = parameters_to_ndarrays(parameters)\n",
        "        gradient = parameters_to_ndarrays(parameters_aggregated[0])\n",
        "\n",
        "        # Compute update\n",
        "        for j, tensor in enumerate(gradient):\n",
        "            current_weights[j] += self.step_size * gradient[j]\n",
        "        print(f\"Round {server_round}: lr {self.step_size}\")\n",
        "\n",
        "        # Return\n",
        "        parameters_prime = ndarrays_to_parameters(current_weights)\n",
        "        del current_weights, gradient\n",
        "        return parameters_prime\n",
        "\n",
        "    @overrides\n",
        "    def stop_review(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        review_round: int,\n",
        "        parameters: Parameters,\n",
        "        client_manager: ClientManager,\n",
        "        parameters_aggregated: List[Optional[Parameters]],\n",
        "        metrics_aggregated: List[Dict[str, Scalar]],\n",
        "    ) -> bool:\n",
        "        print(\n",
        "            f\"Round: {server_round}, review_round: {review_round}, stop_review, candidate loss: {self.candidate_loss}\"\n",
        "        )\n",
        "        gradient = parameters_to_ndarrays(parameters_aggregated[0])\n",
        "        if self.candidate_loss <= (\n",
        "            self.current_loss\n",
        "            - self.gamma\n",
        "            * self.step_size\n",
        "            * sum(map(lambda x: np.linalg.norm(x) ** 2, gradient))\n",
        "        ):\n",
        "            del gradient\n",
        "            return True\n",
        "        else:\n",
        "            del gradient\n",
        "            if (self.step_size > self.min_step_size) and (\n",
        "                review_round < (self.max_review_rounds + 1)\n",
        "            ):\n",
        "                return False\n",
        "            else:\n",
        "                return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfZ5cDTNF_WC"
      },
      "outputs": [],
      "source": [
        "def client_fn(cid: str) -> FlowerClient:\n",
        "    net = Net(NUM_CLASSES).to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader)\n",
        "\n",
        "\n",
        "def evaluate(\n",
        "    server_round: int,\n",
        "    weights: fl.common.NDArrays,\n",
        "    config: Dict[str, fl.common.Scalar],\n",
        ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "    net = Net(NUM_CLASSES).to(DEVICE)\n",
        "    set_parameters(net, weights)  # Update model with the latest parameters\n",
        "    loss, accuracy = test(net, testloader)\n",
        "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
        "    return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "\n",
        "def review_config(server_round: int, review_round: int):\n",
        "    return {\"server_round\": server_round, \"review_round\": review_round}\n",
        "\n",
        "\n",
        "def fit_config(server_round: int):\n",
        "    \"\"\"Return training configuration dict for each round.\n",
        "\n",
        "    Perform two rounds of training with one local epoch, increase to two local\n",
        "    epochs afterwards.\n",
        "    \"\"\"\n",
        "    config = {\n",
        "        \"current_round\": server_round,  # The current round of federated learning\n",
        "        \"local_epochs\": 1 if server_round < 2 else LOCAL_EPOCHS,  #\n",
        "    }\n",
        "    return config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9g7jVivPma00",
        "outputId": "bccb150e-e7cd-4837-d643-4ba58f89722e"
      },
      "outputs": [],
      "source": [
        "strategy = FedLS(\n",
        "    max_review_rounds=4,\n",
        "    step_size_decay=np.cos(np.pi / 4),\n",
        "    fraction_review=FRACTION_REV,\n",
        "    fraction_fit=FRACTION_FIT,\n",
        "    fraction_evaluate=FRACTION_EVAL,\n",
        "    min_review_clients=int(FRACTION_REV * NUM_CLIENTS),\n",
        "    min_fit_clients=int(FRACTION_FIT * NUM_CLIENTS),\n",
        "    min_evaluate_clients=int(FRACTION_EVAL * NUM_CLIENTS),\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=ndarrays_to_parameters(get_parameters(net)),\n",
        "    on_fit_config_fn=fit_config,\n",
        "    on_review_config_fn=review_config,\n",
        "    evaluate_fn=evaluate,\n",
        ")\n",
        "client_manager = SimpleClientManager()\n",
        "server = PeerReviewServer(client_manager, strategy)\n",
        "\n",
        "# Enable this in order to debug or to use the gpu,\n",
        "# running simulations in local mode however suffers\n",
        "# from memory leakage and fills the disk with time.\n",
        "LOCAL_MODE = False\n",
        "\n",
        "hist = start_simulation(\n",
        "    server=server,\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=ServerConfig(num_rounds=NUM_ROUNDS),\n",
        "    strategy=strategy,\n",
        "    client_manager=client_manager,\n",
        "    client_resources={\n",
        "        \"num_cpus\": 1,\n",
        "        \"num_gpus\": 1\n",
        "        if (torch.cuda.is_available() and LOCAL_MODE and \"cuda\" in DEVICE)\n",
        "        else 0,\n",
        "    },\n",
        "    ray_init_args={\n",
        "        \"local_mode\": LOCAL_MODE,\n",
        "        \"include_dashboard\": False,\n",
        "    },\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sim_fedls_gpu.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "567eb23278dc48458ee3370825b5f7f3a84494f863de725a2aacc447ea9c55e5"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 (conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d733d3456094af386394b7fd2c03173": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_468c9e8faee04203997eb8a4d73a3509",
              "IPY_MODEL_57299616e5874f9a81b8749c114e8120",
              "IPY_MODEL_e733490f85e14c27a96a8d6d8703ccb9"
            ],
            "layout": "IPY_MODEL_c62a75920efe4340b87fa7a433ed7013"
          }
        },
        "468c9e8faee04203997eb8a4d73a3509": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_754c794b2b0e47ecad43050323f8cc23",
            "placeholder": "​",
            "style": "IPY_MODEL_8f0e5f89dd8449dca14e3772f7f7361d",
            "value": "100%"
          }
        },
        "57299616e5874f9a81b8749c114e8120": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b082c7cc82cd41c9b9a5456da07de957",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67bf7b1829eb4f65ad0919c614618eb5",
            "value": 170498071
          }
        },
        "67bf7b1829eb4f65ad0919c614618eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69d735d80a2c4b2bbdfdd179c12c66b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "754c794b2b0e47ecad43050323f8cc23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f0e5f89dd8449dca14e3772f7f7361d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ec95ceabccc461184abce4aa7f502d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b082c7cc82cd41c9b9a5456da07de957": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c62a75920efe4340b87fa7a433ed7013": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e733490f85e14c27a96a8d6d8703ccb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69d735d80a2c4b2bbdfdd179c12c66b1",
            "placeholder": "​",
            "style": "IPY_MODEL_9ec95ceabccc461184abce4aa7f502d4",
            "value": " 170498071/170498071 [00:02&lt;00:00, 64132490.70it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
